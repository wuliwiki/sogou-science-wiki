<!DOCTYPE html>
<!-- saved from url=(0083)https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/d10718.htm -->
<html class="" data-reactroot=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script src="./718.数据融合 - 搜狗科学百科_files/analytics.js.download" type="text/javascript"></script>
<script type="text/javascript">window.addEventListener('DOMContentLoaded',function(){var v=archive_analytics.values;v.service='wb';v.server_name='wwwb-app223.us.archive.org';v.server_ms=725;archive_analytics.send_pageview({});});</script>
<script type="text/javascript" src="./718.数据融合 - 搜狗科学百科_files/bundle-playback.js.download" charset="utf-8"></script>
<script type="text/javascript" src="./718.数据融合 - 搜狗科学百科_files/wombat.js.download" charset="utf-8"></script>
<script type="text/javascript">
  __wm.init("https://web.archive.org/web");
  __wm.wombat("https://baike.sogou.com/kexue/d10718.htm","20221025114447","https://web.archive.org/","web","/_static/",
	      "1666698287");
</script>
<link rel="stylesheet" type="text/css" href="./718.数据融合 - 搜狗科学百科_files/banner-styles.css">
<link rel="stylesheet" type="text/css" href="./718.数据融合 - 搜狗科学百科_files/iconochive.css">
<!-- End Wayback Rewrite JS Include -->
<meta name="save" content="history"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="baidu-site-verification" content="VWGb6TyYx8"><meta content="数据融合 - 搜狗科学百科" name="keywords"><meta content="搜狗科学百科是一部有着平等、协作、分享、自由理念的网络科学全书，为每一个互联网用户创造一个涵盖所有领域知识、服务的中文知识性平台。" name="description"><meta http-equiv="x-dns-prefetch-control" content="on"><meta name="server" baike="235" ip="210" env="online"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114447/https://cache.soso.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114447/https://hhy.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114447/https://pic.baike.soso.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114447/https://ugc.qpic.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114447/https://xui.ptlogin2.qq.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114447/https://q1.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114447/https://q2.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114447/https://q3.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114447/https://q4.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114447/https://q.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114447/https://img01.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114447/https://img02.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114447/https://img03.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114447/https://img04.sogoucdn.com/"><link rel="Shortcut Icon" href="https://web.archive.org/web/20221025114447im_/https://www.sogou.com/images/logo/new/favicon.ico?v=4"><link rel="Bookmark" href="https://www.sogou.com/images/logo/new/favicon.ico?v=4"><link href="./718.数据融合 - 搜狗科学百科_files/base_b849887.css" rel="stylesheet"><link href="./718.数据融合 - 搜狗科学百科_files/detail_378aed5.css" rel="stylesheet"><link href="./718.数据融合 - 搜狗科学百科_files/inviteAudit_7894507.css" rel="stylesheet"><link rel="stylesheet" href="./718.数据融合 - 搜狗科学百科_files/highlight.min.css"><title>数据融合 - 搜狗科学百科</title><style>.onekey-close {
	position: absolute;
	top: 16px;
	right: 16px;
	width: 24px;
	height: 24px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	text-indent: -999em;
	background-size: 84px;
	background-position: -63px 0;
}

.onekey-login {
	position: absolute;
	top: 16.4%;
	left: 0;
	right: 0;
	width: 100%;
}

/* .onekey-login-img {
    width: 75px;
    height: 75px;
    background: url("https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/images/sprite_wap_baike.png") no-repeat;
    background-size: 100px 91px;
    background-position: 0 0;
    background-repeat: no-repeat;
    margin: 0 auto;
} */

.onekey-login-title {
	text-align: center;
	padding-bottom: 3px;
	font-size: 21px;
	font-weight: bold;
	line-height: 30px;
	color: #000;
}

.onekey-login-txt {
	text-align: center;
	font-family: PingFangSC;
	font-size: 14px;
	line-height: 20px;
	color: #8f8f8f;
}

.onekey-login-qq,
.onekey-login-wx,
.onekey-login-phone {
	display: block;
	width: 245px;
	height: 54px;
	border-radius: 45px;
	text-align: center;

	margin: 0 auto;
	font-size: 17px;
	line-height: 24px;
	color: #000;
	/* padding: 16px 77px; */
	border-radius: 12px;
	border: solid 1px #e0e0e0;
}
.onekey-qq-content,
.onekey-vx-content,
.onekey-phone-content {
	display: inline-block;
	margin-top: 16px;
}
.onekey-qq-content {
	padding: 0 5px;
}

.onekey-login-qq {
	margin-top: 48px;
	margin-bottom: 24px;
}

.onekey-login-qq:before {
	display: inline-block;
	content: "";
	width: 20px;
	height: 20px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 80px;
	background-position: -20px 0;
	vertical-align: top;
	margin: 17px 8px 0 0;
}

.onekey-login-wx {
	margin-bottom: 24px;
}

.onekey-login-wx:before {
	display: inline-block;
	content: "";
	width: 21px;
	height: 21px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 84px;
	background-position: 0 0;
	vertical-align: top;
	margin: 17px 10px 0 0;
}

.onekey-login-phone {
}

.onekey-login-phone:before {
	display: inline-block;
	content: "";
	width: 21px;
	height: 21px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 84px;
	background-position: -42px 0;
	vertical-align: top;
	margin: 17px 10px 0 0;
}

.onekey-fixed {
	z-index: 100;
	position: fixed;
	top: 0;
	bottom: 0;
	left: 0;
	right: 0;
	background: #fff;
	width: 100%;
	height: 100%;
}

.onekey-fixed.forbid {
	z-index: 100;
	position: fixed;
	top: auto;
	bottom: 68px;
	left: 9%;
	right: 0;
	background: rgba(0, 0, 0, 0.7);
	width: 82%;
	height: 43px;
	border-radius: 25px;
	color: #ffffff;
}
.onekey-login-title.forbid {
	text-align: center;
	padding-bottom: 3px;
	font-size: 14px;
	font-weight: normal;
	line-height: 30px;
	color: white;
}
</style><style>#login_mask {
  background: #000;
  opacity: 0.5;
  filter: alpha(opacity=50);
  position: fixed;
  /*fixed好像在哪个IE上有BUG，先用用*/
  left: 0;
  top: 0;
  z-index: 999;
  height: 100%;
}

#login_iframe_container {
  position: fixed;
  width: 550px;
  height: 360px;
  z-index: 1020;
  background-color: #ffffff;
}

@media screen and (max-width: 828px) {
  #login_iframe_container {
    top: 50% !important;
    left: 50% !important;
    transform: translate(-50%, -50%);
  }
}

#login_iframe_container.new-login {
  width: 550px;
  height: 360px;
  background-image: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/background_2a4a8a6.png);
}

#login_iframe_container.new-login.no-bg {
  background: #fff;
}

#login_iframe_container.new-login .login-title {
  width: 100%;
  height: 42px;
  line-height: 42px;
  text-align: center;
  font-size: 30px;
  letter-spacing: 0.19px;
  color: #ffffff;
  margin-top: 62px;
}
#login_iframe_container.new-login .forbid-title {
  width: 100%;
  height: 42px;
  line-height: 42px;
  text-align: center;
  font-size: 24px;
  letter-spacing: 0.19px;
  color: #333333;
  margin-top: 150px;
}

#login_iframe_container.new-login.no-bg .login-title {
  color: #333333;
}

#login_iframe_container.new-login .login-subtitle {
  width: 100%;
  height: 18px;
  line-height: 18px;
  font-size: 13px;
  letter-spacing: 0.08px;
  color: #ffffff;
  text-align: center;
  margin-top: 9px;
  margin-bottom: 43px;
}

#login_iframe_container.new-login.no-bg .login-subtitle {
  color: #999999;
}

#login_iframe_container.new-login .login-subtitle::before {
  content: '';
  display: inline-block;
  width: 10px;
  height: 1px;
  background-color: #ffffff;
  position: relative;
  top: -4px;
  left: -5px;
}

#login_iframe_container.new-login .login-subtitle::after {
  content: '';
  display: inline-block;
  width: 10px;
  height: 1px;
  background-color: #ffffff;
  position: relative;
  top: -4px;
  left: 5px;
}

#login_iframe_container.new-login.no-bg .login-subtitle::before {
  background-color: #999999;
}

#login_iframe_container.new-login.no-bg .login-subtitle::after {
  background-color: #999999;
}

#login_iframe_container.new-login .close-btn {
  position: absolute;
  top: 20px;
  right: 20px;
  width: 12px;
  height: 12px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -59px -10px;
  background-size: 81px 91px;
  cursor: pointer;
}

#login_iframe_container.new-login .login-btn {
  width: 220px;
  height: 47px;
  border-radius: 24px;
  border: solid 1px #dddddd;
  background-color: #ffffff;
  margin: 0 auto;
  margin-top: 28px;
  position: relative;
  display: block;
}

#login_iframe_container.new-login .login-btn .login-icon {
  position: absolute;
}

#login_iframe_container.new-login .login-btn .login-text {
  width: 61px;
  height: 47px;
  line-height: 47px;
  vertical-align: middle;
  font-size: 15px;
  letter-spacing: 0.1px;
  color: #666666;
  position: absolute;
  right: 62px;
}

#login_iframe_container.new-login .login-btn.qq-btn .login-icon {
  width: 22px;
  height: 27px;
  top: 10px;
  left: 67px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -10px -54px;
  background-size: 81px 91px;
}

#login_iframe_container.new-login .login-btn.qq-btn .login-text {
  right: 59px;
}

#login_iframe_container.new-login .login-btn.wechat-btn .login-icon {
  width: 29px;
  height: 24px;
  top: 12px;
  left: 62px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -10px -10px;
  background-size: 81px 91px;
}</style><style>/* -- container -- */
.rodal,
.rodal-mask {
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: 100;
}

.rodal {
    position: fixed;
}

/* -- mask -- */
.rodal-mask {
    position: fixed;
    background: rgba(0, 0, 0, .5);
}

/* -- dialog -- */
.rodal-dialog {
    position: absolute;
    z-index: 101;
    background: #fff;
    border-radius: 3px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, .2);
}

.rodal-center {
    top: 50%;
    transform: translateY(-50%);
    left: 0;
    right: 0;
    margin: 0 auto;
}

.rodal-bottom {
    left: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

.rodal-top {
    left: 0;
    right: 0;
    top: 0;
    margin: auto;
}

.rodal-left {
    top: 0;
    left: 0;
    bottom: 0;
    margin: auto;
}

.rodal-right {
    top: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

/* -- close button -- */
.rodal-close {
    position: absolute;
    cursor: pointer;
    top: 16px;
    right: 16px;
    width: 16px;
    height: 16px;
}

.rodal-close:before,
.rodal-close:after {
    position: absolute;
    content: '';
    height: 2px;
    width: 100%;
    top: 50%;
    left: 0;
    margin-top: -1px;
    background: #999;
    border-radius: 100%;
    -webkit-transition: background .2s;
    transition: background .2s;
}

.rodal-close:before {
    -webkit-transform: rotate(45deg);
    transform: rotate(45deg);
}

.rodal-close:after {
    -webkit-transform: rotate(-45deg);
    transform: rotate(-45deg);
}

.rodal-close:hover:before,
.rodal-close:hover:after {
    background: #333;
}

/* -- fade -- */
/* @-webkit-keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

@keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

.rodal-fade-enter {
    -webkit-animation: rodal-fade-enter both ease-in;
    animation: rodal-fade-enter both ease-in;
} */

@-webkit-keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

@keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

.rodal-fade-leave {
    -webkit-animation: rodal-fade-leave both ease-out;
    animation: rodal-fade-leave both ease-out;
}

/* -- zoom -- */
@-webkit-keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-enter {
    -webkit-animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-leave {
    -webkit-animation: rodal-zoom-leave both;
    animation: rodal-zoom-leave both;
}

/* -- slideDown -- */
@-webkit-keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-enter {
    -webkit-animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-leave {
    -webkit-animation: rodal-slideDown-leave both;
    animation: rodal-slideDown-leave both;
}

/* -- slideLeft -- */
@-webkit-keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-enter {
    -webkit-animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-leave {
    -webkit-animation: rodal-slideLeft-leave both;
    animation: rodal-slideLeft-leave both;
}

/* -- slideRight -- */
@-webkit-keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-enter {
    -webkit-animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-leave {
    -webkit-animation: rodal-slideRight-leave both;
    animation: rodal-slideRight-leave both;
}

/* -- slideUp -- */
@-webkit-keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-enter {
    -webkit-animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
    animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
}

@-webkit-keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-leave {
    -webkit-animation: rodal-slideUp-leave both;
    animation: rodal-slideUp-leave both;
}

/* -- flip -- */
@-webkit-keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

@keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

.rodal-flip-enter {
    -webkit-animation: rodal-flip-enter both ease-in;
    animation: rodal-flip-enter both ease-in;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

@-webkit-keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

@keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

.rodal-flip-leave {
    -webkit-animation: rodal-flip-leave both;
    animation: rodal-flip-leave both;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

/* -- rotate -- */
@-webkit-keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-enter {
    -webkit-animation: rodal-rotate-enter both;
    animation: rodal-rotate-enter both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

@-webkit-keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-leave {
    -webkit-animation: rodal-rotate-leave both;
    animation: rodal-rotate-leave both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

/* -- door -- */
@-webkit-keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

@keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

.rodal-door-enter {
    -webkit-animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

@keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

.rodal-door-leave {
    -webkit-animation: rodal-door-leave both;
    animation: rodal-door-leave both;
}</style><style>/* -- container -- */
.rodal,
.rodal-mask {
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: 100;
}

.rodal {
    position: fixed;
}

/* -- mask -- */
.rodal-mask {
    position: fixed;
    background: rgba(0, 0, 0, .5);
}

/* -- dialog -- */
.rodal-dialog {
    position: absolute;
    z-index: 101;
    background: #fff;
    border-radius: 3px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, .2);
}

.rodal-center {
    top: 50%;
    transform: translateY(-50%);
    left: 0;
    right: 0;
    margin: 0 auto;
}

.rodal-bottom {
    left: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

.rodal-top {
    left: 0;
    right: 0;
    top: 0;
    margin: auto;
}

.rodal-left {
    top: 0;
    left: 0;
    bottom: 0;
    margin: auto;
}

.rodal-right {
    top: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

/* -- close button -- */
.rodal-close {
    position: absolute;
    cursor: pointer;
    top: 16px;
    right: 16px;
    width: 16px;
    height: 16px;
}

.rodal-close:before,
.rodal-close:after {
    position: absolute;
    content: '';
    height: 2px;
    width: 100%;
    top: 50%;
    left: 0;
    margin-top: -1px;
    background: #999;
    border-radius: 100%;
    -webkit-transition: background .2s;
    transition: background .2s;
}

.rodal-close:before {
    -webkit-transform: rotate(45deg);
    transform: rotate(45deg);
}

.rodal-close:after {
    -webkit-transform: rotate(-45deg);
    transform: rotate(-45deg);
}

.rodal-close:hover:before,
.rodal-close:hover:after {
    background: #333;
}

/* -- fade -- */
/* @-webkit-keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

@keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

.rodal-fade-enter {
    -webkit-animation: rodal-fade-enter both ease-in;
    animation: rodal-fade-enter both ease-in;
} */

@-webkit-keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

@keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

.rodal-fade-leave {
    -webkit-animation: rodal-fade-leave both ease-out;
    animation: rodal-fade-leave both ease-out;
}

/* -- zoom -- */
@-webkit-keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-enter {
    -webkit-animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-leave {
    -webkit-animation: rodal-zoom-leave both;
    animation: rodal-zoom-leave both;
}

/* -- slideDown -- */
@-webkit-keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-enter {
    -webkit-animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-leave {
    -webkit-animation: rodal-slideDown-leave both;
    animation: rodal-slideDown-leave both;
}

/* -- slideLeft -- */
@-webkit-keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-enter {
    -webkit-animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-leave {
    -webkit-animation: rodal-slideLeft-leave both;
    animation: rodal-slideLeft-leave both;
}

/* -- slideRight -- */
@-webkit-keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-enter {
    -webkit-animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-leave {
    -webkit-animation: rodal-slideRight-leave both;
    animation: rodal-slideRight-leave both;
}

/* -- slideUp -- */
@-webkit-keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-enter {
    -webkit-animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
    animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
}

@-webkit-keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-leave {
    -webkit-animation: rodal-slideUp-leave both;
    animation: rodal-slideUp-leave both;
}

/* -- flip -- */
@-webkit-keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

@keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

.rodal-flip-enter {
    -webkit-animation: rodal-flip-enter both ease-in;
    animation: rodal-flip-enter both ease-in;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

@-webkit-keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

@keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

.rodal-flip-leave {
    -webkit-animation: rodal-flip-leave both;
    animation: rodal-flip-leave both;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

/* -- rotate -- */
@-webkit-keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-enter {
    -webkit-animation: rodal-rotate-enter both;
    animation: rodal-rotate-enter both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

@-webkit-keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-leave {
    -webkit-animation: rodal-rotate-leave both;
    animation: rodal-rotate-leave both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

/* -- door -- */
@-webkit-keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

@keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

.rodal-door-enter {
    -webkit-animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

@keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

.rodal-door-leave {
    -webkit-animation: rodal-door-leave both;
    animation: rodal-door-leave both;
}</style></head><body class=""><!-- BEGIN WAYBACK TOOLBAR INSERT -->
<style type="text/css">
body {
  margin-top:0 !important;
  padding-top:0 !important;
  /*min-width:800px !important;*/
}
</style>
<script>__wm.rw(0);</script>
<div id="wm-ipp-base" lang="en" style="display: block; direction: ltr;">
</div><div id="wm-ipp-print">The Wayback Machine - https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/d10718.htm</div>
<script type="text/javascript">//<![CDATA[
__wm.bt(675,27,25,2,"web","https://baike.sogou.com/kexue/d10718.htm","20221025114447",1996,"/_static/",["/_static/css/banner-styles.css?v=S1zqJCYt","/_static/css/iconochive.css?v=qtvMKcIJ"], false);
  __wm.rw(1);
//]]></script>
<!-- END WAYBACK TOOLBAR INSERT --><script>window._gtag=window._gtag||{};window._gtag.shouldGrayed = false;if ('28d32d3d945f4b8da478a64a36d9c07d') window._gtag.traceId = '28d32d3d945f4b8da478a64a36d9c07d';if ({"illegality":true}) window.userInfo = {"illegality":true};</script><div class="topnavbox"><ul class="topnav"><li><a href="https://web.archive.org/web/20221025114447/https://www.sogou.com/web?query=">网页</a></li><li><a href="https://web.archive.org/web/20221025114447/https://weixin.sogou.com/weixin?p=75351201">微信</a></li><li><a href="https://web.archive.org/web/20221025114447/https://zhihu.sogou.com/zhihu?p=75351218">知乎</a></li><li><a href="https://web.archive.org/web/20221025114447/https://pic.sogou.com/pics?query=">图片</a></li><li><a href="https://web.archive.org/web/20221025114447/https://v.sogou.com/v?query=">视频</a></li><li><a href="https://web.archive.org/web/20221025114447/https://mingyi.sogou.com/">医疗</a></li><li class="cur"><strong>科学</strong></li><li><a href="https://web.archive.org/web/20221025114447/https://hanyu.sogou.com/">汉语</a></li><li><a href="https://web.archive.org/web/20221025114447/https://wenwen.sogou.com/">问问</a></li><li><a href="https://web.archive.org/web/20221025114447/https://www.sogou.com/docs/more.htm">更多<span class="topraquo">»</span></a></li></ul></div><div id="header"><div class="header-wrap"><a class="header-logo" href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue"></a><div class="header-search"><div class="querybox" id="suggBox"><form><input id="searchInput" class="query" type="text" placeholder="搜科学领域专业百科词条" name="query" autocomplete="off" value=""><a href="javascript:;" class="query-search"></a></form></div></div><div class="header-rgt"><span class="btn-header-rgt btn-edit" id="editLemma">创建</span><div class="header-user no-login"></div></div></div></div><div class="fixed-placeholder" style="visibility:none"></div><div id="container" class=""><div class="content lemma-level1"><div class="detail-title" id="abstract-title"><h1>数据融合</h1><a href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/d10718.htm#!" class="detail-edit">编辑</a></div><div class="section_content" data-id="14995475358810640"><div class="text_img ed_imgfloat_right"><a class="ed_image_link" data-src="https://img03.sogoucdn.com/app/a/200698/sogou_science_13614" data-bigsrc="https://img03.sogoucdn.com/app/a/200698/sogou_science_13614?w=300&amp;h=272&amp;titlename=%E6%9D%A5%E8%87%AA%E4%B8%A4%E4%B8%AA%E6%9D%A5%E6%BA%90(%E7%BB%B4%E5%BA%A6%231%20%26%20%232)%E7%9A%84%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88%E4%BA%A7%E7%94%9F%E7%9A%84%E5%88%86%E7%B1%BB%E5%99%A8%E8%A6%81%E4%BC%98%E4%BA%8E%E4%BB%85%E5%9F%BA%E4%BA%8E%E7%BB%B4%E5%BA%A6%231%E6%88%96%E7%BB%B4%E5%BA%A6%232%E7%9A%84%E4%BB%BB%E4%BD%95%E5%88%86%E7%B1%BB%E5%99%A8" title="点击查看大图" data-w="300" data-h="272" style="background-image:url(https://web.archive.org/web/20221025114447im_/https://img03.sogoucdn.com/app/a/200698/sogou_science_13614)" href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/d10718.htm#!"></a><div class="text_img_title">来自两个来源(维度#1 &amp; #2)的数据融合产生的分类器要优于仅基于维度#1或维度#2的任何分类器</div></div><div><p><b>数据融合</b>是集成多个数据源以产生比任何单个数据源提供的信息更一致、更准确和更有用的信息的过程。<sup><a href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/d10718.htm#quote_1" class="kx_ref">[1]</a></sup> </p> 
<p></p> 
<p>根据融合的处理阶段，数据融合过程通常分为低、中或高三类。<sup><a href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/d10718.htm#quote_2" class="kx_ref">[2]</a></sup> 低级数据融合结合了几个原始数据来源，以产生新的原始数据。期望融合数据比原始输入信息更丰富、更综合。 </p>
<p>例如，传感器融合也称为(多传感器)数据融合，是信息融合的一个子集。 </p>
<p>人类是数据融合的一个主要例子。作为人类，我们严重依赖我们的感官，如视觉、嗅觉、味觉、听觉和身体运动。所有这些感觉的结合每天都在帮助我们完成日常生活中的大部分任务。这本身就是数据融合的一个主要例子。我们依靠嗅觉、味觉和触觉的融合来确保食物的可食用性。同样，我们依靠视觉、听觉和控制身体的运动能力来行走、驾驶和完成生活中的大部分任务。在所有这些情况下，大脑执行融合处理，并控制我们下一步需要做什么。我们的大脑依赖于上述感官所收集数据的融合。 <sup><a href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/d10718.htm#quote_3" class="kx_ref">[3]</a></sup> </p></div></div><div id="catalog"><h2 class="title2">目录<a href="javascript:" class="detail-edit">编辑</a></h2><div class="catalog_wrap" style=""><ul class="catalog_list col2"><li><span class="order">1</span><a href="javascript:" data-level="1" data-id="14995475358810641">地理空间应用</a></li><li><span class="order">2</span><a href="javascript:" data-level="1" data-id="14995475358810642">数据集成</a></li><li><span class="order">3</span><a href="javascript:" data-level="1" data-id="14995475358810643">JDL/DFIG模型</a></li><li class="secondary_catalog"><span>3.1 </span><a href="javascript:" data-id="14995475358810643">应用领域</a></li><li><span class="order">4</span><a href="javascript:" data-level="1" data-id="14995475375587840">多种交通传感模式</a></li></ul><ul class="catalog_list col2"><li><span class="order">5</span><a href="javascript:" data-level="1" data-id="14995475375587841">决策融合</a></li><li><span class="order">6</span><a href="javascript:" data-level="1" data-id="14995475375587842">增强情景感知</a></li><li><span class="order">7</span><a href="javascript:" data-level="1" data-id="references">参考文献</a></li></ul></div></div><div id="paragraphs"><div><div id="par_14995475358810641"><h2 class="title">1 地理空间应用<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>在地理空间(GIS)领域，数据融合通常与数据集成同义。在这些应用中，通常需要将不同的数据集组合成一个统一的(融合的)数据集，该融合数据集包含来自输入数据集的所有数据点和时间点。融合数据集不同于简单的组合超集，因为融合数据集中的点可能包含原始数据集中没有包含的属性和元数据。 </p>
<p>这一过程的一个简化示例如下所示，其中数据集α与数据集β融合，形成融合数据集δ。集合α中的数据点具有空间坐标X和Y以及属性A1和A2。集合β中的数据点具有空间坐标X和Y以及属性B1和B2。融合的数据集包含所有的点和属性。 </p> 
<div class="shadow-tb show-rgt"><table class="wikitable"> 
 <tbody>
  <tr> 
   <th>输入数据集α</th> 
   <th>输入数据集β</th> 
   <th>融合数据集δ </th>
  </tr> 
  <tr> 
   <td> 
    <table class="wikitable"> 
     <tbody>
      <tr> 
       <th>点 </th> 
       <th>X </th> 
       <th>Y </th> 
       <th>A1 </th> 
       <th>A2 </th>
      </tr> 
      <tr> 
       <td>α1 </td> 
       <td>10 </td> 
       <td>10 </td> 
       <td>M </td> 
       <td>N </td>
      </tr> 
      <tr> 
       <td>α2 </td> 
       <td>10 </td> 
       <td>30 </td> 
       <td>M </td> 
       <td>N </td>
      </tr> 
      <tr> 
       <td>α3 </td> 
       <td>30 </td> 
       <td>10 </td> 
       <td>M </td> 
       <td>N </td>
      </tr> 
      <tr> 
       <td>α4 </td> 
       <td>30 </td> 
       <td>30 </td> 
       <td>M </td> 
       <td>N </td>
      </tr>
     </tbody>
    </table> </td> 
   <td> 
    <table class="wikitable"> 
     <tbody>
      <tr> 
       <th>点 </th> 
       <th>X </th> 
       <th>Y </th> 
       <th>B1 </th> 
       <th>B2 </th>
      </tr> 
      <tr> 
       <td>β1 </td> 
       <td>20 </td> 
       <td>20 </td> 
       <td>Q </td> 
       <td>R </td>
      </tr> 
      <tr> 
       <td>β2 </td> 
       <td>20 </td> 
       <td>40 </td> 
       <td>Q </td> 
       <td>R </td>
      </tr> 
      <tr> 
       <td>β3 </td> 
       <td>40 </td> 
       <td>20 </td> 
       <td>Q </td> 
       <td>R </td>
      </tr> 
      <tr> 
       <td>β4 </td> 
       <td>40 </td> 
       <td>40 </td> 
       <td>Q </td> 
       <td>R </td>
      </tr>
     </tbody>
    </table> </td> 
   <td> 
    <table class="wikitable"> 
     <tbody>
      <tr> 
       <th>点 </th> 
       <th>X </th> 
       <th>Y </th> 
       <th>A1 </th> 
       <th>A2 </th> 
       <th>B1 </th> 
       <th>B2 </th>
      </tr> 
      <tr> 
       <td>δ1 </td> 
       <td>10 </td> 
       <td>10 </td> 
       <td>M </td> 
       <td>N </td> 
       <td><i>Q?</i> </td> 
       <td><i>R?</i> </td>
      </tr> 
      <tr> 
       <td>δ2 </td> 
       <td>10 </td> 
       <td>30 </td> 
       <td>M </td> 
       <td>N </td> 
       <td><i>Q?</i> </td> 
       <td><i>R?</i> </td>
      </tr> 
      <tr> 
       <td>δ3 </td> 
       <td>30 </td> 
       <td>10 </td> 
       <td>M </td> 
       <td>N </td> 
       <td><i>Q?</i> </td> 
       <td><i>R?</i> </td>
      </tr> 
      <tr> 
       <td>δ4 </td> 
       <td>30 </td> 
       <td>30 </td> 
       <td>M </td> 
       <td>N </td> 
       <td><i>Q?</i> </td> 
       <td><i>R?</i> </td>
      </tr> 
      <tr> 
       <td>δ5 </td> 
       <td>20 </td> 
       <td>20 </td> 
       <td><i>M?</i> </td> 
       <td><i>N?</i> </td> 
       <td>Q </td> 
       <td>R </td>
      </tr> 
      <tr> 
       <td>δ6 </td> 
       <td>20 </td> 
       <td>40 </td> 
       <td><i>M?</i> </td> 
       <td><i>N?</i> </td> 
       <td>Q </td> 
       <td>R </td>
      </tr> 
      <tr> 
       <td>δ7 </td> 
       <td>40 </td> 
       <td>20 </td> 
       <td><i>M?</i> </td> 
       <td><i>N?</i> </td> 
       <td>Q </td> 
       <td>R </td>
      </tr> 
      <tr> 
       <td>δ8 </td> 
       <td>40 </td> 
       <td>40 </td> 
       <td><i>M?</i> </td> 
       <td><i>N?</i> </td> 
       <td>Q </td> 
       <td>R </td>
      </tr>
     </tbody>
    </table> </td>
  </tr>
 </tbody>
</table></div> 
<p>在这个简单的例子中，所有的属性在整个分析域中都是一致的，属性可以简单地分配。如将M?、N?、Q?、R?分配为M、N、Q、R。在实际应用中，属性是不一致的，通常需要某种类型的插值来为融合集中的数据点正确分配属性。 </p> 
<div class="text_img ed_imgfloat_right">
            <a class="ed_image_link lazyLoad" data-src="https://img01.sogoucdn.com/app/a/200698/sogou_science_13616" data-bigsrc="" title="点击查看大图" href="javascript:" data-observer="true"></a>
            <div class="text_img_title" style="text-align: center;"></div>   
        </div> 
<p>在一个复杂得多的应用中，海洋动物研究人员使用数据融合将动物跟踪数据与测深、气象、海洋表面温度(SST)和动物栖息地数据相结合，以探查和了解栖息地利用和动物对外部力量(如天气或水温)的反应。这些数据集显示了不同的空间网格和采样率，因此简单的组合可能会产生错误的假设，并污染分析结果。但是通过使用数据融合，所有的数据和属性都被整合到一个视图中，并在这个视图中创建一个更完整的环境图像。这使科学家能够确定关键的时间和地点，并对环境和动物行为之间相互作用形成新的见解。 </p>
<p>在右图中，塔斯马尼亚海岸的岩石龙虾作为了研究对象。塔斯马尼亚大学的休·彼得森博士使用数据融合软件将南部龙虾跟踪数据(白天和晚上分别用黄色和黑色进行颜色编码)与水深和栖息地数据融合，创建了独特的4D龙虾行为图片。 </p></div></div><div id="par_14995475358810642"><h2 class="title">2 数据集成<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>在地理空间领域之外的应用中，数据集成和数据融合这两个术语的用法有所不同。例如，在商业智能等领域，数据集成被用来描述数据的组合，而数据融合是包含减少或替换的集成。数据集成可以被视为集合组合，其中较大的集合被保留，而融合是一种提高置信度的集合缩减技术。 </p></div></div><div id="par_14995475358810643"><h2 class="title">3 JDL/DFIG模型<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>20世纪80年代中期，联合主管实验室(Joint Directors of Laboratories)组建了数据融合子板(Data Fusion Subpanel，后来被称为数据融合小组)。随着万维网的出现，数据融合包含了数据、传感器和信息融合。JDL/DFIG 引入了一种数据融合模型，以将不同的过程分开。目前，数据融合信息组(DFIG)模型的六个级别是： </p>
<p>级别0：源预处理/主题评估 </p>
<p>级别1：对象评估 </p>
<p>级别2：形势评估 </p>
<p>第3级：影响评估(或威胁改进) </p>
<p>第4级：流程细化 </p>
<p>第5级：用户提炼(或认知提炼) </p>
<p>尽管JDL模型(1-4级)至今仍在使用，但它经常受到批评，因为它暗示这些级别必然是有序发生的，也因为它没有充分体现人在回路中的潜力。DFIG应模型(0-5级)探索了态势感知、用户细化和任务管理的含义。<sup><a href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/d10718.htm#quote_4" class="kx_ref">[4]</a></sup> 尽管存在这些缺点，JDL/DFIG模型对于可视化数据融合过程、促进讨论和共同理解非常有用，<sup><a href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/d10718.htm#quote_5" class="kx_ref">[5]</a></sup> 并且对于系统级的信息融合设计非常重要。<sup><a href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/d10718.htm#quote_4" class="kx_ref">[4]</a></sup> </p> 
<h3>3.1 <span>应用领域</span></h3> 
<ul>
 <li>地理空间信息系统</li> 
 <li>土壤制图</li> 
 <li>商业智能</li> 
 <li>海洋学</li> 
 <li>发现科学</li> 
 <li>业务绩效管理</li> 
 <li>智能运输系统</li> 
 <li>顾客积分卡</li> 
 <li>化学信息学 
  <ul>
   <li>定量构效关系</li>
  </ul></li> 
 <li>生物信息学</li> 
 <li>情报机构</li> 
 <li>无线传感器网络</li> 
 <li>生物测定学</li>
</ul></div></div><div id="par_14995475375587840"><h2 class="title">4 多种交通传感模式<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>来自不同传感技术的数据可以以智能的方式组合，以准确地确定交通状态。基于路边收集的声音、图像和传感器数据的数据融合方法，结合了不同的单个方法的优点。<sup><a href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/d10718.htm#quote_6" class="kx_ref">[6]</a></sup> </p></div></div><div id="par_14995475375587841"><h2 class="title">5 决策融合<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>在许多情况下，地理上分散的传感器受到严重的能量和带宽限制。因此，某一现象的原始数据通常被整合为来自每个传感器的几个比特。当推断二元事件(即，H0或H1或)时，在极端情况下，只有二元决策信息从传感器发送到决策融合中心(DFC)并进行融合，以获得改进的分类性能。<sup><a href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/d10718.htm#quote_7" class="kx_ref">[7]</a></sup><sup><a href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/d10718.htm#quote_8" class="kx_ref">[8]</a></sup><sup><a href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/d10718.htm#quote_9" class="kx_ref">[9]</a></sup> </p></div></div><div id="par_14995475375587842"><h2 class="title">6 增强情景感知<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>利用包括运动传感器、环境传感器、位置传感器在内的大量内置传感器，现代移动设备通常允许移动应用程序访问大量传感数据，这些传感数据可以被用来增强情景感知。使用信号处理和数据融合技术(如特征生成、可行性研究和主成分分析(PCA))来分析这些感知数据，将大大提高对设备运动和情景状态分类的正确率。<sup><a href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/d10718.htm#quote_10" class="kx_ref">[10]</a></sup> </p></div></div></div></div><div id="references"><h2 class="title" id="par_references">参考文献</h2><ul class="references"><li id="quote_1"><span class="references-num">[1]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Haghighat, Mohammad; Abdel-Mottaleb, Mohamed; Alhalabi, Wadee (2016). "Discriminant Correlation Analysis: Real-Time Feature Level Fusion for Multimodal Biometric Recognition". IEEE Transactions on Information Forensics and Security. 11 (9): 1984–1996. doi:10.1109/TIFS.2016.2569061..</span></p></li><li id="quote_2"><span class="references-num">[2]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Klein, Lawrence A. (2004). Sensor and data fusion: A tool for information assessment and decision making. SPIE Press. p. 51. ISBN 978-0-8194-5435-5..</span></p></li><li id="quote_3"><span class="references-num">[3]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Penn State WebAccess Secure Login". ieeexplore-ieee-org.ezaccess.libraries.psu.edu (in 英语). Retrieved 2018-06-27..</span></p></li><li id="quote_4"><span class="references-num">[4]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Blasch, Erik P.; Bossé, Éloi; Lambert, Dale A. (2012). High-Level Information Fusion Management and System Design. Norwood, MA: Artech House Publishers. ISBN 978-1-6080-7151-7..</span></p></li><li id="quote_5"><span class="references-num">[5]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Liggins, Martin E.; Hall, David L.; Llinas, James (2008). Multisensor Data Fusion, Second Edition: Theory and Practice (Multisensor Data Fusion). CRC. ISBN 978-1-4200-5308-1..</span></p></li><li id="quote_6"><span class="references-num">[6]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Joshi, V., Rajamani, N., Takayuki, K., Prathapaneni, Subramaniam, L. V., (2013). Information Fusion Based Learning for Frugal Traffic State Sensing. Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence.CS1 maint: Multiple names: authors list (link).</span></p></li><li id="quote_7"><span class="references-num">[7]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Ciuonzo, D.; Papa, G.; Romano, G.; Salvo Rossi, P.; Willett, P. (2013-09-01). "One-Bit Decentralized Detection With a Rao Test for Multisensor Fusion". IEEE Signal Processing Letters. 20 (9): 861–864. arXiv:1306.6141. Bibcode:2013ISPL...20..861C. doi:10.1109/LSP.2013.2271847. ISSN 1070-9908..</span></p></li><li id="quote_8"><span class="references-num">[8]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Ciuonzo, D.; Salvo Rossi, P. (2014-02-01). "Decision Fusion With Unknown Sensor Detection Probability". IEEE Signal Processing Letters. 21 (2): 208–212. arXiv:1312.2227. Bibcode:2014ISPL...21..208C. doi:10.1109/LSP.2013.2295054. ISSN 1070-9908..</span></p></li><li id="quote_9"><span class="references-num">[9]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Ciuonzo, D.; De Maio, A.; Salvo Rossi, P. (2015-09-01). "A Systematic Framework for Composite Hypothesis Testing of Independent Bernoulli Trials". IEEE Signal Processing Letters. 22 (9): 1249–1253. Bibcode:2015ISPL...22.1249C. doi:10.1109/LSP.2015.2395811. ISSN 1070-9908..</span></p></li><li id="quote_10"><span class="references-num">[10]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Guiry, John J.; van de Ven, Pepijn; Nelson, John (2014-03-21). "Multi-Sensor Fusion for Enhanced Contextual Awareness of Everyday Activities with Ubiquitous Devices". Sensors (in 英语). 14 (3): 5687–5701. doi:10.3390/s140305687. PMC 4004015. PMID 24662406..</span></p></li></ul></div><div class="read-num">阅读 <!-- -->74</div></div><div class="right-side" id="rightSide"><div class="side" id="lemma-side"><div class="side-title">版本记录</div><ul class="side-lst"><li><p class="side-lst-txt">暂无</p></li></ul><div class="user-card userCard"></div></div><div class="side"><div class="side-event"></div></div></div></div><div class="footer-box"><div id="footer"><div class="footer-logo-wrap"><div class="footer-logo"></div><div class="footer-logo-text">知识·传播·科普</div></div><div class="footer-info">本网站内容采用<a target="_blank" href="https://web.archive.org/web/20221025114447/https://creativecommons.org/licenses/by-sa/3.0/deed.zh?tdsourcetag=s_pctim_aiomsg">CC-BY-SA 3.0</a>授权</div><div class="footer-btn-wrap"><a target="_blank" href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/help/#user_protocol">用户协议</a><a target="_blank" href="https://web.archive.org/web/20221025114447/http://www.sogou.com/docs/terms.htm?v=1">免责声明</a><a target="_blank" href="https://web.archive.org/web/20221025114447/http://corp.sogou.com/private.html">隐私政策</a><a target="_blank" href="https://web.archive.org/web/20221025114447/https://baike.sogou.com/kexue/intro.htm">关于我们</a></div></div></div><script>window.lemmaInfo ={"lemmaId":"10718","versionId":"14995475358810632","title":"数据融合","subtitle":"","abstracts":{"paragraphId":"14995475358810640","title":"简介","versionId":"14995475358810633","lemmaId":10718,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":31221062,"name":"张志煌","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233999,"comment":null,"dependVersionId":0,"contentType":2,"content":"<p><b>数据融合</b>是集成多个数据源以产生比任何单个数据源提供的信息更一致、更准确和更有用的信息的过程。<sup><a href=\"#quote_1\" class=\"kx_ref\">[1]</a></sup> </p> \n<p></p> \n<p>根据融合的处理阶段，数据融合过程通常分为低、中或高三类。<sup><a href=\"#quote_2\" class=\"kx_ref\">[2]</a></sup> 低级数据融合结合了几个原始数据来源，以产生新的原始数据。期望融合数据比原始输入信息更丰富、更综合。 </p>\n<p>例如，传感器融合也称为(多传感器)数据融合，是信息融合的一个子集。 </p>\n<p>人类是数据融合的一个主要例子。作为人类，我们严重依赖我们的感官，如视觉、嗅觉、味觉、听觉和身体运动。所有这些感觉的结合每天都在帮助我们完成日常生活中的大部分任务。这本身就是数据融合的一个主要例子。我们依靠嗅觉、味觉和触觉的融合来确保食物的可食用性。同样，我们依靠视觉、听觉和控制身体的运动能力来行走、驾驶和完成生活中的大部分任务。在所有这些情况下，大脑执行融合处理，并控制我们下一步需要做什么。我们的大脑依赖于上述感官所收集数据的融合。 <sup><a href=\"#quote_3\" class=\"kx_ref\">[3]</a></sup> </p>","pics":[{"originalUrl":"https://web.archive.org/web/20221025114447/https://img03.sogoucdn.com/app/a/200698/sogou_science_13614?w=300&h=272&titlename=%E6%9D%A5%E8%87%AA%E4%B8%A4%E4%B8%AA%E6%9D%A5%E6%BA%90(%E7%BB%B4%E5%BA%A6%231%20%26%20%232)%E7%9A%84%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88%E4%BA%A7%E7%94%9F%E7%9A%84%E5%88%86%E7%B1%BB%E5%99%A8%E8%A6%81%E4%BC%98%E4%BA%8E%E4%BB%85%E5%9F%BA%E4%BA%8E%E7%BB%B4%E5%BA%A6%231%E6%88%96%E7%BB%B4%E5%BA%A6%232%E7%9A%84%E4%BB%BB%E4%BD%95%E5%88%86%E7%B1%BB%E5%99%A8","url":"https://web.archive.org/web/20221025114447/https://img03.sogoucdn.com/app/a/200698/sogou_science_13614","rw":300,"rh":272,"title":"来自两个来源(维度#1 & #2)的数据融合产生的分类器要优于仅基于维度#1或维度#2的任何分类器","alt":null,"width":0,"height":0}],"card":null,"references":[],"versionCount":0},"card":{"paragraphId":"0","title":null,"versionId":"0","lemmaId":0,"createType":0,"creator":null,"createTime":0,"versionEditor":null,"editTime":0,"comment":null,"dependVersionId":0,"contentType":0,"content":null,"pics":null,"card":null,"references":null,"versionCount":0},"categories":[{"id":6,"name":"机械工程","parents":[]}],"creator":{"uid":31221062,"name":"张志煌","pic":"https://web.archive.org/web/20221025114447/https://cache.soso.com/qlogo/g?b=oidb&k=yI5YsiaWJ2vMgkUriabwpoPQ&s=100&t=1555539303","introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":"","jobBrief":"","role":0,"roleName":null,"title":"","professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":151,"partnerIdCreateTime":1595844883,"partnerIdPoped":false},"createTime":1568626451,"editor":{"uid":31221062,"name":"张志煌","pic":"https://web.archive.org/web/20221025114447/https://cache.soso.com/qlogo/g?b=oidb&k=yI5YsiaWJ2vMgkUriabwpoPQ&s=100&t=1555539303","introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":"","jobBrief":"","role":0,"roleName":null,"title":"","professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":151,"partnerIdCreateTime":1595844883,"partnerIdPoped":false},"editTime":1576233999,"state":1,"versionCount":1,"upNum":0,"downNum":0,"pics":[{"originalUrl":"https://web.archive.org/web/20221025114447/https://img03.sogoucdn.com/app/a/200698/sogou_science_13614?w=300&h=272&titlename=%E6%9D%A5%E8%87%AA%E4%B8%A4%E4%B8%AA%E6%9D%A5%E6%BA%90(%E7%BB%B4%E5%BA%A6%231%20%26%20%232)%E7%9A%84%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88%E4%BA%A7%E7%94%9F%E7%9A%84%E5%88%86%E7%B1%BB%E5%99%A8%E8%A6%81%E4%BC%98%E4%BA%8E%E4%BB%85%E5%9F%BA%E4%BA%8E%E7%BB%B4%E5%BA%A6%231%E6%88%96%E7%BB%B4%E5%BA%A6%232%E7%9A%84%E4%BB%BB%E4%BD%95%E5%88%86%E7%B1%BB%E5%99%A8","url":"https://web.archive.org/web/20221025114447/https://img03.sogoucdn.com/app/a/200698/sogou_science_13614","rw":300,"rh":272,"title":"来自两个来源(维度#1 & #2)的数据融合产生的分类器要优于仅基于维度#1或维度#2的任何分类器","alt":null,"width":0,"height":0},{"originalUrl":"https://web.archive.org/web/20221025114447/https://img01.sogoucdn.com/app/a/200698/sogou_science_13616?w=450&h=269&titlename=","url":"https://web.archive.org/web/20221025114447/https://img01.sogoucdn.com/app/a/200698/sogou_science_13616","rw":450,"rh":269,"title":"","alt":null,"width":0,"height":0}],"catalogs":[{"level":1,"title":"地理空间应用","paragraphId":"14995475358810641","subCatalogs":null},{"level":1,"title":"数据集成","paragraphId":"14995475358810642","subCatalogs":null},{"level":1,"title":"JDL/DFIG模型","paragraphId":"14995475358810643","subCatalogs":[{"level":2,"title":"应用领域","paragraphId":"14995475358810643","subCatalogs":null}]},{"level":1,"title":"多种交通传感模式","paragraphId":"14995475375587840","subCatalogs":null},{"level":1,"title":"决策融合","paragraphId":"14995475375587841","subCatalogs":null},{"level":1,"title":"增强情景感知","paragraphId":"14995475375587842","subCatalogs":null},{"level":1,"title":"参考文献","paragraphId":"-1","subCatalogs":null}],"paragraphs":[{"paragraphId":"14995475358810641","title":"地理空间应用","versionId":"14995475358810634","lemmaId":10718,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":31221062,"name":"张志煌","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233999,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>在地理空间(GIS)领域，数据融合通常与数据集成同义。在这些应用中，通常需要将不同的数据集组合成一个统一的(融合的)数据集，该融合数据集包含来自输入数据集的所有数据点和时间点。融合数据集不同于简单的组合超集，因为融合数据集中的点可能包含原始数据集中没有包含的属性和元数据。 </p>\n<p>这一过程的一个简化示例如下所示，其中数据集α与数据集β融合，形成融合数据集δ。集合α中的数据点具有空间坐标X和Y以及属性A1和A2。集合β中的数据点具有空间坐标X和Y以及属性B1和B2。融合的数据集包含所有的点和属性。 </p> \n<table class=\"wikitable\"> \n <tbody>\n  <tr> \n   <th>输入数据集α</th> \n   <th>输入数据集β</th> \n   <th>融合数据集δ </th>\n  </tr> \n  <tr> \n   <td> \n    <table class=\"wikitable\"> \n     <tbody>\n      <tr> \n       <th>点 </th> \n       <th>X </th> \n       <th>Y </th> \n       <th>A1 </th> \n       <th>A2 </th>\n      </tr> \n      <tr> \n       <td>α1 </td> \n       <td>10 </td> \n       <td>10 </td> \n       <td>M </td> \n       <td>N </td>\n      </tr> \n      <tr> \n       <td>α2 </td> \n       <td>10 </td> \n       <td>30 </td> \n       <td>M </td> \n       <td>N </td>\n      </tr> \n      <tr> \n       <td>α3 </td> \n       <td>30 </td> \n       <td>10 </td> \n       <td>M </td> \n       <td>N </td>\n      </tr> \n      <tr> \n       <td>α4 </td> \n       <td>30 </td> \n       <td>30 </td> \n       <td>M </td> \n       <td>N </td>\n      </tr>\n     </tbody>\n    </table> </td> \n   <td> \n    <table class=\"wikitable\"> \n     <tbody>\n      <tr> \n       <th>点 </th> \n       <th>X </th> \n       <th>Y </th> \n       <th>B1 </th> \n       <th>B2 </th>\n      </tr> \n      <tr> \n       <td>β1 </td> \n       <td>20 </td> \n       <td>20 </td> \n       <td>Q </td> \n       <td>R </td>\n      </tr> \n      <tr> \n       <td>β2 </td> \n       <td>20 </td> \n       <td>40 </td> \n       <td>Q </td> \n       <td>R </td>\n      </tr> \n      <tr> \n       <td>β3 </td> \n       <td>40 </td> \n       <td>20 </td> \n       <td>Q </td> \n       <td>R </td>\n      </tr> \n      <tr> \n       <td>β4 </td> \n       <td>40 </td> \n       <td>40 </td> \n       <td>Q </td> \n       <td>R </td>\n      </tr>\n     </tbody>\n    </table> </td> \n   <td> \n    <table class=\"wikitable\"> \n     <tbody>\n      <tr> \n       <th>点 </th> \n       <th>X </th> \n       <th>Y </th> \n       <th>A1 </th> \n       <th>A2 </th> \n       <th>B1 </th> \n       <th>B2 </th>\n      </tr> \n      <tr> \n       <td>δ1 </td> \n       <td>10 </td> \n       <td>10 </td> \n       <td>M </td> \n       <td>N </td> \n       <td><i>Q?</i> </td> \n       <td><i>R?</i> </td>\n      </tr> \n      <tr> \n       <td>δ2 </td> \n       <td>10 </td> \n       <td>30 </td> \n       <td>M </td> \n       <td>N </td> \n       <td><i>Q?</i> </td> \n       <td><i>R?</i> </td>\n      </tr> \n      <tr> \n       <td>δ3 </td> \n       <td>30 </td> \n       <td>10 </td> \n       <td>M </td> \n       <td>N </td> \n       <td><i>Q?</i> </td> \n       <td><i>R?</i> </td>\n      </tr> \n      <tr> \n       <td>δ4 </td> \n       <td>30 </td> \n       <td>30 </td> \n       <td>M </td> \n       <td>N </td> \n       <td><i>Q?</i> </td> \n       <td><i>R?</i> </td>\n      </tr> \n      <tr> \n       <td>δ5 </td> \n       <td>20 </td> \n       <td>20 </td> \n       <td><i>M?</i> </td> \n       <td><i>N?</i> </td> \n       <td>Q </td> \n       <td>R </td>\n      </tr> \n      <tr> \n       <td>δ6 </td> \n       <td>20 </td> \n       <td>40 </td> \n       <td><i>M?</i> </td> \n       <td><i>N?</i> </td> \n       <td>Q </td> \n       <td>R </td>\n      </tr> \n      <tr> \n       <td>δ7 </td> \n       <td>40 </td> \n       <td>20 </td> \n       <td><i>M?</i> </td> \n       <td><i>N?</i> </td> \n       <td>Q </td> \n       <td>R </td>\n      </tr> \n      <tr> \n       <td>δ8 </td> \n       <td>40 </td> \n       <td>40 </td> \n       <td><i>M?</i> </td> \n       <td><i>N?</i> </td> \n       <td>Q </td> \n       <td>R </td>\n      </tr>\n     </tbody>\n    </table> </td>\n  </tr>\n </tbody>\n</table> \n<p>在这个简单的例子中，所有的属性在整个分析域中都是一致的，属性可以简单地分配。如将M?、N?、Q?、R?分配为M、N、Q、R。在实际应用中，属性是不一致的，通常需要某种类型的插值来为融合集中的数据点正确分配属性。 </p> \n<img alt=\"Visualization of fused data sets for rock lobster tracks in the Tasman Sea.  Image generated using Eonfusion software by Myriax Pty. Ltd. - eonfusion.myriax.com\" class=\"fileimage kx_img ed_imgfloat_right\" img_height=\"269\" img_width=\"450\" titlename=\"\" data-src=\"https://img01.sogoucdn.com/app/a/200698/sogou_science_13616\"> \n<p>在一个复杂得多的应用中，海洋动物研究人员使用数据融合将动物跟踪数据与测深、气象、海洋表面温度(SST)和动物栖息地数据相结合，以探查和了解栖息地利用和动物对外部力量(如天气或水温)的反应。这些数据集显示了不同的空间网格和采样率，因此简单的组合可能会产生错误的假设，并污染分析结果。但是通过使用数据融合，所有的数据和属性都被整合到一个视图中，并在这个视图中创建一个更完整的环境图像。这使科学家能够确定关键的时间和地点，并对环境和动物行为之间相互作用形成新的见解。 </p>\n<p>在右图中，塔斯马尼亚海岸的岩石龙虾作为了研究对象。塔斯马尼亚大学的休·彼得森博士使用数据融合软件将南部龙虾跟踪数据(白天和晚上分别用黄色和黑色进行颜色编码)与水深和栖息地数据融合，创建了独特的4D龙虾行为图片。 </p>","pics":[{"originalUrl":"https://web.archive.org/web/20221025114447/https://img01.sogoucdn.com/app/a/200698/sogou_science_13616?w=450&h=269&titlename=","url":"https://web.archive.org/web/20221025114447/https://img01.sogoucdn.com/app/a/200698/sogou_science_13616","rw":450,"rh":269,"title":"","alt":null,"width":0,"height":0}],"card":null,"references":[],"versionCount":0},{"paragraphId":"14995475358810642","title":"数据集成","versionId":"14995475358810635","lemmaId":10718,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":31221062,"name":"张志煌","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233999,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>在地理空间领域之外的应用中，数据集成和数据融合这两个术语的用法有所不同。例如，在商业智能等领域，数据集成被用来描述数据的组合，而数据融合是包含减少或替换的集成。数据集成可以被视为集合组合，其中较大的集合被保留，而融合是一种提高置信度的集合缩减技术。 </p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995475358810643","title":"JDL/DFIG模型","versionId":"14995475358810636","lemmaId":10718,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":31221062,"name":"张志煌","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233999,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>20世纪80年代中期，联合主管实验室(Joint Directors of Laboratories)组建了数据融合子板(Data Fusion Subpanel，后来被称为数据融合小组)。随着万维网的出现，数据融合包含了数据、传感器和信息融合。JDL/DFIG 引入了一种数据融合模型，以将不同的过程分开。目前，数据融合信息组(DFIG)模型的六个级别是： </p>\n<p>级别0：源预处理/主题评估 </p>\n<p>级别1：对象评估 </p>\n<p>级别2：形势评估 </p>\n<p>第3级：影响评估(或威胁改进) </p>\n<p>第4级：流程细化 </p>\n<p>第5级：用户提炼(或认知提炼) </p>\n<p>尽管JDL模型(1-4级)至今仍在使用，但它经常受到批评，因为它暗示这些级别必然是有序发生的，也因为它没有充分体现人在回路中的潜力。DFIG应模型(0-5级)探索了态势感知、用户细化和任务管理的含义。<sup><a href=\"#quote_4\" class=\"kx_ref\">[4]</a></sup> 尽管存在这些缺点，JDL/DFIG模型对于可视化数据融合过程、促进讨论和共同理解非常有用，<sup><a href=\"#quote_5\" class=\"kx_ref\">[5]</a></sup> 并且对于系统级的信息融合设计非常重要。<sup><a href=\"#quote_4\" class=\"kx_ref\">[4]</a></sup> </p> \n<h3>应用领域</h3> \n<ul>\n <li>地理空间信息系统</li> \n <li>土壤制图</li> \n <li>商业智能</li> \n <li>海洋学</li> \n <li>发现科学</li> \n <li>业务绩效管理</li> \n <li>智能运输系统</li> \n <li>顾客积分卡</li> \n <li>化学信息学 \n  <ul>\n   <li>定量构效关系</li>\n  </ul></li> \n <li>生物信息学</li> \n <li>情报机构</li> \n <li>无线传感器网络</li> \n <li>生物测定学</li>\n</ul>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995475375587840","title":"多种交通传感模式","versionId":"14995475358810637","lemmaId":10718,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":31221062,"name":"张志煌","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233999,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>来自不同传感技术的数据可以以智能的方式组合，以准确地确定交通状态。基于路边收集的声音、图像和传感器数据的数据融合方法，结合了不同的单个方法的优点。<sup><a href=\"#quote_6\" class=\"kx_ref\">[6]</a></sup> </p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995475375587841","title":"决策融合","versionId":"14995475358810638","lemmaId":10718,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":31221062,"name":"张志煌","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233999,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>在许多情况下，地理上分散的传感器受到严重的能量和带宽限制。因此，某一现象的原始数据通常被整合为来自每个传感器的几个比特。当推断二元事件(即，H0或H1或)时，在极端情况下，只有二元决策信息从传感器发送到决策融合中心(DFC)并进行融合，以获得改进的分类性能。<sup><a href=\"#quote_7\" class=\"kx_ref\">[7]</a></sup><sup><a href=\"#quote_8\" class=\"kx_ref\">[8]</a></sup><sup><a href=\"#quote_9\" class=\"kx_ref\">[9]</a></sup> </p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995475375587842","title":"增强情景感知","versionId":"14995475358810639","lemmaId":10718,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":31221062,"name":"张志煌","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233999,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>利用包括运动传感器、环境传感器、位置传感器在内的大量内置传感器，现代移动设备通常允许移动应用程序访问大量传感数据，这些传感数据可以被用来增强情景感知。使用信号处理和数据融合技术(如特征生成、可行性研究和主成分分析(PCA))来分析这些感知数据，将大大提高对设备运动和情景状态分类的正确率。<sup><a href=\"#quote_10\" class=\"kx_ref\">[10]</a></sup> </p>","pics":null,"card":null,"references":[],"versionCount":0}],"references":[{"id":1,"type":"book","title":"Haghighat, Mohammad; Abdel-Mottaleb, Mohamed; Alhalabi, Wadee (2016). \"Discriminant Correlation Analysis: Real-Time Feature Level Fusion for Multimodal Biometric Recognition\". IEEE Transactions on Information Forensics and Security. 11 (9): 1984–1996. doi:10.1109/TIFS.2016.2569061.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":2,"type":"book","title":"Klein, Lawrence A. (2004). Sensor and data fusion: A tool for information assessment and decision making. SPIE Press. p. 51. ISBN 978-0-8194-5435-5.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":3,"type":"book","title":"\"Penn State WebAccess Secure Login\". ieeexplore-ieee-org.ezaccess.libraries.psu.edu (in 英语). Retrieved 2018-06-27.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":4,"type":"book","title":"Blasch, Erik P.; Bossé, Éloi; Lambert, Dale A. (2012). High-Level Information Fusion Management and System Design. Norwood, MA: Artech House Publishers. ISBN 978-1-6080-7151-7.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":5,"type":"book","title":"Liggins, Martin E.; Hall, David L.; Llinas, James (2008). Multisensor Data Fusion, Second Edition: Theory and Practice (Multisensor Data Fusion). CRC. ISBN 978-1-4200-5308-1.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":6,"type":"book","title":"Joshi, V., Rajamani, N., Takayuki, K., Prathapaneni, Subramaniam, L. V., (2013). Information Fusion Based Learning for Frugal Traffic State Sensing. Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence.CS1 maint: Multiple names: authors list (link)","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":7,"type":"book","title":"Ciuonzo, D.; Papa, G.; Romano, G.; Salvo Rossi, P.; Willett, P. (2013-09-01). \"One-Bit Decentralized Detection With a Rao Test for Multisensor Fusion\". IEEE Signal Processing Letters. 20 (9): 861–864. arXiv:1306.6141. Bibcode:2013ISPL...20..861C. doi:10.1109/LSP.2013.2271847. ISSN 1070-9908.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":8,"type":"book","title":"Ciuonzo, D.; Salvo Rossi, P. (2014-02-01). \"Decision Fusion With Unknown Sensor Detection Probability\". IEEE Signal Processing Letters. 21 (2): 208–212. arXiv:1312.2227. Bibcode:2014ISPL...21..208C. doi:10.1109/LSP.2013.2295054. ISSN 1070-9908.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":9,"type":"book","title":"Ciuonzo, D.; De Maio, A.; Salvo Rossi, P. (2015-09-01). \"A Systematic Framework for Composite Hypothesis Testing of Independent Bernoulli Trials\". IEEE Signal Processing Letters. 22 (9): 1249–1253. Bibcode:2015ISPL...22.1249C. doi:10.1109/LSP.2015.2395811. ISSN 1070-9908.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":10,"type":"book","title":"Guiry, John J.; van de Ven, Pepijn; Nelson, John (2014-03-21). \"Multi-Sensor Fusion for Enhanced Contextual Awareness of Everyday Activities with Ubiquitous Devices\". Sensors (in 英语). 14 (3): 5687–5701. doi:10.3390/s140305687. PMC 4004015. PMID 24662406.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false}],"recommendReferences":null,"auditState":2,"lemmaLevel":1,"origin":0,"originEnTitle":null,"originZhTitle":null,"pv":74,"auditType":0,"synonyms":null,"showEditTime":"2019.12.13 18:46","auditors":[{"uid":0,"name":"Ki.κe","pic":"https://web.archive.org/web/20221025114447/https://wx.qlogo.cn/mmopen/vi_32/y67kfr32Doib4wg71Jiau7jVWvharic3nRKgdRRQSl6koeQJCo0GQs2Krw0vwdFRsOWnHIQOwAZsSg5lIkIrFCOcQ/132","introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":"","jobBrief":"","role":0,"roleName":null,"title":"","professionalTitle":null,"phoneNo":null,"editable":true,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false}],"hasZhishiNav":false,"auditInfos":{},"isHistory":false};</script><script crossorigin="anonymous" src="./718.数据融合 - 搜狗科学百科_files/aegis.min.js.download"></script><script crossorigin="anonymous" src="./718.数据融合 - 搜狗科学百科_files/main_2020092401.js.download"></script><script crossorigin="anonymous" src="./718.数据融合 - 搜狗科学百科_files/react.production.min.js.download"></script><script crossorigin="anonymous" src="./718.数据融合 - 搜狗科学百科_files/react-dom.production.min.js.download"></script><script crossorigin="anonymous" src="./718.数据融合 - 搜狗科学百科_files/jquery-1.11.1.min.js.download"></script><script crossorigin="anonymous" src="./718.数据融合 - 搜狗科学百科_files/main_2022062701.js.download"></script><script crossorigin="anonymous" src="./718.数据融合 - 搜狗科学百科_files/main_66bbe21.js.download"></script><script crossorigin="anonymous" src="./718.数据融合 - 搜狗科学百科_files/react.production.min.js.download"></script><script crossorigin="anonymous" src="./718.数据融合 - 搜狗科学百科_files/react-dom.production.min.js.download"></script><script crossorigin="anonymous" src="./718.数据融合 - 搜狗科学百科_files/main_edf0f08.js.download"></script><div id="popControl"><div class="pop-control-mask" style="display: none;"><div class="pop-container"><i class="close-icon"></i><div class="stop-title">搜狗科学百科停止服务运营公告</div><div class="stop-user">亲爱的用户：</div><div class="stop-content">因业务方向调整，搜狗科学百科将于2022年11月11日正式停止服务与运营。届时产品内所有数据将依据相关法律进行删除并关闭服务器，您将无法登录及使用搜狗科学百科，相关内容在平台下线后将无法找回。</div><div class="stop-content">搜狗科学百科是由搜狗推出的科学领域专业百科产品，与搜狗百科为两个独立产品，本次停止服务与运营仅对搜狗科学百科，并不影响搜狗百科产品正常使用，敬请知悉。</div><div class="stop-content">由此给您带来的不便我们深表歉意，敬请谅解。再次感谢您一直以来的陪伴与支持！</div><div class="stop-team">搜狗科学百科产品&amp;运营团队</div><div class="stop-time">2022年10月11日</div></div></div></div>
</body></html>