<!DOCTYPE html>
<!-- saved from url=(0083)https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm -->
<html class="" data-reactroot=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script src="./438.深度学习 - 搜狗科学百科_files/analytics.js.download" type="text/javascript"></script>
<script type="text/javascript">window.addEventListener('DOMContentLoaded',function(){var v=archive_analytics.values;v.service='wb';v.server_name='wwwb-app209.us.archive.org';v.server_ms=276;archive_analytics.send_pageview({});});</script>
<script type="text/javascript" src="./438.深度学习 - 搜狗科学百科_files/bundle-playback.js.download" charset="utf-8"></script>
<script type="text/javascript" src="./438.深度学习 - 搜狗科学百科_files/wombat.js.download" charset="utf-8"></script>
<script type="text/javascript">
  __wm.init("https://web.archive.org/web");
  __wm.wombat("https://baike.sogou.com/kexue/d10438.htm","20221025113558","https://web.archive.org/","web","/_static/",
	      "1666697758");
</script>
<link rel="stylesheet" type="text/css" href="./438.深度学习 - 搜狗科学百科_files/banner-styles.css">
<link rel="stylesheet" type="text/css" href="./438.深度学习 - 搜狗科学百科_files/iconochive.css">
<!-- End Wayback Rewrite JS Include -->
<meta name="save" content="history"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="baidu-site-verification" content="VWGb6TyYx8"><meta content="深度学习 - 搜狗科学百科" name="keywords"><meta content="搜狗科学百科是一部有着平等、协作、分享、自由理念的网络科学全书，为每一个互联网用户创造一个涵盖所有领域知识、服务的中文知识性平台。" name="description"><meta http-equiv="x-dns-prefetch-control" content="on"><meta name="server" baike="235" ip="210" env="online"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025113558/https://cache.soso.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025113558/https://hhy.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025113558/https://pic.baike.soso.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025113558/https://ugc.qpic.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025113558/https://xui.ptlogin2.qq.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025113558/https://q1.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025113558/https://q2.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025113558/https://q3.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025113558/https://q4.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025113558/https://q.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025113558/https://img01.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025113558/https://img02.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025113558/https://img03.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025113558/https://img04.sogoucdn.com/"><link rel="Shortcut Icon" href="https://web.archive.org/web/20221025113558im_/https://www.sogou.com/images/logo/new/favicon.ico?v=4"><link rel="Bookmark" href="https://www.sogou.com/images/logo/new/favicon.ico?v=4"><link href="./438.深度学习 - 搜狗科学百科_files/base_b849887.css" rel="stylesheet"><link href="./438.深度学习 - 搜狗科学百科_files/detail_378aed5.css" rel="stylesheet"><link href="./438.深度学习 - 搜狗科学百科_files/inviteAudit_7894507.css" rel="stylesheet"><link rel="stylesheet" href="./438.深度学习 - 搜狗科学百科_files/highlight.min.css"><title>深度学习 - 搜狗科学百科</title><style>.onekey-close {
	position: absolute;
	top: 16px;
	right: 16px;
	width: 24px;
	height: 24px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	text-indent: -999em;
	background-size: 84px;
	background-position: -63px 0;
}

.onekey-login {
	position: absolute;
	top: 16.4%;
	left: 0;
	right: 0;
	width: 100%;
}

/* .onekey-login-img {
    width: 75px;
    height: 75px;
    background: url("https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/images/sprite_wap_baike.png") no-repeat;
    background-size: 100px 91px;
    background-position: 0 0;
    background-repeat: no-repeat;
    margin: 0 auto;
} */

.onekey-login-title {
	text-align: center;
	padding-bottom: 3px;
	font-size: 21px;
	font-weight: bold;
	line-height: 30px;
	color: #000;
}

.onekey-login-txt {
	text-align: center;
	font-family: PingFangSC;
	font-size: 14px;
	line-height: 20px;
	color: #8f8f8f;
}

.onekey-login-qq,
.onekey-login-wx,
.onekey-login-phone {
	display: block;
	width: 245px;
	height: 54px;
	border-radius: 45px;
	text-align: center;

	margin: 0 auto;
	font-size: 17px;
	line-height: 24px;
	color: #000;
	/* padding: 16px 77px; */
	border-radius: 12px;
	border: solid 1px #e0e0e0;
}
.onekey-qq-content,
.onekey-vx-content,
.onekey-phone-content {
	display: inline-block;
	margin-top: 16px;
}
.onekey-qq-content {
	padding: 0 5px;
}

.onekey-login-qq {
	margin-top: 48px;
	margin-bottom: 24px;
}

.onekey-login-qq:before {
	display: inline-block;
	content: "";
	width: 20px;
	height: 20px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 80px;
	background-position: -20px 0;
	vertical-align: top;
	margin: 17px 8px 0 0;
}

.onekey-login-wx {
	margin-bottom: 24px;
}

.onekey-login-wx:before {
	display: inline-block;
	content: "";
	width: 21px;
	height: 21px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 84px;
	background-position: 0 0;
	vertical-align: top;
	margin: 17px 10px 0 0;
}

.onekey-login-phone {
}

.onekey-login-phone:before {
	display: inline-block;
	content: "";
	width: 21px;
	height: 21px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 84px;
	background-position: -42px 0;
	vertical-align: top;
	margin: 17px 10px 0 0;
}

.onekey-fixed {
	z-index: 100;
	position: fixed;
	top: 0;
	bottom: 0;
	left: 0;
	right: 0;
	background: #fff;
	width: 100%;
	height: 100%;
}

.onekey-fixed.forbid {
	z-index: 100;
	position: fixed;
	top: auto;
	bottom: 68px;
	left: 9%;
	right: 0;
	background: rgba(0, 0, 0, 0.7);
	width: 82%;
	height: 43px;
	border-radius: 25px;
	color: #ffffff;
}
.onekey-login-title.forbid {
	text-align: center;
	padding-bottom: 3px;
	font-size: 14px;
	font-weight: normal;
	line-height: 30px;
	color: white;
}
</style><style>#login_mask {
  background: #000;
  opacity: 0.5;
  filter: alpha(opacity=50);
  position: fixed;
  /*fixed好像在哪个IE上有BUG，先用用*/
  left: 0;
  top: 0;
  z-index: 999;
  height: 100%;
}

#login_iframe_container {
  position: fixed;
  width: 550px;
  height: 360px;
  z-index: 1020;
  background-color: #ffffff;
}

@media screen and (max-width: 828px) {
  #login_iframe_container {
    top: 50% !important;
    left: 50% !important;
    transform: translate(-50%, -50%);
  }
}

#login_iframe_container.new-login {
  width: 550px;
  height: 360px;
  background-image: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/background_2a4a8a6.png);
}

#login_iframe_container.new-login.no-bg {
  background: #fff;
}

#login_iframe_container.new-login .login-title {
  width: 100%;
  height: 42px;
  line-height: 42px;
  text-align: center;
  font-size: 30px;
  letter-spacing: 0.19px;
  color: #ffffff;
  margin-top: 62px;
}
#login_iframe_container.new-login .forbid-title {
  width: 100%;
  height: 42px;
  line-height: 42px;
  text-align: center;
  font-size: 24px;
  letter-spacing: 0.19px;
  color: #333333;
  margin-top: 150px;
}

#login_iframe_container.new-login.no-bg .login-title {
  color: #333333;
}

#login_iframe_container.new-login .login-subtitle {
  width: 100%;
  height: 18px;
  line-height: 18px;
  font-size: 13px;
  letter-spacing: 0.08px;
  color: #ffffff;
  text-align: center;
  margin-top: 9px;
  margin-bottom: 43px;
}

#login_iframe_container.new-login.no-bg .login-subtitle {
  color: #999999;
}

#login_iframe_container.new-login .login-subtitle::before {
  content: '';
  display: inline-block;
  width: 10px;
  height: 1px;
  background-color: #ffffff;
  position: relative;
  top: -4px;
  left: -5px;
}

#login_iframe_container.new-login .login-subtitle::after {
  content: '';
  display: inline-block;
  width: 10px;
  height: 1px;
  background-color: #ffffff;
  position: relative;
  top: -4px;
  left: 5px;
}

#login_iframe_container.new-login.no-bg .login-subtitle::before {
  background-color: #999999;
}

#login_iframe_container.new-login.no-bg .login-subtitle::after {
  background-color: #999999;
}

#login_iframe_container.new-login .close-btn {
  position: absolute;
  top: 20px;
  right: 20px;
  width: 12px;
  height: 12px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -59px -10px;
  background-size: 81px 91px;
  cursor: pointer;
}

#login_iframe_container.new-login .login-btn {
  width: 220px;
  height: 47px;
  border-radius: 24px;
  border: solid 1px #dddddd;
  background-color: #ffffff;
  margin: 0 auto;
  margin-top: 28px;
  position: relative;
  display: block;
}

#login_iframe_container.new-login .login-btn .login-icon {
  position: absolute;
}

#login_iframe_container.new-login .login-btn .login-text {
  width: 61px;
  height: 47px;
  line-height: 47px;
  vertical-align: middle;
  font-size: 15px;
  letter-spacing: 0.1px;
  color: #666666;
  position: absolute;
  right: 62px;
}

#login_iframe_container.new-login .login-btn.qq-btn .login-icon {
  width: 22px;
  height: 27px;
  top: 10px;
  left: 67px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -10px -54px;
  background-size: 81px 91px;
}

#login_iframe_container.new-login .login-btn.qq-btn .login-text {
  right: 59px;
}

#login_iframe_container.new-login .login-btn.wechat-btn .login-icon {
  width: 29px;
  height: 24px;
  top: 12px;
  left: 62px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -10px -10px;
  background-size: 81px 91px;
}</style><style>/* -- container -- */
.rodal,
.rodal-mask {
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: 100;
}

.rodal {
    position: fixed;
}

/* -- mask -- */
.rodal-mask {
    position: fixed;
    background: rgba(0, 0, 0, .5);
}

/* -- dialog -- */
.rodal-dialog {
    position: absolute;
    z-index: 101;
    background: #fff;
    border-radius: 3px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, .2);
}

.rodal-center {
    top: 50%;
    transform: translateY(-50%);
    left: 0;
    right: 0;
    margin: 0 auto;
}

.rodal-bottom {
    left: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

.rodal-top {
    left: 0;
    right: 0;
    top: 0;
    margin: auto;
}

.rodal-left {
    top: 0;
    left: 0;
    bottom: 0;
    margin: auto;
}

.rodal-right {
    top: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

/* -- close button -- */
.rodal-close {
    position: absolute;
    cursor: pointer;
    top: 16px;
    right: 16px;
    width: 16px;
    height: 16px;
}

.rodal-close:before,
.rodal-close:after {
    position: absolute;
    content: '';
    height: 2px;
    width: 100%;
    top: 50%;
    left: 0;
    margin-top: -1px;
    background: #999;
    border-radius: 100%;
    -webkit-transition: background .2s;
    transition: background .2s;
}

.rodal-close:before {
    -webkit-transform: rotate(45deg);
    transform: rotate(45deg);
}

.rodal-close:after {
    -webkit-transform: rotate(-45deg);
    transform: rotate(-45deg);
}

.rodal-close:hover:before,
.rodal-close:hover:after {
    background: #333;
}

/* -- fade -- */
/* @-webkit-keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

@keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

.rodal-fade-enter {
    -webkit-animation: rodal-fade-enter both ease-in;
    animation: rodal-fade-enter both ease-in;
} */

@-webkit-keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

@keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

.rodal-fade-leave {
    -webkit-animation: rodal-fade-leave both ease-out;
    animation: rodal-fade-leave both ease-out;
}

/* -- zoom -- */
@-webkit-keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-enter {
    -webkit-animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-leave {
    -webkit-animation: rodal-zoom-leave both;
    animation: rodal-zoom-leave both;
}

/* -- slideDown -- */
@-webkit-keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-enter {
    -webkit-animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-leave {
    -webkit-animation: rodal-slideDown-leave both;
    animation: rodal-slideDown-leave both;
}

/* -- slideLeft -- */
@-webkit-keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-enter {
    -webkit-animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-leave {
    -webkit-animation: rodal-slideLeft-leave both;
    animation: rodal-slideLeft-leave both;
}

/* -- slideRight -- */
@-webkit-keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-enter {
    -webkit-animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-leave {
    -webkit-animation: rodal-slideRight-leave both;
    animation: rodal-slideRight-leave both;
}

/* -- slideUp -- */
@-webkit-keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-enter {
    -webkit-animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
    animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
}

@-webkit-keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-leave {
    -webkit-animation: rodal-slideUp-leave both;
    animation: rodal-slideUp-leave both;
}

/* -- flip -- */
@-webkit-keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

@keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

.rodal-flip-enter {
    -webkit-animation: rodal-flip-enter both ease-in;
    animation: rodal-flip-enter both ease-in;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

@-webkit-keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

@keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

.rodal-flip-leave {
    -webkit-animation: rodal-flip-leave both;
    animation: rodal-flip-leave both;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

/* -- rotate -- */
@-webkit-keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-enter {
    -webkit-animation: rodal-rotate-enter both;
    animation: rodal-rotate-enter both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

@-webkit-keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-leave {
    -webkit-animation: rodal-rotate-leave both;
    animation: rodal-rotate-leave both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

/* -- door -- */
@-webkit-keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

@keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

.rodal-door-enter {
    -webkit-animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

@keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

.rodal-door-leave {
    -webkit-animation: rodal-door-leave both;
    animation: rodal-door-leave both;
}</style><style>/* -- container -- */
.rodal,
.rodal-mask {
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: 100;
}

.rodal {
    position: fixed;
}

/* -- mask -- */
.rodal-mask {
    position: fixed;
    background: rgba(0, 0, 0, .5);
}

/* -- dialog -- */
.rodal-dialog {
    position: absolute;
    z-index: 101;
    background: #fff;
    border-radius: 3px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, .2);
}

.rodal-center {
    top: 50%;
    transform: translateY(-50%);
    left: 0;
    right: 0;
    margin: 0 auto;
}

.rodal-bottom {
    left: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

.rodal-top {
    left: 0;
    right: 0;
    top: 0;
    margin: auto;
}

.rodal-left {
    top: 0;
    left: 0;
    bottom: 0;
    margin: auto;
}

.rodal-right {
    top: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

/* -- close button -- */
.rodal-close {
    position: absolute;
    cursor: pointer;
    top: 16px;
    right: 16px;
    width: 16px;
    height: 16px;
}

.rodal-close:before,
.rodal-close:after {
    position: absolute;
    content: '';
    height: 2px;
    width: 100%;
    top: 50%;
    left: 0;
    margin-top: -1px;
    background: #999;
    border-radius: 100%;
    -webkit-transition: background .2s;
    transition: background .2s;
}

.rodal-close:before {
    -webkit-transform: rotate(45deg);
    transform: rotate(45deg);
}

.rodal-close:after {
    -webkit-transform: rotate(-45deg);
    transform: rotate(-45deg);
}

.rodal-close:hover:before,
.rodal-close:hover:after {
    background: #333;
}

/* -- fade -- */
/* @-webkit-keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

@keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

.rodal-fade-enter {
    -webkit-animation: rodal-fade-enter both ease-in;
    animation: rodal-fade-enter both ease-in;
} */

@-webkit-keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

@keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

.rodal-fade-leave {
    -webkit-animation: rodal-fade-leave both ease-out;
    animation: rodal-fade-leave both ease-out;
}

/* -- zoom -- */
@-webkit-keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-enter {
    -webkit-animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-leave {
    -webkit-animation: rodal-zoom-leave both;
    animation: rodal-zoom-leave both;
}

/* -- slideDown -- */
@-webkit-keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-enter {
    -webkit-animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-leave {
    -webkit-animation: rodal-slideDown-leave both;
    animation: rodal-slideDown-leave both;
}

/* -- slideLeft -- */
@-webkit-keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-enter {
    -webkit-animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-leave {
    -webkit-animation: rodal-slideLeft-leave both;
    animation: rodal-slideLeft-leave both;
}

/* -- slideRight -- */
@-webkit-keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-enter {
    -webkit-animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-leave {
    -webkit-animation: rodal-slideRight-leave both;
    animation: rodal-slideRight-leave both;
}

/* -- slideUp -- */
@-webkit-keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-enter {
    -webkit-animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
    animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
}

@-webkit-keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-leave {
    -webkit-animation: rodal-slideUp-leave both;
    animation: rodal-slideUp-leave both;
}

/* -- flip -- */
@-webkit-keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

@keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

.rodal-flip-enter {
    -webkit-animation: rodal-flip-enter both ease-in;
    animation: rodal-flip-enter both ease-in;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

@-webkit-keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

@keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

.rodal-flip-leave {
    -webkit-animation: rodal-flip-leave both;
    animation: rodal-flip-leave both;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

/* -- rotate -- */
@-webkit-keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-enter {
    -webkit-animation: rodal-rotate-enter both;
    animation: rodal-rotate-enter both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

@-webkit-keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-leave {
    -webkit-animation: rodal-rotate-leave both;
    animation: rodal-rotate-leave both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

/* -- door -- */
@-webkit-keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

@keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

.rodal-door-enter {
    -webkit-animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

@keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

.rodal-door-leave {
    -webkit-animation: rodal-door-leave both;
    animation: rodal-door-leave both;
}</style>
<!--百度统计-->
<script>
   var _hmt = _hmt || [];
   (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?3c7614be3026469d5a60f41ab30b5082";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
      })();
</script>

	<!--百度统计-->
	<script>
		var _hmt = _hmt || [];
		(function() {
			var hm = document.createElement("script");
			hm.src = "https://hm.baidu.com/hm.js?3c7614be3026469d5a60f41ab30b5082";
			var s = document.getElementsByTagName("script")[0]; 
			s.parentNode.insertBefore(hm, s);
			})();
	</script>
</head>
<body class=""><!-- BEGIN WAYBACK TOOLBAR INSERT -->
<style type="text/css">
body {
  margin-top:0 !important;
  padding-top:0 !important;
  /*min-width:800px !important;*/
}
</style>
<script>__wm.rw(0);</script>
<div id="wm-ipp-base" lang="en" style="display: block; direction: ltr;">
</div><div id="wm-ipp-print">The Wayback Machine - https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm</div>
<script type="text/javascript">//<![CDATA[
__wm.bt(675,27,25,2,"web","https://baike.sogou.com/kexue/d10438.htm","20221025113558",1996,"/_static/",["/_static/css/banner-styles.css?v=S1zqJCYt","/_static/css/iconochive.css?v=qtvMKcIJ"], false);
  __wm.rw(1);
//]]></script>
<!-- END WAYBACK TOOLBAR INSERT --><script>window._gtag=window._gtag||{};window._gtag.shouldGrayed = false;if ('fe36df130ac244d1b1ead7d4db5e6b58') window._gtag.traceId = 'fe36df130ac244d1b1ead7d4db5e6b58';if ({"illegality":true}) window.userInfo = {"illegality":true};</script><div class="topnavbox"><ul class="topnav"><li><a href="https://web.archive.org/web/20221025113558/https://www.sogou.com/web?query=">网页</a></li><li><a href="https://web.archive.org/web/20221025113558/https://weixin.sogou.com/weixin?p=75351201">微信</a></li><li><a href="https://web.archive.org/web/20221025113558/https://zhihu.sogou.com/zhihu?p=75351218">知乎</a></li><li><a href="https://web.archive.org/web/20221025113558/https://pic.sogou.com/pics?query=">图片</a></li><li><a href="https://web.archive.org/web/20221025113558/https://v.sogou.com/v?query=">视频</a></li><li><a href="https://web.archive.org/web/20221025113558/https://mingyi.sogou.com/">医疗</a></li><li class="cur"><strong>科学</strong></li><li><a href="https://web.archive.org/web/20221025113558/https://hanyu.sogou.com/">汉语</a></li><li><a href="https://web.archive.org/web/20221025113558/https://wenwen.sogou.com/">问问</a></li><li><a href="https://web.archive.org/web/20221025113558/https://www.sogou.com/docs/more.htm">更多<span class="topraquo">»</span></a></li></ul></div><div id="header"><div class="header-wrap"><a class="header-logo" href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue"></a><div class="header-search"><div class="querybox" id="suggBox"><form><input id="searchInput" class="query" type="text" placeholder="搜科学领域专业百科词条" name="query" autocomplete="off" value=""><a href="javascript:;" class="query-search"></a></form></div></div><div class="header-rgt"><span class="btn-header-rgt btn-edit" id="editLemma">创建</span><div class="header-user no-login"></div></div></div></div><div class="fixed-placeholder" style="visibility:none"></div><div id="container" class=""><div class="content lemma-level1"><div class="detail-title" id="abstract-title"><h1>深度学习</h1><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#!" class="detail-edit">编辑</a></div><div class="section_content" data-id="14995109430952204"><div><p>深度学习（也称为深度结构化学习或分层学习）是基于人工神经网络的更广泛的机器学习方法族的一部分。学习可以是有监督的、半监督的或无监督的。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_1" class="kx_ref">[1]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_2" class="kx_ref">[2]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_3" class="kx_ref">[3]</a></sup> </p>
<p>深度学习架构，例如深度神经网络、深度信念网络、循环神经网络和卷积神经网络，已经被应用于包括计算机视觉、语音识别、自然语言处理、音频识别、社交网络过滤、机器翻译、生物信息学、药物设计、医学图像分析、材料检查和棋盘游戏程序在内的领域，在这些领域中，它们的成果可与人类专家媲美，并且在某些情况下胜过人类专家。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_4" class="kx_ref">[4]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_5" class="kx_ref">[5]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_6" class="kx_ref">[6]</a></sup> </p>
<p>神经网络受到生物系统中信息处理和分布式通信节点的启发。人工神经网络与生物大脑有各种不同。具体而言，神经网络往往是静态和象征性的，而大多数生物的大脑是动态(可塑)和模拟的。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_7" class="kx_ref">[7]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_8" class="kx_ref">[8]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_9" class="kx_ref">[9]</a></sup> </p></div></div><div id="catalog"><h2 class="title2">目录<a href="javascript:" class="detail-edit">编辑</a></h2><div class="catalog_wrap" style=""><ul class="catalog_list col4"><li><span class="order">1</span><a href="javascript:" data-level="1" data-id="14995109447729414">定义</a></li><li><span class="order">2</span><a href="javascript:" data-level="1" data-id="14995109464506635">概览</a></li><li><span class="order">3</span><a href="javascript:" data-level="1" data-id="14995109464506636">解释</a></li><li><span class="order">4</span><a href="javascript:" data-level="1" data-id="14995109481283848">历史</a></li><li class="secondary_catalog"><span>4.1 </span><a href="javascript:" data-id="14995109481283848">深度学习革命</a></li><li><span class="order">5</span><a href="javascript:" data-level="1" data-id="14995109514838287">神经网络</a></li><li class="secondary_catalog"><span>5.1 </span><a href="javascript:" data-id="14995109514838287">人工神经网络</a></li><li class="secondary_catalog"><span>5.2 </span><a href="javascript:" data-id="14995109514838287">深度神经网络</a></li></ul><ul class="catalog_list col4"><li><span class="order">6</span><a href="javascript:" data-level="1" data-id="14995109514838288">应用</a></li><li class="secondary_catalog"><span>6.1 </span><a href="javascript:" data-id="14995109514838288">自动语音识别</a></li><li class="secondary_catalog"><span>6.2 </span><a href="javascript:" data-id="14995109514838288">图像识别</a></li><li class="secondary_catalog"><span>6.3 </span><a href="javascript:" data-id="14995109514838288">视觉艺术处理</a></li><li class="secondary_catalog"><span>6.4 </span><a href="javascript:" data-id="14995109514838288">自然语言处理</a></li><li class="secondary_catalog"><span>6.5 </span><a href="javascript:" data-id="14995109514838288">药物发现和毒理学</a></li><li class="secondary_catalog"><span>6.6 </span><a href="javascript:" data-id="14995109514838288">客户关系管理</a></li><li class="secondary_catalog"><span>6.7 </span><a href="javascript:" data-id="14995109514838288">推荐系统</a></li></ul><ul class="catalog_list col4"><li class="secondary_catalog"><span>6.8 </span><a href="javascript:" data-id="14995109514838288">生物信息学</a></li><li class="secondary_catalog"><span>6.9 </span><a href="javascript:" data-id="14995109514838288">医学图像分析</a></li><li class="secondary_catalog"><span>6.10 </span><a href="javascript:" data-id="14995109514838288">手机广告</a></li><li class="secondary_catalog"><span>6.11 </span><a href="javascript:" data-id="14995109514838288">图像恢复</a></li><li class="secondary_catalog"><span>6.12 </span><a href="javascript:" data-id="14995109514838288">金融欺诈检测</a></li><li class="secondary_catalog"><span>6.13 </span><a href="javascript:" data-id="14995109514838288">军队</a></li><li><span class="order">7</span><a href="javascript:" data-level="1" data-id="14995109531615498">与人类认知和大脑发育的关系</a></li></ul><ul class="catalog_list col4"><li><span class="order">8</span><a href="javascript:" data-level="1" data-id="14995109548392712">商业活动</a></li><li><span class="order">9</span><a href="javascript:" data-level="1" data-id="14995109565169923">批判和议论</a></li><li class="secondary_catalog"><span>9.1 </span><a href="javascript:" data-id="14995109565169923">理论</a></li><li class="secondary_catalog"><span>9.2 </span><a href="javascript:" data-id="14995109565169923">错误</a></li><li class="secondary_catalog"><span>9.3 </span><a href="javascript:" data-id="14995109565169923">网络威胁</a></li><li><span class="order">10</span><a href="javascript:" data-level="1" data-id="references">参考文献</a></li></ul></div></div><div id="paragraphs"><div><div id="par_14995109447729414"><h2 class="title">1 定义<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>深度学习是一类机器学习算法：<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_10" class="kx_ref">[10]</a></sup> 使用多个层逐步从原始输入中逐步提取更高级别的特征。例如，在图像处理中，较低层可以识别边缘，而较高层可以识别对人类有意义的部分，例如数字/字母或面部。 </p></div></div><div id="par_14995109464506635"><h2 class="title">2 概览<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>大多数现代的深度学习模型基于人工神经网络，特别是卷积神经网络（CNN），尽管它们也可以包括命题公式或在深度生成模型中逐层组织的潜变量，例如深度信念网络和深度玻尔兹曼机中的节点。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_11" class="kx_ref">[11]</a></sup> </p>
<p>在深度学习中，每一级学习将其输入数据转换成稍微抽象和复合的表示。在图像识别应用中，原始输入可以是像素矩阵；第一代表层可以提取像素并编码边缘；第二层可以组成和编码边缘排列；第三层可以编码鼻子和眼睛；并且第四层可以识别包含人脸的图像。重要的是，深入的学习过程可以学习将哪些特征放在哪个级别上是最优的。(当然，这并不能完全避免需要手动调整；例如，不同的层数和层大小可以提供不同程度的抽象。)<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_1" class="kx_ref">[1]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_12" class="kx_ref">[12]</a></sup> </p>
<p>“深度学习”中的“深度”是指数据转换的层数。更准确地说，深度学习系统有一个实质的<i>信用分配路径 （CAP）</i>深度。CAP是从输入到输出的转换链。CAP描述了输入和输出之间潜在的因果关系。对于前馈神经网络，CAP的深度是网络的深度，等于隐藏层的数量加上1(因为输出层也是参数化的)。对于递归神经网络，其中信号可能不止一次地通过一个层传播，CAP深度可能是无限的。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_2" class="kx_ref">[2]</a></sup>没有普遍认同的深度阈值将浅层和深度学习区分开来，但是大多数研究者认同深度学习中的CAP深度&gt;2。深度为2的CAP已被证明是一个通用逼近器，因为它可以模拟任何函数。除此之外，更多的层不会增加网络的函数逼近能力。深度模型（CAP &gt; 2）能够提取比浅层模型更好的特征，因此，额外的层有助于学习特征。 </p>
<p>深度学习架构通常是用贪婪逐层方法构建的。深度学习有助于理清这些抽象概念，并找出哪些特性可以提高性能。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_1" class="kx_ref">[1]</a></sup> </p>
<p>对于监督学习任务，深度学习方法通过将数据转换成类似于主成分的紧凑中间表示，并导出消除冗余表示后的分层结构，从而避免了特征工程。 </p>
<p>深度学习算法可以应用于无监督的学习任务。这是一个重要的好处，因为未标记的数据比标记的数据更丰富。可以无监督方式训练的深层结构的例子有神经历史压缩器<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_13" class="kx_ref">[13]</a></sup>和深度信念网络。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_1" class="kx_ref">[1]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_14" class="kx_ref">[14]</a></sup> </p></div></div><div id="par_14995109464506636"><h2 class="title">3 解释<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>深度神经网络通常用万能近似定理或者概率推理<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_10" class="kx_ref">[10]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_11" class="kx_ref">[11]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_1" class="kx_ref">[1]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_2" class="kx_ref">[2]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_14" class="kx_ref">[14]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_15" class="kx_ref">[15]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_16" class="kx_ref">[16]</a></sup>来解释。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_17" class="kx_ref">[17]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_18" class="kx_ref">[18]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_19" class="kx_ref">[19]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_20" class="kx_ref">[20]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_21" class="kx_ref">[21]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_22" class="kx_ref">[22]</a></sup> </p>
<p>经典的万用近似定理关注具有有限大小的单个隐藏层的前馈神经网络逼近连续函数的能力。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_17" class="kx_ref">[17]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_18" class="kx_ref">[18]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_19" class="kx_ref">[19]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_20" class="kx_ref">[20]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_21" class="kx_ref">[21]</a></sup>1989年，乔治·赛本科发表了关于sigmoid激活函数的首个证明<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_18" class="kx_ref">[18]</a></sup>，库尔特·霍尼克在1991年将其推广到前馈多层体系结构。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_19" class="kx_ref">[19]</a></sup> </p>
<p>深度神经网络的万用近似定理涉及有限宽度但深度可增长的网络的容量。Lu等人<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_22" class="kx_ref">[22]</a></sup>证明了如果具有ReLU激活的深度神经网络的宽度严格大于输入维数，则网络可以近似任何勒贝格可积函数；如果宽度小于或等于输入维数，那么深度神经网络不是一个通用逼近器。 </p>
<p>概率解释<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_15" class="kx_ref">[15]</a></sup>源自机器学习领域。它的特点是推理，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_10" class="kx_ref">[10]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_11" class="kx_ref">[11]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_1" class="kx_ref">[1]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_2" class="kx_ref">[2]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_14" class="kx_ref">[14]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_15" class="kx_ref">[15]</a></sup>以及分别与拟合和泛化相关的训练和测试的优化概念。更具体地说，概率解释将非线性激活函数视为累积分布函数。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_15" class="kx_ref">[15]</a></sup>概率解释导致在神经网络中引入损失作为正则化。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_23" class="kx_ref">[23]</a></sup>概率解释由霍普菲尔德、维卓尔和纳伦德拉等研究人员引入，并在毕晓普等人的调查中得到推广。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_24" class="kx_ref">[24]</a></sup> </p></div></div><div id="par_14995109481283848"><h2 class="title">4 历史<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p><i>深度学习</i>这个术语由Rina Dechter于1986年引入机器学习社区，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_25" class="kx_ref">[25]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_13" class="kx_ref">[13]</a></sup>伊戈尔·艾森堡和他的同事于2000年在布尔阈值神经元的背景下引入人工神经网络。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_26" class="kx_ref">[26]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_27" class="kx_ref">[27]</a></sup> </p>
<p>Alexey Ivakhnenko和帕拉在1965年发表了第一个用于监督的、深度的、前馈的多层感知器的通用工作学习算法。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_28" class="kx_ref">[28]</a></sup>1971年的一篇论文描述了一个由数据处理算法的分组方法训练的8层深度网络。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_29" class="kx_ref">[29]</a></sup> </p>
<p>其他深度学习工作架构，特别是那些为计算机视觉而构建的架构，始于1980年由福岛国彦引入的神经认知机。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_30" class="kx_ref">[30]</a></sup>1989年，扬·勒丘恩等人对深度神经网络应用了标准的反向传播算法，这种算法自1970年以来一直是自动微分的反向模式，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_31" class="kx_ref">[31]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_32" class="kx_ref">[32]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_33" class="kx_ref">[33]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_34" class="kx_ref">[34]</a></sup>目的是识别邮件上手写的邮政编码。算法工作需要3天的训练。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_35" class="kx_ref">[35]</a></sup> </p>
<p>到1991年，这种系统被用于识别孤立的二维手写数字，而识别三维物体是通过将二维图像与手工制作的三维物体模型相匹配来完成的。翁等人提出人脑并不使用单一的三维对象模型，1992年，他们发表了Cresceptron，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_36" class="kx_ref">[36]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_37" class="kx_ref">[37]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_38" class="kx_ref">[38]</a></sup>一种在复杂场景中进行三维物体识别的方法。因为它直接使用自然图像，Cresceptron开启了自然3D世界的通用视觉学习。与神经认知机相似，Cresceptron是一多层的级联。但是，虽然神经认知机需要人类程序员手工合并特征，Cresceptron却在没有监督的情况下在每一层中学习了大量的特征，其中每个特征都由卷积核表示。Cresceptron通过网络进行反分析，从杂乱的场景中分割出每个学习对象。最大池化(Max pooling)现在经常被深度神经网络采用(例如图像网测试)，最早在Cresceptron中通过级联用来将位置分辨率降低(2x2)到1倍，以便更好地泛化。 </p>
<p>1994年，安德烈德·卡瓦略与迈克·法尔赫斯特和大卫·比塞特一起发表了多层布尔神经网络（也称为失重神经网络）的实验结果，该网络由三层自组织特征提取神经网络模块(SOFT)和多层分类神经网络模块（GSN）组成，并经过独立训练。特征提取模块中的每一层提取的特征与前一层相比更加复杂。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_39" class="kx_ref">[39]</a></sup> </p>
<p>1995年，布兰登·弗雷证明，使用由彼得·达扬和辛顿共同开发的唤醒睡眠算法，可以训练(超过两天)一个包含六个全连接的层和数百个隐藏单元的网络。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_40" class="kx_ref">[40]</a></sup>许多因素导致了速度的缓慢，包括Sepp Hochreiter在1991年分析的梯度消失问题。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_41" class="kx_ref">[41]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_42" class="kx_ref">[42]</a></sup> </p>
<p>由于人工神经网络的计算成本和对大脑如何连接生物网络缺乏理解，使用特定任务的手工特征（如Gabor滤波器和支持向量机）的简单模型在20世纪90年代和2000年代是一个流行的选择。 </p>
<p>人工神经网络的浅层和深度学习(如循环网络)经历了多年的探索。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_43" class="kx_ref">[43]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_44" class="kx_ref">[44]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_45" class="kx_ref">[45]</a></sup>这些方法从未优于非均匀内部手工高斯混合模型/隐马尔可夫模型（HMM）技术，它们基于区别训练的语音生成模型。包括梯度递减<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_41" class="kx_ref">[41]</a></sup>和神经预测模型中的弱时间相关结构在内的<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_46" class="kx_ref">[46]</a></sup>关键困难也已经得到分析。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_47" class="kx_ref">[47]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_48" class="kx_ref">[48]</a></sup>另外的困难是缺乏训练数据和有限的计算能力。 </p>
<p>大多数语音识别研究人员从神经网络转向了生成模型。一个例外是20世纪90年代末的斯坦福国际研究院（SRI International）。在美国国家安全局和美国国防部高级研究计划局的资助下，SRI研究了语音和说话人识别中的深度神经网络。Heck的说话人识别团队在1998年的国家标准与技术研究所说话人识别评估中，首次在语音处理中使用深度神经网络取得了重大成功。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_49" class="kx_ref">[49]</a></sup>虽然SRI在说话人识别中使用深度神经网络取得了成功，但在语音识别中却没有取得类似的成功。在20世纪90年代后期的“原始”谱图或线性滤波器组特征的深度自动编码器的架构中，首次成功地探索到将“原始”特征提升到手工优化之上的原理，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_49" class="kx_ref">[49]</a></sup>并表现出它优于包含光谱图固定变换阶段的Mel-Cepstral特征。语音、波形的原始特征后来产生了大规模卓越成果。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_50" class="kx_ref">[50]</a></sup> </p>
<p>语音识别的许多方面被一种叫做长短期记忆(LSTM)的深度学习方法所取代，这是一种由霍克雷特和施密休伯在1997年发表的循环神经网络。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_51" class="kx_ref">[51]</a></sup>LSTM神经网络避免了梯度消失问题，可以学习“非常深入学习”任务<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_2" class="kx_ref">[2]</a></sup>，这需要对之前发生的几千个离散时间步长的事件进行记忆，这对语音识别很重要。2003年，LSTM开始在某些特定任务上与传统的语音识别器竞争。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_52" class="kx_ref">[52]</a></sup>后来，它与联结主义时间分类(CTC)相结合<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_53" class="kx_ref">[53]</a></sup>为成堆的LSTM循环神经网络。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_54" class="kx_ref">[54]</a></sup> 据报道，在2015年，谷歌的语音识别通过CTC的LSTM产生了49%的惊人性能提升，并将它用于Google语音搜索。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_55" class="kx_ref">[55]</a></sup> </p>
<p>2006年，杰夫·辛顿、鲁斯兰·萨拉赫丁诺夫、奥辛德罗和特赫的出版物<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_56" class="kx_ref">[56]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_57" class="kx_ref">[57]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_58" class="kx_ref">[58]</a></sup>展示了多层前馈神经网络如何有效地一次预训练一层，依次将每层视为无监督的受限玻尔兹曼机，然后使用有监督的反向传播对其进行微调。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_59" class="kx_ref">[59]</a></sup>他们的论文参考了<i>《learning for deep belief nets》。</i> </p>
<p>深度学习是各学科最先进系统的一部分，特别是计算机视觉和自动语音识别(ASR)。TIMIT（ASR）和MNIST（图像分类）等常用评估集以及一系列大词汇量语音识别任务的结果都在稳步改善。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_60" class="kx_ref">[60]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_61" class="kx_ref">[61]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_62" class="kx_ref">[62]</a></sup>ASR中的卷积神经网络被CTC取代<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_53" class="kx_ref">[53]</a></sup>为LSTM。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_51" class="kx_ref">[51]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_55" class="kx_ref">[55]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_63" class="kx_ref">[63]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_64" class="kx_ref">[64]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_65" class="kx_ref">[65]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_66" class="kx_ref">[66]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_67" class="kx_ref">[67]</a></sup>但是在计算机视觉方面取得了更大成功。 </p>
<p>据扬·勒丘恩称，行业中深度学习的影响始于21世纪初，当时CNN已经处理了大约10%至20%的美国手写支票。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_68" class="kx_ref">[68]</a></sup>深度学习在大规模语音识别中的产业应用始于2010年左右。 </p>
<p>2009年NIPS语音识别深度学习大会<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_69" class="kx_ref">[69]</a></sup>的动机是深层语音生成模型的局限性，以及给定更强力的硬件和大规模数据集使得深层神经网络（DNN）变实用的可能性。人们认为，使用深层信念网络（DBN）的生成模型预先训练深度神经网络将克服神经网络的主要困难。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_70" class="kx_ref">[70]</a></sup>然而，当使用具有大的上下文相关输出层的深度神经网络时，发现用大量训练数据代替预训练用于直接反向传播，产生的错误率大大低于当时最先进的高斯混合模型(GMM)/隐马尔可夫模型(HMM)，也低于更先进的基于生成模型的系统。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_60" class="kx_ref">[60]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_71" class="kx_ref">[71]</a></sup>这两种系统产生的识别错误的性质是不同的，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_72" class="kx_ref">[72]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_69" class="kx_ref">[69]</a></sup>这为如何将深度学习集成到所有主要语音识别系统部署的现有高效运行语音解码系统中提供了技术见解。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_10" class="kx_ref">[10]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_73" class="kx_ref">[73]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_74" class="kx_ref">[74]</a></sup>2009-2010年左右的分析对比了GMM（和其他生成性语音模型）和DNN模型，刺激了早期产业对语音识别深度学习的投资，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_72" class="kx_ref">[72]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_69" class="kx_ref">[69]</a></sup>最终导致该行业的普遍和主导使用。这一分析是在判别性DNN和生成性模型之间进行的，他们具有相当的性能（错误率不到1.5%）。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_60" class="kx_ref">[60]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_72" class="kx_ref">[72]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_70" class="kx_ref">[70]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_75" class="kx_ref">[75]</a></sup> </p>
<p>2010年，研究人员基于决策树构造的上下文相关隐马尔可夫模型，采用DNN的大输出层，将TIMIT的深度学习扩展到大词汇量语音识别。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_76" class="kx_ref">[76]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_77" class="kx_ref">[77]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_78" class="kx_ref">[78]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_73" class="kx_ref">[73]</a></sup> </p>
<p>硬件的发展使人们重新燃起了兴趣。2009年，英伟达参与了所谓的深度学习“大爆炸”，因为深度学习神经网络是由英伟达图形处理单元(GPU)训练的。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_79" class="kx_ref">[79]</a></sup>那一年，谷歌大脑使用英伟达GPU创建了高性能深度神经网络。其中吴恩达确定GPU可以将深度学习系统的速度提高大约100倍。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_80" class="kx_ref">[80]</a></sup>具体而言，GPU非常适合机器学习中涉及的矩阵/向量数学。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_81" class="kx_ref">[81]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_82" class="kx_ref">[82]</a></sup>GPU能将训练算法的速度提高几个数量级，将运行时间从数周缩短到数天。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_83" class="kx_ref">[83]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_84" class="kx_ref">[84]</a></sup>专用硬件和算法优化可用于高效处理。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_85" class="kx_ref">[85]</a></sup> </p> 
<h3>4.1 <span>深度学习革命</span></h3> 
<p></p><p></p><div class="text_img ed_imgfloat_right">
            <a class="ed_image_link lazyLoad" data-src="https://img04.sogoucdn.com/app/a/200698/sogou_science_11667" data-bigsrc="" title="点击查看大图" href="javascript:" data-observer="true"></a>
            <div class="text_img_title">深度学习是机器学习的一个子集，机器学习是人工智能的子集</div>   
        </div> <p></p><p></p> 
<p>2012年，达尔领导的团队利用多任务深层神经网络预测一种药物的生物分子靶并以此赢得了“默克分子活性挑战”。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_86" class="kx_ref">[86]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_87" class="kx_ref">[87]</a></sup>2014年，霍克雷特的团队利用深度学习来检测营养素、家用产品和药物中环境化学品的脱靶和毒性效应，并赢得了美国国家卫生研究院、美国食品和药物管理局和NCATS的“Tox21数据挑战”。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_88" class="kx_ref">[88]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_89" class="kx_ref">[89]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_90" class="kx_ref">[90]</a></sup> </p>
<p>从2011年到2012年，深度学习在图像或物体识别方面产生了显著的额外影响。虽然通过反向传播训练的卷积神经网络已经出现了几十年，GPU实现的网络也已经出现了几年，包括卷积伸进网络，但要在计算机视觉上取得进展，还需要以Ciresan和同事的方式在GPU上实现最大池化的快速网络。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_81" class="kx_ref">[81]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_82" class="kx_ref">[82]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_35" class="kx_ref">[35]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_91" class="kx_ref">[91]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_2" class="kx_ref">[2]</a></sup>2011年，这种方法首次在视觉模式识别竞赛中实现了惊人的表现。同为2011年，它赢得了ICDAR中文手写比赛，并在2012年5月赢得了ISBI图像分割比赛。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_92" class="kx_ref">[92]</a></sup>直到2011年，卷积神经网络还没有在计算机视觉会议上大展拳脚，但在2012年6月，Ciresan等人在CVPR的主要会议上发表了一篇论文<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_4" class="kx_ref">[4]</a></sup>说明了如何在GPU上最大限度地汇集CNN可以显著改善许多视觉基准记录。2012年10月，克里兹夫斯基等人提出了一个类似的系统。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_5" class="kx_ref">[5]</a></sup>在大规模的图像网竞赛中以绝对优势战胜了浅层机器学习方法。2012年11月，西雷森等人的系统还在ICPR癌症检测大型医学图像分析竞赛中胜出，并在第二年赢得了同一主题的MICCAI大挑战。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_93" class="kx_ref">[93]</a></sup>在2013年和2014年，使用深度学习的图像网任务的错误率进一步降低，这与大规模语音识别的趋势相近。沃尔夫勒姆图像识别项目公布了这些改进。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_94" class="kx_ref">[94]</a></sup> </p>
<p>然后，图像分类被扩展到更具挑战性的任务，为图像生成描述（字幕），通常是由CNN和LSTM的组合进行。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_95" class="kx_ref">[95]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_96" class="kx_ref">[96]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_97" class="kx_ref">[97]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_98" class="kx_ref">[98]</a></sup> </p>
<p>一些研究人员估计，2012年10月图像网的胜利标志着一场“深度学习革命”的开始，这场革命改变了人工智能行业。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_99" class="kx_ref">[99]</a></sup> </p>
<p>2019年3月，约书亚·本希奥、杰弗里·辛顿和扬·勒丘恩因概念和工程突破而被授予图灵奖，这些突破使深度神经网络成为计算的关键组成部分。 </p></div></div><div id="par_14995109514838287"><h2 class="title">5 神经网络<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><h3>5.1 <span>人工神经网络</span></h3> 
<p>人工神经网络（ANN）或联结系统是由构成动物大脑的生物神经网络启发的计算系统。这种系统通过考虑示例来学习（逐步提高它们的能力）完成任务，通常不需要特定任务的编程。例如，在图像识别中，他们可以通过分析手动标记为“猫”或“没有猫”的示例图像，并使用分析结果来识别其他图像中的猫，从而学会识别包含猫的图像。它们大多数使用于很难用传统的基于规则编程的计算机算法来表达的应用。 </p>
<p>人工神经网络基于被称为人造神经元的连接单元的集合（类似于生物大脑中的生物神经元）。神经元之间的每个连接(突触)都可以向另一个神经元传递信号。接收（后突触）神经元可以处理信号，然后向与之相连的下游神经元发送信号。神经元可能有状态，通常用实数表示，一般在0和1之间。神经元和突触的权重也可能随着学习的进行而变化，这会增加或减少它向下游发送的信号的强度。 </p>
<p>通常，神经元是分层组织的。不同的层可以对它们的输入执行不同种类的转换。信号可能在多次穿过这些层之后从第一（输入）层传播到最后一个（输出）层。 </p>
<p>神经网络方法的起初目的是像人脑一样解决问题。随着时间的推移，重心集中在匹配特定的思维能力上，导致与生物学的偏差，例如反向传播，或者以相反的方向传递信息，并调整网络以反映这些信息。 </p>
<p>神经网络已经用于各种任务，包括计算机视觉、语音识别、机器翻译、社交网络过滤、棋盘和视频游戏以及医学诊断。 </p>
<p>截至2017年，神经网络通常有几千到几百万个单元和几百万个连接。尽管这个数字比人脑中的神经元数量少几个数量级，但这些网络可以在超出人类水平的水平上执行许多任务（例如，人脸识别，下围棋<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_100" class="kx_ref">[100]</a></sup> )。 </p> 
<h3>5.2 <span>深度神经网络</span></h3> 
<p>深度神经网络（DNN）是一个在输入层和输出层之间有多层的人工神经网络。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_11" class="kx_ref">[11]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_2" class="kx_ref">[2]</a></sup>DNN找到了将输入转化为输出的正确数学操作，无论是线性关系还是非线性关系。网络遍历各层并计算每个输出的概率。例如，被训练识别狗品种的DNN将检查给定的图像，并计算图像中的狗是某个品种的概率。用户可以查看结果并选择网络应显示的概率（高于某个阈值等）并返回建议的标签。每一个这样的数学操作都被认为是一个层，而复杂的DNN有许多层次，因此被称为“深度”网络。 </p>
<p>DNN可以模拟复杂的非线性关系。DNN架构生成组合模型，其中对象被表示为图元的分层组合。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_101" class="kx_ref">[101]</a></sup>额外的层使得能够从较低层合成特征，用比执行类似操作的浅层网络更少的单元来建模复杂数据。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_11" class="kx_ref">[11]</a></sup> </p>
<p>深层架构包括一些基本方法的许多变体。每个架构都在特定领域取得了成功。除非对相同的数据集进行了评估，否则不可能总能比较多个体系结构的性能。 </p>
<p>DNN是一种典型的前馈网络，数据从输入层流向输出层而不返回。首先，DNN创建了一个虚拟神经元的映射，并为它们之间的联系分配随机数值或者说“权重”。权重和输入相乘，返回0到1之间的输出。如果网络不能准确识别特定模式，算法会调整权重。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_102" class="kx_ref">[102]</a></sup>这样，算法可以使某些参数更有影响力，直到它确定正确的数学操作来完全处理数据。 </p>
<p>循环神经网络（RNN）中数据可以向任何方向流动，用于诸如语言建模的应用。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_103" class="kx_ref">[103]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_104" class="kx_ref">[104]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_105" class="kx_ref">[105]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_106" class="kx_ref">[106]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_107" class="kx_ref">[107]</a></sup>长短期记忆在这方面特别有效。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_51" class="kx_ref">[51]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_108" class="kx_ref">[108]</a></sup> </p>
<p>深度卷积神经网络用于计算机视觉。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_109" class="kx_ref">[109]</a></sup> CNN也被用于自动语音识别（ASR）的声学建模。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_67" class="kx_ref">[67]</a></sup> </p> 
<p><strong>挑战</strong></p> 
<p>与人工神经网络一样，训练不完善的深度神经网络中可能会出现许多问题。两个常见的问题是过拟合和计算时间。 </p>
<p>DNN倾向于过拟合，因为增加了抽象层，允许它们对训练数据中罕见的依赖关系建模。正则化方法如Ivakhnenko的单元剪枝<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_29" class="kx_ref">[29]</a></sup>或者权重衰减（<span class="kx_formula" alt="{\displaystyle \ell _{2}}">
  <svg xmlns:xlink="http://www.w3.org/1999/xlink" style="fill-opacity:1; color-rendering:auto; color-interpolation:auto; text-rendering:auto; stroke:black; stroke-linecap:square; stroke-miterlimit:10; shape-rendering:auto; stroke-opacity:1; fill:black; stroke-dasharray:none; font-weight:normal; stroke-width:1; font-family:&#39;Dialog&#39;; font-style:normal; stroke-linejoin:miter; font-size:12px; stroke-dashoffset:0; image-rendering:auto;" width="16" height="23" xmlns="http://www.w3.org/2000/svg" class="transfer_formula">
   <!--Generated by the Batik Graphics2D SVG Generator-->
   <defs id="genericDefs"></defs>
   <g>
    <g transform="scale(20,20) translate(0,0.8444)" style="font-size:1px; text-rendering:geometricPrecision; color-rendering:optimizeQuality; image-rendering:optimizeQuality; font-family:&#39;jlm_cmmi10&#39;; color-interpolation:linearRGB;">
     <path style="stroke:none;" d="M0.0156 -0.0938 L0.0156 -0.0938 L0.0938 -0.1719 Q0.0938 -0.3438 0.1719 -0.5156 Q0.2188 -0.6406 0.2812 -0.6875 Q0.3125 -0.7031 0.3438 -0.7031 Q0.3906 -0.7031 0.3906 -0.625 Q0.3906 -0.4688 0.2188 -0.2812 Q0.2031 -0.25 0.1719 -0.2188 Q0.1562 -0.2031 0.1562 -0.2031 Q0.1406 -0.1875 0.1406 -0.1406 Q0.1406 -0.0156 0.2031 -0.0156 Q0.2656 -0.0156 0.3438 -0.0938 Q0.3438 -0.0938 0.3594 -0.0938 Q0.3594 -0.0938 0.3594 -0.0781 Q0.3594 -0.0781 0.3125 -0.0312 L0.3125 -0.0312 Q0.3125 -0.0312 0.2969 -0.0312 Q0.25 0.0156 0.2031 0.0156 Q0.1094 0.0156 0.0938 -0.1406 Q0.0781 -0.125 0.0625 -0.1094 Q0.0312 -0.0781 0.0156 -0.0781 Q0.0156 -0.0781 0.0156 -0.0938 Q0.0156 -0.0938 0.0156 -0.0938 ZM0.1562 -0.2344 Q0.375 -0.4688 0.375 -0.625 Q0.375 -0.6875 0.3438 -0.6875 Q0.3125 -0.6875 0.2812 -0.625 L0.2812 -0.625 L0.2656 -0.5938 Q0.2031 -0.4688 0.1562 -0.25 L0.1562 -0.25 Q0.1562 -0.2344 0.1562 -0.2344 Z"></path>
    </g>
    <g transform="matrix(20,0,0,20,0,0) translate(0.4167,0.9944) scale(0.07,0.07)" style="font-size:1px; text-rendering:geometricPrecision; color-rendering:optimizeQuality; image-rendering:optimizeQuality; font-family:&#39;jlm_cmmi10&#39;; color-interpolation:linearRGB;">
     <path style="stroke:none;" d="M4.5781 -1.2812 L4.125 0 L0.2188 0 L0.2188 -0.1875 Q1.9375 -1.75 2.6406 -2.75 Q3.3438 -3.75 3.3438 -4.5781 Q3.3438 -5.2031 2.9609 -5.6094 Q2.5781 -6.0156 2.0312 -6.0156 Q1.5469 -6.0156 1.1562 -5.7266 Q0.7656 -5.4375 0.5938 -4.8906 L0.4062 -4.8906 Q0.5312 -5.7969 1.0312 -6.2812 Q1.5312 -6.7656 2.2969 -6.7656 Q3.0938 -6.7656 3.6406 -6.2422 Q4.1875 -5.7188 4.1875 -5.0156 Q4.1875 -4.5156 3.9531 -4.0156 Q3.5781 -3.2188 2.7812 -2.3438 Q1.5625 -1.0156 1.25 -0.7344 L2.9844 -0.7344 Q3.5156 -0.7344 3.7266 -0.7734 Q3.9375 -0.8125 4.1094 -0.9375 Q4.2812 -1.0625 4.4062 -1.2812 L4.5781 -1.2812 Z"></path>
    </g>
   </g>
  </svg>&nbsp;</span>-正则化）或稀疏化（<span class="kx_formula" alt="{\displaystyle \ell _{1}}">
  <svg xmlns:xlink="http://www.w3.org/1999/xlink" style="fill-opacity:1; color-rendering:auto; color-interpolation:auto; text-rendering:auto; stroke:black; stroke-linecap:square; stroke-miterlimit:10; shape-rendering:auto; stroke-opacity:1; fill:black; stroke-dasharray:none; font-weight:normal; stroke-width:1; font-family:&#39;Dialog&#39;; font-style:normal; stroke-linejoin:miter; font-size:12px; stroke-dashoffset:0; image-rendering:auto;" width="15" height="23" xmlns="http://www.w3.org/2000/svg" class="transfer_formula">
   <!--Generated by the Batik Graphics2D SVG Generator-->
   <defs id="genericDefs"></defs>
   <g>
    <g transform="scale(20,20) translate(0,0.8444)" style="font-size:1px; text-rendering:geometricPrecision; color-rendering:optimizeQuality; image-rendering:optimizeQuality; font-family:&#39;jlm_cmmi10&#39;; color-interpolation:linearRGB;">
     <path style="stroke:none;" d="M0.0156 -0.0938 L0.0156 -0.0938 L0.0938 -0.1719 Q0.0938 -0.3438 0.1719 -0.5156 Q0.2188 -0.6406 0.2812 -0.6875 Q0.3125 -0.7031 0.3438 -0.7031 Q0.3906 -0.7031 0.3906 -0.625 Q0.3906 -0.4688 0.2188 -0.2812 Q0.2031 -0.25 0.1719 -0.2188 Q0.1562 -0.2031 0.1562 -0.2031 Q0.1406 -0.1875 0.1406 -0.1406 Q0.1406 -0.0156 0.2031 -0.0156 Q0.2656 -0.0156 0.3438 -0.0938 Q0.3438 -0.0938 0.3594 -0.0938 Q0.3594 -0.0938 0.3594 -0.0781 Q0.3594 -0.0781 0.3125 -0.0312 L0.3125 -0.0312 Q0.3125 -0.0312 0.2969 -0.0312 Q0.25 0.0156 0.2031 0.0156 Q0.1094 0.0156 0.0938 -0.1406 Q0.0781 -0.125 0.0625 -0.1094 Q0.0312 -0.0781 0.0156 -0.0781 Q0.0156 -0.0781 0.0156 -0.0938 Q0.0156 -0.0938 0.0156 -0.0938 ZM0.1562 -0.2344 Q0.375 -0.4688 0.375 -0.625 Q0.375 -0.6875 0.3438 -0.6875 Q0.3125 -0.6875 0.2812 -0.625 L0.2812 -0.625 L0.2656 -0.5938 Q0.2031 -0.4688 0.1562 -0.25 L0.1562 -0.25 Q0.1562 -0.2344 0.1562 -0.2344 Z"></path>
    </g>
    <g transform="matrix(20,0,0,20,0,0) translate(0.4167,0.9944) scale(0.07,0.07)" style="font-size:1px; text-rendering:geometricPrecision; color-rendering:optimizeQuality; image-rendering:optimizeQuality; font-family:&#39;jlm_cmmi10&#39;; color-interpolation:linearRGB;">
     <path style="stroke:none;" d="M1.1719 -5.9688 L2.7812 -6.7656 L2.9375 -6.7656 L2.9375 -1.1719 Q2.9375 -0.6094 2.9844 -0.4766 Q3.0312 -0.3438 3.1797 -0.2656 Q3.3281 -0.1875 3.7812 -0.1875 L3.7812 0 L1.2969 0 L1.2969 -0.1875 Q1.7656 -0.1875 1.8984 -0.2578 Q2.0312 -0.3281 2.0859 -0.4531 Q2.1406 -0.5781 2.1406 -1.1719 L2.1406 -4.7344 Q2.1406 -5.4688 2.0938 -5.6719 Q2.0625 -5.8281 1.9688 -5.8984 Q1.875 -5.9688 1.75 -5.9688 Q1.5625 -5.9688 1.25 -5.8281 L1.1719 -5.9688 Z"></path>
    </g>
   </g>
  </svg>&nbsp;</span>正规化）可以在避免过拟合的训练中使用。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_110" class="kx_ref">[110]</a></sup>另外，在训练过程中，dropout正则化会随机省略隐藏层中的单元。这有助于排除罕见的依赖性。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_111" class="kx_ref">[111]</a></sup>最后，可以通过剪枝和旋转等方法来增加数据，从而可以增加较小的训练集，以减少过拟合的机会。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_112" class="kx_ref">[112]</a></sup> </p>
<p>DNN必须考虑许多训练参数，例如大小（层数和每层单元数）、学习速率和初始权重。由于时间和计算资源的成本，在参数空间中搜索最优参数可能是不可行的。有各种技巧如批处理（一次计算几个训练示例的梯度，而不是单个示例）<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_113" class="kx_ref">[113]</a></sup>加速计算。多核架构（如GPU或英特尔Xeon Phi）的强大处理能力大大加快了训练速度，因为这种处理架构适合矩阵和向量计算。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_114" class="kx_ref">[114]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_115" class="kx_ref">[115]</a></sup> </p>
<p>另外，工程师可以寻找其他具有更直接和收敛的训练算法的神经网络。CMAC（小脑神经网络）就是这样一种神经网络。CMAC不需要学习率或随机初始权重。可以保证训练过程与新的一批数据一步收敛，并且训练算法的计算复杂度与涉及的神经元数量成线性关系。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_116" class="kx_ref">[116]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_117" class="kx_ref">[117]</a></sup> </p></div></div><div id="par_14995109514838288"><h2 class="title">6 应用<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><h3>6.1 <span>自动语音识别</span></h3> 
<p>大规模自动语音识别是深度学习的第一个也是最有说服力的成功案例。LSTM神经网络可以学习“非常深入学习”任务<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_2" class="kx_ref">[2]</a></sup>，这涉及包含由数千个离散时间步长分隔的语音事件的多秒间隔，其中一个时间步长对应约10ms。具有遗忘门的LSTM<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_108" class="kx_ref">[108]</a></sup>在特定任务上可以与传统的语音识别器相媲美。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_52" class="kx_ref">[52]</a></sup> </p>
<p>语音识别的最初成功是基于TIMIT的小规模识别任务。该数据集包含来自美国英语八种主要方言的630名说话者，每个说话者读10个句子。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_118" class="kx_ref">[118]</a></sup>它的小规模允许尝试许多配置。更重要的是，TIMIT任务涉及音素序列识别，这与单词序列识别不同，它允许弱音素二元语言模型。这使得语音识别的声学建模方面的强度更容易分析。以下列出的错误率，包括这些早期结果，以及以音素错误率百分比(PER)衡量的错误率，自1991年以来一直在汇总。 </p> 
<table class="wikitable"> 
 <tbody>
  <tr> 
   <th>方法</th> 
   <th>声音误差率（PER，%) </th>
  </tr> 
  <tr> 
   <td>随机初始化RNN<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_119" class="kx_ref">[119]</a></sup></td> 
   <td>26.1 </td>
  </tr> 
  <tr> 
   <td>贝叶斯三音子GMM-HMM</td> 
   <td>25.6 </td>
  </tr> 
  <tr> 
   <td>隐藏轨迹（生成）模型</td> 
   <td>24.8 </td>
  </tr> 
  <tr> 
   <td>单音子重复初始化DNN</td> 
   <td>23.4 </td>
  </tr> 
  <tr> 
   <td>单音子DBN-DNN</td> 
   <td>22.4 </td>
  </tr> 
  <tr> 
   <td>带BMMI训练的三音子GMM-HMM</td> 
   <td>21.7 </td>
  </tr> 
  <tr> 
   <td>共享池上的单音子DBN-DNN</td> 
   <td>20.7 </td>
  </tr> 
  <tr> 
   <td>卷积DNN<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_120" class="kx_ref">[120]</a></sup></td> 
   <td>20.0 </td>
  </tr> 
  <tr> 
   <td>卷积DNN w。异构池</td> 
   <td>18.7 </td>
  </tr> 
  <tr> 
   <td>DNN / CNN / RNN合奏<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_121" class="kx_ref">[121]</a></sup></td> 
   <td>18.3 </td>
  </tr> 
  <tr> 
   <td>双向LSTM</td> 
   <td>17.9 </td>
  </tr> 
  <tr> 
   <td>分层卷积深度超出网络<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_122" class="kx_ref">[122]</a></sup></td> 
   <td>16.5 </td>
  </tr>
 </tbody>
</table> 
<p>20世纪90年代末首次出现用于说话人识别的深度神经网络，2009-2011年前后首次出现用于语音识别的深度神经网络，2003-2007年前后首次出现用于LSTM的深度神经网络，加速了八个主要领域的进展:<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_10" class="kx_ref">[10]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_75" class="kx_ref">[75]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_73" class="kx_ref">[73]</a></sup> </p> 
<ul>
 <li>放大/缩小和加速DNN训练和解码</li> 
 <li>序列辨别训练</li> 
 <li>通过对潜在机制有深刻理解的深层模型进行特征处理</li> 
 <li>DNN和相关深度模型的适应</li> 
 <li>基于DnS和相关深层模型的多任务迁移学习</li> 
 <li>卷积神经网络以及如何设计它们来最好地利用语音领域知识</li> 
 <li>RNN及其丰富的LSTM变体</li> 
 <li>其他类型的深层模型包括基于张量的模型和集成的深层生成/判别模型。</li>
</ul> 
<p>所有主要的商业语音识别系统（如微软小娜、Xbox、Skype翻译器、亚马逊Alexa、Google Now、苹果Siri、百度和iFlyTek语音搜索，以及一系列Nuance语音产品等）都建立在深度学习的基础上。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_10" class="kx_ref">[10]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_123" class="kx_ref">[123]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_124" class="kx_ref">[124]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_125" class="kx_ref">[125]</a></sup> </p> 
<h3>6.2 <span>图像识别</span></h3> 
<p>图像分类的常用评估集是MNIST数据库数据集。MNIST由手写数字组成，包括60000个训练示例和10000个测试示例。和TIMIT一样，它的小尺寸让用户可以测试多种配置。这个集合的完整结果列表是可获得的。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_126" class="kx_ref">[126]</a></sup> </p>
<p>基于深度学习的图像识别已经成为“超人”，可以获得比人类参赛者更准确的结果。这首次出现在2011年。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_127" class="kx_ref">[127]</a></sup> </p>
<p>经过深度学习训练的车辆现在可以理解360度摄像头的视角。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_128" class="kx_ref">[128]</a></sup>另一个例子是面部畸形分析（FDNA），用于分析与一个大型遗传综合征数据库相关的人类畸形病例。 </p> 
<h3>6.3 <span>视觉艺术处理</span></h3> 
<p>与图像识别取得的进展密切相关的是深度学习技术在各种视觉艺术任务中的日益应用。DNN的强大能力已经得到证明，例如，a）识别给定绘画的风格周期，b）神经风格迁移-捕捉给定艺术品的风格，并以愉悦视觉方式将其应用于任意照片或视频，以及c）基于随机视觉输入字段生成醒目的图像。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_129" class="kx_ref">[129]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_130" class="kx_ref">[130]</a></sup> </p> 
<h3>6.4 <span>自然语言处理</span></h3> 
<p>自21世纪初以来，神经网络就被用于实现语言模型。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_103" class="kx_ref">[103]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_131" class="kx_ref">[131]</a></sup>LSTM帮助改进了机器翻译和语言建模。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_104" class="kx_ref">[104]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_105" class="kx_ref">[105]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_106" class="kx_ref">[106]</a></sup> </p>
<p>该领域的其他关键技术是负采样<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_132" class="kx_ref">[132]</a></sup>和单词嵌入。词嵌入如<i>word2vec</i>，可以被认为是深度学习体系结构中的表示层，该体系结构将原子单词转换为该单词相对于数据集中其他单词的位置表示；该位置表示为向量空间中的一个点。使用单词嵌入作为RNN输入层允许网络使用有效的合成向量语法来解析句子和短语。成分向量语法可以被认为是由RNN实现的概率上下文无关文法（PCFG）。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_133" class="kx_ref">[133]</a></sup>建立在单词嵌入之上的递归自动编码器可以评估句子相似性并检测语义。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_133" class="kx_ref">[133]</a></sup>深层神经架构为选区分析，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_134" class="kx_ref">[134]</a></sup>情绪分析，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_135" class="kx_ref">[135]</a></sup>信息检索，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_136" class="kx_ref">[136]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_137" class="kx_ref">[137]</a></sup>口语理解，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_138" class="kx_ref">[138]</a></sup>机器翻译，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_104" class="kx_ref">[104]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_139" class="kx_ref">[139]</a></sup>上下文实体链接，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_139" class="kx_ref">[139]</a></sup>写作风格识别，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_140" class="kx_ref">[140]</a></sup>文本分类等<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_141" class="kx_ref">[141]</a></sup>提供了最佳结果。 </p>
<p>最近的发展将单词嵌入推广到句子嵌入。 </p>
<p>谷歌翻译使用大型端到端长短期记忆网络。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_142" class="kx_ref">[142]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_143" class="kx_ref">[143]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_144" class="kx_ref">[144]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_145" class="kx_ref">[145]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_146" class="kx_ref">[146]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_147" class="kx_ref">[147]</a></sup>Google神经机器翻译系统（GNMT）使用基于实例的机器翻译方法，其中系统“从数百万个实例中学习”<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_143" class="kx_ref">[143]</a></sup>它一次翻译“整个句子，而非片段”。谷歌翻译支持一百多种语言。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_143" class="kx_ref">[143]</a></sup>网络对“句子的语义，而非简单地记忆短语的翻译”进行编码。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_143" class="kx_ref">[143]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_148" class="kx_ref">[148]</a></sup>GT使用英语作为大多数语言对之间的中间语言。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_148" class="kx_ref">[148]</a></sup> </p> 
<h3>6.5 <span>药物发现和毒理学</span></h3> 
<p>很大一部分候选药物未能获得监管部门的批准。这些失败是由功效不足（靶点效应）、意料之外的相互作用（脱靶效应）或意外的毒性效应引起的。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_149" class="kx_ref">[149]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_150" class="kx_ref">[150]</a></sup>研究已经探索了使用深度学习来预测生物分子目标，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_86" class="kx_ref">[86]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_87" class="kx_ref">[87]</a></sup>营养物、家用产品和药物中环境化学物质的脱靶和毒性影响。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_88" class="kx_ref">[88]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_89" class="kx_ref">[89]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_90" class="kx_ref">[90]</a></sup> </p>
<p>AtomNet是一个基于结构的合理药物设计的深度学习系统。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_151" class="kx_ref">[151]</a></sup>AtomNet用于预测埃博拉病毒等疾病靶标的新候选生物分子<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_152" class="kx_ref">[152]</a></sup>和多发性硬化症。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_153" class="kx_ref">[153]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_154" class="kx_ref">[154]</a></sup> </p> 
<h3>6.6 <span>客户关系管理</span></h3> 
<p>深度强化学习已被用于估算可能的直销活动的价值，这是根据RFM变量定义的。估计价值函数显示为客户终身价值的自然解释。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_155" class="kx_ref">[155]</a></sup> </p> 
<h3>6.7 <span>推荐系统</span></h3> 
<p>推荐系统已经使用深度学习为基于内容的音乐推荐提取潜在因素模型的有意义的特征。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_156" class="kx_ref">[156]</a></sup>多视角深度学习已经应用于从多个领域学习用户偏好。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_157" class="kx_ref">[157]</a></sup>该模型使用了一种基于内容和协作的混合方法，并在多个任务中增强推荐。 </p> 
<h3>6.8 <span>生物信息学</span></h3> 
<p>自动编码器人工神经网络用于生物信息学，预测基因本体注释和基因功能关系。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_158" class="kx_ref">[158]</a></sup> </p>
<p>在医学信息学中，深度学习被用来根据可穿戴设备的数据预测睡眠质量<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_159" class="kx_ref">[159]</a></sup>以及根据电子健康记录数据对健康并发症进行预测。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_160" class="kx_ref">[160]</a></sup>深度学习也显示出医疗保健的功效。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_161" class="kx_ref">[161]</a></sup> </p> 
<h3>6.9 <span>医学图像分析</span></h3> 
<p>深度学习在医学应用例如癌细胞分类、病变检测、器官分割和图像增强<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_162" class="kx_ref">[162]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_163" class="kx_ref">[163]</a></sup>中产生的结果已经与其他方法相当。 </p> 
<h3>6.10 <span>手机广告</span></h3> 
<p>为移动广告寻找合适的移动受众总是具有挑战性的，因为在任何广告服务器创建并在广告服务中使用目标片段之前，必须考虑和吸收许多数据点。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_164" class="kx_ref">[164]</a></sup>深度学习已经被用于解释大的、多维的广告数据集。许多数据点是在请求/服务/点击互联网广告周期中收集的。这些信息可以形成机器学习的基础数据，以改进广告的选择。 </p> 
<h3>6.11 <span>图像恢复</span></h3> 
<p>深度学习已成功应用于反问题，如去噪、超分辨率、修复和胶片着色。这些应用包括学习方法如在图像数据集上进行训练的“有效图像恢复的收缩字段”<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_165" class="kx_ref">[165]</a></sup>方法和训练需要恢复的图像的深度图像先验方法。 </p> 
<h3>6.12 <span>金融欺诈检测</span></h3> 
<p>深度学习正成功应用于金融欺诈检测和反洗钱。“深度反洗钱检测系统可以发现和识别数据之间的关系和相似性，并在未来学习检测异常或分类和预测特定事件”。该解决方案利用监督学习（如可疑交易的分类）和非监督学习（如异常检测）技术。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_166" class="kx_ref">[166]</a></sup> </p> 
<h3>6.13 <span>军队</span></h3> 
<p>美国国防部通过观察应用深度学习来训练机器人完成新任务。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_167" class="kx_ref">[167]</a></sup> </p></div></div><div id="par_14995109531615498"><h2 class="title">7 与人类认知和大脑发育的关系<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>深度学习与认知神经科学家在20世纪90年代早期提出的一类大脑发育理论（特别是新皮质发育）密切相关。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_168" class="kx_ref">[168]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_169" class="kx_ref">[169]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_170" class="kx_ref">[170]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_171" class="kx_ref">[171]</a></sup>这些发展理论在计算模型中被实例化，使它们成为深度学习系统的前身。这些发展模型的共同特点是，大脑中各种提议的学习动力学（例如，神经生长因子波）支持自组织，这在某种程度上类似于深度学习模型中使用的神经网络。与新皮质一样，神经网络采用分层过滤器的层次结构，其中每一层考虑来自前一层（或操作环境）的信息，然后将其输出（可能还含有原始输入）传递给其他层。这一过程产生了一个自组织的传感器堆栈，可以很好地适应它们的工作环境。一份1995年的描述指出，“...婴儿的大脑似乎在所谓营养因子波的影响下自我组织...大脑的不同区域依次相连，一层组织先于另一层成熟，依此类推，直到整个大脑成熟。”<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_172" class="kx_ref">[172]</a></sup> </p>
<p>从神经生物学的角度研究深度学习模型的合理性已经使用了各种各样的方法。一方面，为了提高反向传播算法的处理真实感提出了几种反向传播算法的变体。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_173" class="kx_ref">[173]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_174" class="kx_ref">[174]</a></sup>其他研究人员认为，无监督形式的深度学习，例如基于层次生成模型和深度信念网络的学习，可能更接近生物现实。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_175" class="kx_ref">[175]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_176" class="kx_ref">[176]</a></sup>在这方面，生成性神经网络模型已经与大脑皮层中基于样本的处理的神经生物学证据相关联。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_177" class="kx_ref">[177]</a></sup> </p>
<p>虽然人类大脑组织和深度网络中神经元编码之间的系统比较尚未建立，但报告中已有几个类比。例如，深度学习单元执行的计算可能类似于实际神经元的计算<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_178" class="kx_ref">[178]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_179" class="kx_ref">[179]</a></sup>和神经群。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_180" class="kx_ref">[180]</a></sup>类似地，由深度学习模型开发的表示类似于灵长类视觉系统<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_181" class="kx_ref">[181]</a></sup>在单一单元<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_182" class="kx_ref">[182]</a></sup>和在种群<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_183" class="kx_ref">[183]</a></sup>等级上测量的表示。 </p></div></div><div id="par_14995109548392712"><h2 class="title">8 商业活动<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>许多组织对特定的应用采用深度学习。脸书的人工智能实验室进行了一些任务如自动给上传的图片贴上标签，上面有人物的名字。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_184" class="kx_ref">[184]</a></sup> </p>
<p>谷歌的DeepMind科技公司开发了一个系统，它能够学习如何只用像素作为数据输入来玩雅达利电子游戏。2015年，他们展示了他们的AlphaGo系统，该系统下围棋的能力足以击败职业围棋选手。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_185" class="kx_ref">[185]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_186" class="kx_ref">[186]</a></sup><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_187" class="kx_ref">[187]</a></sup>谷歌翻译使用LSTM翻译100多种语言。 </p>
<p>2015年，Blippar展示了一个移动增强现实应用，它使用深度学习实时识别物体。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_188" class="kx_ref">[188]</a></sup> </p>
<p>截至2008年，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_189" class="kx_ref">[189]</a></sup>德克萨斯大学奥斯汀分校（UT）的研究人员开发了一个名为“通过评估强化手动训练代理”的机器学习框架，该框架为机器人或计算机程序提供了通过与人类教师交互来学习如何执行任务的新方法。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_167" class="kx_ref">[167]</a></sup> </p>
<p>最初作为TAMER开发、后来在2018年美国陆军研究实验室（ARL）和UT研究人员的合作中引入了一种称为Deep TAMER的新算法。Deep TAMER使用深度学习为机器人提供通过观察学习新任务的能力。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_167" class="kx_ref">[167]</a></sup> </p>
<p>使用Deep TAMER，机器人与人类教练一起学习任务，观看视频流或观察人类亲自执行任务。机器人后来在教练的指导下练习了这项任务，教练在这个过程中提供了“做得好”和“做得不好”等反馈<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_190" class="kx_ref">[190]</a></sup>。 </p></div></div><div id="par_14995109565169923"><h2 class="title">9 批判和议论<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>深度学习吸引了批判和评论，在某些情况下来自计算机科学领域之外。 </p> 
<h3>9.1 <span>理论</span></h3> 
<p>一个主要的批评是缺乏围绕某些方法的理论。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_191" class="kx_ref">[191]</a></sup>在最常见的深层架构中的学习是使用众所周知的梯度下降来实现的。然而，围绕其他算法的理论，如对比散度算法，则不太清楚。（例如，它会收敛吗？如果是，有多快？它近似于何值？)深度学习方法通常被视为一个黑盒，大多数证实是凭经验进行的，而不是理论上的。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_192" class="kx_ref">[192]</a></sup> </p>
<p> 其他人指出，深度学习应该被视为实现强人工智能的一个步骤，而不是一个包罗万象的解决方案。尽管有深度学习方法的力量，但它们仍然缺乏完全实现这一目标所需的许多功能。研究心理学家加里·马库斯指出:</p>
<p>“事实上，深度学习只是构建智能机的更大挑战的一部分。这些技术缺乏表述因果关系的方式（……）没有显式的方法进行逻辑推理，而且它们距整合抽象知识还有很长的路要走，例如关于什么是对象、它们的用途和它们通常如何使用。最强大的人工智能系统如Watson（……）将深度学习等技术作为相当复杂的技术集合中的一个元素，涉及从贝叶斯推理的统计技术到演绎推理。”<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_193" class="kx_ref">[193]</a></sup></p>
<p>作为对深度学习极限的重点的可选项，一位作者推测，训练机器视觉堆栈来执行区分“老主人”和业余人物的绘图的复杂任务是可能的，并且假设这样的灵敏度可能代表了不平凡的机器共感的雏形。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_194" class="kx_ref">[194]</a></sup>这位作者提出，这与人类学是一致的，人类学将美学视为行为现代性的一个关键要素。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_195" class="kx_ref">[195]</a></sup> </p>
<p>在进一步提到艺术敏感性可能存在于相对较低的认知层次的观点时，一系列已发表的深层（20-30层）神经网络内部状态图表示试图在本质上是随机的数据中辨别它们所训练的图像<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_196" class="kx_ref">[196]</a></sup>中展现出了视觉吸引力：最初的研究通知收到了超过1000条评论，并且是<i>《卫报》</i><sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_197" class="kx_ref">[197]</a></sup>网站上一段时间内最常被访问的文章主题。 </p> 
<h3>9.2 <span>错误</span></h3> 
<p>一些深度学习架构显现出了有问题的行为，<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_198" class="kx_ref">[198]</a></sup>例如自信地将不可识别的图像分类为属于熟悉的普通图像类别<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_199" class="kx_ref">[199]</a></sup>以及对正确分类图像的微小扰动进行错误分类。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_200" class="kx_ref">[200]</a></sup>戈泽尔假设，这些行为是由于其内部表现的限制，这些限制将抑制集成到异构多组件通用人工智能（AGI）架构。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_198" class="kx_ref">[198]</a></sup>这些问题可以通过深度学习架构来解决，这种架构内部形成与观察到的实体和事件的图像-语法分解同源的状态<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_201" class="kx_ref">[201]</a></sup>。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_198" class="kx_ref">[198]</a></sup>从训练数据中学习语法（视觉或语言的）相当于将系统限制在常识推理上，常识推理根据语法产生规则对概念进行操作，并且是人类语言习得和人工智能的基本目标<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_202" class="kx_ref">[202]</a></sup>。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_203" class="kx_ref">[203]</a></sup> </p> 
<h3>9.3 <span>网络威胁</span></h3> 
<p>随着深度学习从实验室走向世界，研究和经验表明，人工神经网络容易被黑客攻击和欺骗。通过识别这些系统运行的模式，攻击者可以修改人工神经网络的输入，使得人工神经网络找到人类观察者无法识别的匹配对象。例如，攻击者可以对图像进行细微的更改，使得人工神经网络能够找到匹配的图像，即使该图像在人类看来与搜索目标完全不同。这种操纵被称为“对抗性攻击”。2016年，研究人员使用一个人工神经网络以反复试验的方式对图像进行修改，识别另一个人工神经网络的焦点，从而生成欺骗它的图像。修改后的图像在人眼看来没有什么不同。另一组显示，打印出的篡改图像成功地欺骗了图像分类系统。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_204" class="kx_ref">[204]</a></sup>一种防御方式是反向图像搜索，其中一个可能的假图像被提交到一个网站，如TinEye，然后可以找到它的其他实例。一种改进是只使用图像的一部分进行搜索，以识别可能拍摄到的图像。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_205" class="kx_ref">[205]</a></sup> </p>
<p>另一组研究表明，某些迷惑现象可以愚弄面部识别系统，使其认为普通人是名人，这可能会让一个人冒充另一个人。2017年，研究人员在停车标志上添加了标签，导致人工神经网络对它们进行了错误分类。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_204" class="kx_ref">[204]</a></sup> </p>
<p>然而，人工神经网络可以被进一步训练以检测欺骗意图，潜在地导致攻击者和防御者进入类似于一个已经定义恶意软件防御行业的军备竞赛。人工神经网络已经被训练来击败基于人工神经网络的反恶意软件，通过反复攻击反恶意软件的防御，该网络被遗传算法不断地改变，直到它成功欺骗了反恶意软件，同时保持其破坏目标的能力。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_204" class="kx_ref">[204]</a></sup> </p>
<p>另一个小组证明了某些声音可以让Google即时语音指挥系统打开一个特定的网址来下载恶意软件。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_204" class="kx_ref">[204]</a></sup> </p>
<p>在“数据中毒”中，错误数据不断地被偷放入机器学习系统的训练集中，以防止它掌握这个模型。<sup><a href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/d10438.htm#quote_204" class="kx_ref">[204]</a></sup> </p></div></div></div></div><div id="references"><h2 class="title" id="par_references">参考文献</h2><ul class="references"><li id="quote_1"><span class="references-num">[1]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Bengio, Y.; Courville, A.; Vincent, P. (2013). "Representation Learning: A Review and New Perspectives". IEEE Transactions on Pattern Analysis and Machine Intelligence. 35 (8): 1798–1828. arXiv:1206.5538. doi:10.1109/tpami.2013.50. PMID 23787338..</span></p></li><li id="quote_2"><span class="references-num">[2]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Schmidhuber, J. (2015). "Deep Learning in Neural Networks: An Overview". Neural Networks. 61: 85–117. arXiv:1404.7828. doi:10.1016/j.neunet.2014.09.003. PMID 25462637..</span></p></li><li id="quote_3"><span class="references-num">[3]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Bengio, Yoshua; LeCun, Yann; Hinton, Geoffrey (2015). "Deep Learning". Nature. 521 (7553): 436–444. Bibcode:2015Natur.521..436L. doi:10.1038/nature14539. PMID 26017442..</span></p></li><li id="quote_4"><span class="references-num">[4]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Ciresan, Dan; Meier, U.; Schmidhuber, J. (June 2012). "Multi-column deep neural networks for image classification". 2012 IEEE Conference on Computer Vision and Pattern Recognition: 3642–3649. arXiv:1202.2745. doi:10.1109/cvpr.2012.6248110. ISBN 978-1-4673-1228-8..</span></p></li><li id="quote_5"><span class="references-num">[5]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Krizhevsky, Alex; Sutskever, Ilya; Hinton, Geoffry (2012). "ImageNet Classification with Deep Convolutional Neural Networks" (PDF). NIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada..</span></p></li><li id="quote_6"><span class="references-num">[6]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Google's AlphaGo AI wins three-match series against the world's best Go player". TechCrunch. 25 May 2017..</span></p></li><li id="quote_7"><span class="references-num">[7]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Marblestone, Adam H.; Wayne, Greg; Kording, Konrad P. (2016). "Toward an Integration of Deep Learning and Neuroscience". Frontiers in Computational Neuroscience. 10: 94. doi:10.3389/fncom.2016.00094. PMC 5021692. PMID 27683554..</span></p></li><li id="quote_8"><span class="references-num">[8]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Olshausen, B. A. (1996). "Emergence of simple-cell receptive field properties by learning a sparse code for natural images". Nature. 381 (6583): 607–609. Bibcode:1996Natur.381..607O. doi:10.1038/381607a0. PMID 8637596..</span></p></li><li id="quote_9"><span class="references-num">[9]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Bengio, Yoshua; Lee, Dong-Hyun; Bornschein, Jorg; Mesnard, Thomas; Lin, Zhouhan (2015-02-13). "Towards Biologically Plausible Deep Learning". arXiv:1502.04156 [cs.LG]..</span></p></li><li id="quote_10"><span class="references-num">[10]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Deng, L.; Yu, D. (2014). "Deep Learning: Methods and Applications" (PDF). Foundations and Trends in Signal Processing. 7 (3–4): 1–199. doi:10.1561/2000000039..</span></p></li><li id="quote_11"><span class="references-num">[11]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Bengio, Yoshua (2009). "Learning Deep Architectures for AI" (PDF). Foundations and Trends in Machine Learning. 2 (1): 1–127. CiteSeerX 10.1.1.701.9550. doi:10.1561/2200000006..</span></p></li><li id="quote_12"><span class="references-num">[12]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">LeCun, Yann; Bengio, Yoshua; Hinton, Geoffrey (28 May 2015). "Deep learning". Nature. 521 (7553): 436–444. Bibcode:2015Natur.521..436L. doi:10.1038/nature14539. PMID 26017442..</span></p></li><li id="quote_13"><span class="references-num">[13]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Jürgen Schmidhuber (2015). Deep Learning. Scholarpedia, 10(11):32832. Online.</span></p></li><li id="quote_14"><span class="references-num">[14]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Hinton, G.E. (2009). "Deep belief networks". Scholarpedia. 4 (5): 5947. Bibcode:2009SchpJ...4.5947H. doi:10.4249/scholarpedia.5947..</span></p></li><li id="quote_15"><span class="references-num">[15]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Murphy, Kevin P. (24 August 2012). Machine Learning: A Probabilistic Perspective. MIT Press. ISBN 978-0-262-01802-9..</span></p></li><li id="quote_16"><span class="references-num">[16]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Patel, Ankit; Nguyen, Tan; Baraniuk, Richard (2016). "A Probabilistic Framework for Deep Learning" (PDF). Advances in Neural Information Processing Systems..</span></p></li><li id="quote_17"><span class="references-num">[17]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Balázs Csanád Csáji (2001). Approximation with Artificial Neural Networks; Faculty of Sciences; Eötvös Loránd University, Hungary.</span></p></li><li id="quote_18"><span class="references-num">[18]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Cybenko (1989). "Approximations by superpositions of sigmoidal functions" (PDF). Mathematics of Control, Signals, and Systems. 2 (4): 303–314. doi:10.1007/bf02551274. Archived from the original (PDF) on 2015-10-10..</span></p></li><li id="quote_19"><span class="references-num">[19]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Hornik, Kurt (1991). "Approximation Capabilities of Multilayer Feedforward Networks". Neural Networks. 4 (2): 251–257. doi:10.1016/0893-6080(91)90009-t..</span></p></li><li id="quote_20"><span class="references-num">[20]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Haykin, Simon S. (1999). Neural Networks: A Comprehensive Foundation. Prentice Hall. ISBN 978-0-13-273350-2..</span></p></li><li id="quote_21"><span class="references-num">[21]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Hassoun, Mohamad H. (1995). Fundamentals of Artificial Neural Networks. MIT Press. p. 48. ISBN 978-0-262-08239-6..</span></p></li><li id="quote_22"><span class="references-num">[22]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Lu, Z., Pu, H., Wang, F., Hu, Z., &amp; Wang, L. (2017). The Expressive Power of Neural Networks: A View from the Width. Neural Information Processing Systems, 6231-6239..</span></p></li><li id="quote_23"><span class="references-num">[23]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Hinton, G. E.; Srivastava, N.; Krizhevsky, A.; Sutskever, I.; Salakhutdinov, R.R. (2012). "Improving neural networks by preventing co-adaptation of feature detectors". arXiv:1207.0580 [math.LG]..</span></p></li><li id="quote_24"><span class="references-num">[24]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Bishop, Christopher M. (2006). Pattern Recognition and Machine Learning (PDF). Springer. ISBN 978-0-387-31073-2..</span></p></li><li id="quote_25"><span class="references-num">[25]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Rina Dechter (1986). Learning while searching in constraint-satisfaction problems. University of California, Computer Science Department, Cognitive Systems Laboratory.Online.</span></p></li><li id="quote_26"><span class="references-num">[26]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Igor Aizenberg, Naum N. Aizenberg, Joos P.L. Vandewalle (2000). Multi-Valued and Universal Binary Neurons: Theory, Learning and Applications. Springer Science &amp; Business Media..</span></p></li><li id="quote_27"><span class="references-num">[27]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Co-evolving recurrent neurons learn deep memory POMDPs. Proc. GECCO, Washington, D. C., pp. 1795-1802, ACM Press, New York, NY, USA, 2005..</span></p></li><li id="quote_28"><span class="references-num">[28]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Ivakhnenko, A. G. (1973). Cybernetic Predicting Devices. CCM Information Corporation..</span></p></li><li id="quote_29"><span class="references-num">[29]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Ivakhnenko, Alexey (1971). "Polynomial theory of complex systems". IEEE Transactions on Systems, Man and Cybernetics. 1 (4): 364–378. doi:10.1109/TSMC.1971.4308320..</span></p></li><li id="quote_30"><span class="references-num">[30]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Fukushima, K. (1980). "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position". Biol. Cybern. 36 (4): 193–202. doi:10.1007/bf00344251. PMID 7370364..</span></p></li><li id="quote_31"><span class="references-num">[31]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Seppo Linnainmaa (1970). The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors. Master's Thesis (in Finnish), Univ. Helsinki, 6-7..</span></p></li><li id="quote_32"><span class="references-num">[32]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Griewank, Andreas (2012). "Who Invented the Reverse Mode of Differentiation?" (PDF). Documenta Matematica (Extra Volume ISMP): 389–400..</span></p></li><li id="quote_33"><span class="references-num">[33]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Werbos, P. (1974). "Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences". Harvard University. Retrieved 12 June 2017..</span></p></li><li id="quote_34"><span class="references-num">[34]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Werbos, Paul (1982). "Applications of advances in nonlinear sensitivity analysis" (PDF). System modeling and optimization. Springer. pp. 762–770..</span></p></li><li id="quote_35"><span class="references-num">[35]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">LeCun et al., "Backpropagation Applied to Handwritten Zip Code Recognition," Neural Computation, 1, pp. 541–551, 1989..</span></p></li><li id="quote_36"><span class="references-num">[36]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">J. Weng, N. Ahuja and T. S. Huang, "Cresceptron: a self-organizing neural network which grows adaptively," Proc. International Joint Conference on Neural Networks, Baltimore, Maryland, vol I, pp. 576-581, June, 1992..</span></p></li><li id="quote_37"><span class="references-num">[37]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">J. Weng, N. Ahuja and T. S. Huang, "Learning recognition and segmentation of 3-D objects from 2-D images," Proc. 4th International Conf. Computer Vision, Berlin, Germany, pp. 121-128, May, 1993..</span></p></li><li id="quote_38"><span class="references-num">[38]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">J. Weng, N. Ahuja and T. S. Huang, "Learning recognition and segmentation using the Cresceptron," International Journal of Computer Vision, vol. 25, no. 2, pp. 105-139, Nov. 1997..</span></p></li><li id="quote_39"><span class="references-num">[39]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">de Carvalho, Andre C. L. F.; Fairhurst, Mike C.; Bisset, David (1994-08-08). "An integrated Boolean neural network for pattern classification". Pattern Recognition Letters. 15 (8): 807–813. doi:10.1016/0167-8655(94)90009-4..</span></p></li><li id="quote_40"><span class="references-num">[40]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Hinton, Geoffrey E.; Dayan, Peter; Frey, Brendan J.; Neal, Radford (1995-05-26). "The wake-sleep algorithm for unsupervised neural networks". Science. 268 (5214): 1158–1161. Bibcode:1995Sci...268.1158H. doi:10.1126/science.7761831..</span></p></li><li id="quote_41"><span class="references-num">[41]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">S. Hochreiter., "Untersuchungen zu dynamischen neuronalen Netzen," Diploma thesis. Institut f. Informatik, Technische Univ. Munich. Advisor: J. Schmidhuber, 1991..</span></p></li><li id="quote_42"><span class="references-num">[42]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Hochreiter, S.; et al. (15 January 2001). "Gradient flow in recurrent nets: the difficulty of learning long-term dependencies". In Kolen, John F.; Kremer, Stefan C. A Field Guide to Dynamical Recurrent Networks. John Wiley &amp; Sons. ISBN 978-0-7803-5369-5..</span></p></li><li id="quote_43"><span class="references-num">[43]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Morgan, Nelson; Bourlard, Hervé; Renals, Steve; Cohen, Michael; Franco, Horacio (1993-08-01). "Hybrid neural network/hidden markov model systems for continuous speech recognition". International Journal of Pattern Recognition and Artificial Intelligence. 07 (4): 899–916. doi:10.1142/s0218001493000455. ISSN 0218-0014..</span></p></li><li id="quote_44"><span class="references-num">[44]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Robinson, T. (1992). "A real-time recurrent error propagation network word recognition system". ICASSP: 617–620..</span></p></li><li id="quote_45"><span class="references-num">[45]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Waibel, A.; Hanazawa, T.; Hinton, G.; Shikano, K.; Lang, K. J. (March 1989). "Phoneme recognition using time-delay neural networks". IEEE Transactions on Acoustics, Speech, and Signal Processing. 37 (3): 328–339. doi:10.1109/29.21701. ISSN 0096-3518..</span></p></li><li id="quote_46"><span class="references-num">[46]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Baker, J.; Deng, Li; Glass, Jim; Khudanpur, S.; Lee, C.-H.; Morgan, N.; O'Shaughnessy, D. (2009). "Research Developments and Directions in Speech Recognition and Understanding, Part 1". IEEE Signal Processing Magazine. 26 (3): 75–80. Bibcode:2009ISPM...26...75B. doi:10.1109/msp.2009.932166..</span></p></li><li id="quote_47"><span class="references-num">[47]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Bengio, Y. (1991). "Artificial Neural Networks and their Application to Speech/Sequence Recognition". McGill University Ph.D. thesis..</span></p></li><li id="quote_48"><span class="references-num">[48]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Deng, L.; Hassanein, K.; Elmasry, M. (1994). "Analysis of correlation structure for a neural predictive model with applications to speech recognition". Neural Networks. 7 (2): 331–339. doi:10.1016/0893-6080(94)90027-2..</span></p></li><li id="quote_49"><span class="references-num">[49]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Heck, L.; Konig, Y.; Sonmez, M.; Weintraub, M. (2000). "Robustness to Telephone Handset Distortion in Speaker Recognition by Discriminative Feature Design". Speech Communication. 31 (2): 181–192. doi:10.1016/s0167-6393(99)00077-1..</span></p></li><li id="quote_50"><span class="references-num">[50]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Acoustic Modeling with Deep Neural Networks Using Raw Time Signal for LVCSR (PDF Download Available)". ResearchGate. Retrieved 2017-06-14..</span></p></li><li id="quote_51"><span class="references-num">[51]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Hochreiter, Sepp; Schmidhuber, Jürgen (1997-11-01). "Long Short-Term Memory". Neural Computation. 9 (8): 1735–1780. doi:10.1162/neco.1997.9.8.1735. ISSN 0899-7667. PMID 9377276..</span></p></li><li id="quote_52"><span class="references-num">[52]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Graves, Alex; Eck, Douglas; Beringer, Nicole; Schmidhuber, Jürgen (2003). "Biologically Plausible Speech Recognition with LSTM Neural Nets" (PDF). 1st Intl. Workshop on Biologically Inspired Approaches to Advanced Information Technology, Bio-ADIT 2004, Lausanne, Switzerland. pp. 175–184..</span></p></li><li id="quote_53"><span class="references-num">[53]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Graves, Alex; Fernández, Santiago; Gomez, Faustino (2006). "Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks". Proceedings of the International Conference on Machine Learning, ICML 2006: 369–376. CiteSeerX 10.1.1.75.6306..</span></p></li><li id="quote_54"><span class="references-num">[54]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Santiago Fernandez, Alex Graves, and Jürgen Schmidhuber (2007). An application of recurrent neural networks to discriminative keyword spotting. Proceedings of ICANN (2), pp. 220–229..</span></p></li><li id="quote_55"><span class="references-num">[55]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Sak, Haşim; Senior, Andrew; Rao, Kanishka; Beaufays, Françoise; Schalkwyk, Johan (September 2015). "Google voice search: faster and more accurate"..</span></p></li><li id="quote_56"><span class="references-num">[56]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Hinton, Geoffrey E. (2007-10-01). "Learning multiple layers of representation". Trends in Cognitive Sciences. 11 (10): 428–434. doi:10.1016/j.tics.2007.09.004. ISSN 1364-6613. PMID 17921042..</span></p></li><li id="quote_57"><span class="references-num">[57]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Hinton, G. E.; Osindero, S.; Teh, Y. W. (2006). "A Fast Learning Algorithm for Deep Belief Nets" (PDF). Neural Computation. 18 (7): 1527–1554. doi:10.1162/neco.2006.18.7.1527. PMID 16764513..</span></p></li><li id="quote_58"><span class="references-num">[58]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Bengio, Yoshua (2012). "Practical recommendations for gradient-based training of deep architectures". arXiv:1206.5533 [cs.LG]..</span></p></li><li id="quote_59"><span class="references-num">[59]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">G. E. Hinton., "Learning multiple layers of representation," Trends in Cognitive Sciences, 11, pp. 428–434, 2007..</span></p></li><li id="quote_60"><span class="references-num">[60]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Hinton, G.; Deng, L.; Yu, D.; Dahl, G.; Mohamed, A.; Jaitly, N.; Senior, A.; Vanhoucke, V.; Nguyen, P.; Sainath, T.; Kingsbury, B. (2012). "Deep Neural Networks for Acoustic Modeling in Speech Recognition --- The shared views of four research groups". IEEE Signal Processing Magazine. 29 (6): 82–97. doi:10.1109/msp.2012.2205597..</span></p></li><li id="quote_61"><span class="references-num">[61]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Deng, Li; Hinton, Geoffrey; Kingsbury, Brian (1 May 2013). "New types of deep neural network learning for speech recognition and related applications: An overview" – via research.microsoft.com..</span></p></li><li id="quote_62"><span class="references-num">[62]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Deng, L.; Li, J.; Huang, J. T.; Yao, K.; Yu, D.; Seide, F.; Seltzer, M.; Zweig, G.; He, X. (May 2013). "Recent advances in deep learning for speech research at Microsoft". 2013 IEEE International Conference on Acoustics, Speech and Signal Processing: 8604–8608. doi:10.1109/icassp.2013.6639345. ISBN 978-1-4799-0356-6..</span></p></li><li id="quote_63"><span class="references-num">[63]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Sak, Hasim; Senior, Andrew; Beaufays, Francoise (2014). "Long Short-Term Memory recurrent neural network architectures for large scale acoustic modeling" (PDF)..</span></p></li><li id="quote_64"><span class="references-num">[64]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Li, Xiangang; Wu, Xihong (2014). "Constructing Long Short-Term Memory based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition". arXiv:1410.4281 [cs.CL]..</span></p></li><li id="quote_65"><span class="references-num">[65]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Zen, Heiga; Sak, Hasim (2015). "Unidirectional Long Short-Term Memory Recurrent Neural Network with Recurrent Output Layer for Low-Latency Speech Synthesis" (PDF). Google.com. ICASSP. pp. 4470–4474..</span></p></li><li id="quote_66"><span class="references-num">[66]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Deng, L.; Abdel-Hamid, O.; Yu, D. (2013). "A deep convolutional neural network using heterogeneous pooling for trading acoustic invariance with phonetic confusion" (PDF). Google.com. ICASSP..</span></p></li><li id="quote_67"><span class="references-num">[67]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Sainath, T. N.; Mohamed, A. r; Kingsbury, B.; Ramabhadran, B. (May 2013). "Deep convolutional neural networks for LVCSR". 2013 IEEE International Conference on Acoustics, Speech and Signal Processing: 8614–8618. doi:10.1109/icassp.2013.6639347. ISBN 978-1-4799-0356-6..</span></p></li><li id="quote_68"><span class="references-num">[68]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Yann LeCun (2016). Slides on Deep Learning Online.</span></p></li><li id="quote_69"><span class="references-num">[69]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">NIPS Workshop: Deep Learning for Speech Recognition and Related Applications, Whistler, BC, Canada, Dec. 2009 (Organizers: Li Deng, Geoff Hinton, D. Yu)..</span></p></li><li id="quote_70"><span class="references-num">[70]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Keynote talk: Recent Developments in Deep Neural Networks. ICASSP, 2013 (by Geoff Hinton)..</span></p></li><li id="quote_71"><span class="references-num">[71]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">D. Yu, L. Deng, G. Li, and F. Seide (2011). "Discriminative pretraining of deep neural networks," U.S. Patent Filing..</span></p></li><li id="quote_72"><span class="references-num">[72]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Deng, L.; Hinton, G.; Kingsbury, B. (2013). "New types of deep neural network learning for speech recognition and related applications: An overview (ICASSP)" (PDF)..</span></p></li><li id="quote_73"><span class="references-num">[73]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Yu, D.; Deng, L. (2014). Automatic Speech Recognition: A Deep Learning Approach (Publisher: Springer). ISBN 978-1-4471-5779-3..</span></p></li><li id="quote_74"><span class="references-num">[74]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Deng receives prestigious IEEE Technical Achievement Award - Microsoft Research". Microsoft Research. 3 December 2015..</span></p></li><li id="quote_75"><span class="references-num">[75]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Li, Deng (September 2014). "Keynote talk: 'Achievements and Challenges of Deep Learning - From Speech Analysis and Recognition To Language and Multimodal Processing'". Interspeech..</span></p></li><li id="quote_76"><span class="references-num">[76]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Yu, D.; Deng, L. (2010). "Roles of Pre-Training and Fine-Tuning in Context-Dependent DBN-HMMs for Real-World Speech Recognition". NIPS Workshop on Deep Learning and Unsupervised Feature Learning..</span></p></li><li id="quote_77"><span class="references-num">[77]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Seide, F.; Li, G.; Yu, D. (2011). "Conversational speech transcription using context-dependent deep neural networks". Interspeech..</span></p></li><li id="quote_78"><span class="references-num">[78]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Deng, Li; Li, Jinyu; Huang, Jui-Ting; Yao, Kaisheng; Yu, Dong; Seide, Frank; Seltzer, Mike; Zweig, Geoff; He, Xiaodong (2013-05-01). "Recent Advances in Deep Learning for Speech Research at Microsoft". Microsoft Research..</span></p></li><li id="quote_79"><span class="references-num">[79]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Nvidia CEO bets big on deep learning and VR". Venture Beat. April 5, 2016..</span></p></li><li id="quote_80"><span class="references-num">[80]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"From not working to neural networking". The Economist..</span></p></li><li id="quote_81"><span class="references-num">[81]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Oh, K.-S.; Jung, K. (2004). "GPU implementation of neural networks". Pattern Recognition. 37 (6): 1311–1314. doi:10.1016/j.patcog.2004.01.013..</span></p></li><li id="quote_82"><span class="references-num">[82]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Chellapilla, K., Puri, S., and Simard, P. (2006). High performance convolutional neural networks for document processing. International Workshop on Frontiers in Handwriting Recognition..</span></p></li><li id="quote_83"><span class="references-num">[83]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Cireşan, Dan Claudiu; Meier, Ueli; Gambardella, Luca Maria; Schmidhuber, Jürgen (2010-09-21). "Deep, Big, Simple Neural Nets for Handwritten Digit Recognition". Neural Computation. 22 (12): 3207–3220. arXiv:1003.0358. doi:10.1162/neco_a_00052. ISSN 0899-7667. PMID 20858131..</span></p></li><li id="quote_84"><span class="references-num">[84]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Raina, Rajat; Madhavan, Anand; Ng, Andrew Y. (2009). "Large-scale Deep Unsupervised Learning Using Graphics Processors". Proceedings of the 26th Annual International Conference on Machine Learning. ICML '09. New York, NY, USA: ACM: 873–880. CiteSeerX 10.1.1.154.372. doi:10.1145/1553374.1553486. ISBN 9781605585161..</span></p></li><li id="quote_85"><span class="references-num">[85]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Sze, Vivienne; Chen, Yu-Hsin; Yang, Tien-Ju; Emer, Joel (2017). "Efficient Processing of Deep Neural Networks: A Tutorial and Survey". arXiv:1703.09039 [cs.CV]..</span></p></li><li id="quote_86"><span class="references-num">[86]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Announcement of the winners of the Merck Molecular Activity Challenge"..</span></p></li><li id="quote_87"><span class="references-num">[87]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Multi-task Neural Networks for QSAR Predictions | Data Science Association". www.datascienceassn.org. Retrieved 2017-06-14..</span></p></li><li id="quote_88"><span class="references-num">[88]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Toxicology in the 21st century Data Challenge".</span></p></li><li id="quote_89"><span class="references-num">[89]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"NCATS Announces Tox21 Data Challenge Winners"..</span></p></li><li id="quote_90"><span class="references-num">[90]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Archived copy". Archived from the original on 2015-02-28. Retrieved 2015-03-05.CS1 maint: Archived copy as title (link).</span></p></li><li id="quote_91"><span class="references-num">[91]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Ciresan, D. C.; Meier, U.; Masci, J.; Gambardella, L. M.; Schmidhuber, J. (2011). "Flexible, High Performance Convolutional Neural Networks for Image Classification" (PDF). International Joint Conference on Artificial Intelligence. doi:10.5591/978-1-57735-516-8/ijcai11-210..</span></p></li><li id="quote_92"><span class="references-num">[92]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Ciresan, Dan; Giusti, Alessandro; Gambardella, Luca M.; Schmidhuber, Juergen (2012). Pereira, F.; Burges, C. J. C.; Bottou, L.; Weinberger, K. Q., eds. Advances in Neural Information Processing Systems 25 (PDF). Curran Associates, Inc. pp. 2843–2851..</span></p></li><li id="quote_93"><span class="references-num">[93]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Ciresan, D.; Giusti, A.; Gambardella, L.M.; Schmidhuber, J. (2013). "Mitosis Detection in Breast Cancer Histology Images using Deep Neural Networks". Proceedings MICCAI. Lecture Notes in Computer Science. 7908: 411–418. doi:10.1007/978-3-642-40763-5_51. ISBN 978-3-642-38708-1..</span></p></li><li id="quote_94"><span class="references-num">[94]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"The Wolfram Language Image Identification Project". www.imageidentify.com. Retrieved 2017-03-22..</span></p></li><li id="quote_95"><span class="references-num">[95]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Vinyals, Oriol; Toshev, Alexander; Bengio, Samy; Erhan, Dumitru (2014). "Show and Tell: A Neural Image Caption Generator". arXiv:1411.4555 [cs.CV]...</span></p></li><li id="quote_96"><span class="references-num">[96]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Fang, Hao; Gupta, Saurabh; Iandola, Forrest; Srivastava, Rupesh; Deng, Li; Dollár, Piotr; Gao, Jianfeng; He, Xiaodong; Mitchell, Margaret; Platt, John C; Lawrence Zitnick, C; Zweig, Geoffrey (2014). "From Captions to Visual Concepts and Back". arXiv:1411.4952 [cs.CV]...</span></p></li><li id="quote_97"><span class="references-num">[97]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Kiros, Ryan; Salakhutdinov, Ruslan; Zemel, Richard S (2014). "Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models". arXiv:1411.2539 [cs.LG]...</span></p></li><li id="quote_98"><span class="references-num">[98]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Zhong, Sheng-hua; Liu, Yan; Liu, Yang (2011). "Bilinear Deep Learning for Image Classification". Proceedings of the 19th ACM International Conference on Multimedia. MM '11. New York, NY, USA: ACM: 343–352. doi:10.1145/2072298.2072344. ISBN 9781450306164..</span></p></li><li id="quote_99"><span class="references-num">[99]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Why Deep Learning Is Suddenly Changing Your Life". Fortune. 2016. Retrieved 13 April 2018..</span></p></li><li id="quote_100"><span class="references-num">[100]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Silver, David; Huang, Aja; Maddison, Chris J.; Guez, Arthur; Sifre, Laurent; Driessche, George van den; Schrittwieser, Julian; Antonoglou, Ioannis; Panneershelvam, Veda (January 2016). "Mastering the game of Go with deep neural networks and tree search". Nature. 529 (7587): 484–489. Bibcode:2016Natur.529..484S. doi:10.1038/nature16961. ISSN 1476-4687. PMID 26819042..</span></p></li><li id="quote_101"><span class="references-num">[101]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Szegedy, Christian; Toshev, Alexander; Erhan, Dumitru (2013). "Deep neural networks for object detection". Advances in Neural Information Processing Systems..</span></p></li><li id="quote_102"><span class="references-num">[102]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Hof, Robert D. "Is Artificial Intelligence Finally Coming into Its Own?". MIT Technology Review. Retrieved 2018-07-10..</span></p></li><li id="quote_103"><span class="references-num">[103]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Gers, Felix A.; Schmidhuber, Jürgen (2001). "LSTM Recurrent Networks Learn Simple Context Free and Context Sensitive Languages". IEEE Trans. Neural Netw. 12 (6): 1333–1340. doi:10.1109/72.963769. PMID 18249962..</span></p></li><li id="quote_104"><span class="references-num">[104]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Sutskever, L.; Vinyals, O.; Le, Q. (2014). "Sequence to Sequence Learning with Neural Networks" (PDF). Proc. NIPS..</span></p></li><li id="quote_105"><span class="references-num">[105]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Jozefowicz, Rafal; Vinyals, Oriol; Schuster, Mike; Shazeer, Noam; Wu, Yonghui (2016). "Exploring the Limits of Language Modeling". arXiv:1602.02410 [cs.CL]..</span></p></li><li id="quote_106"><span class="references-num">[106]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Gillick, Dan; Brunk, Cliff; Vinyals, Oriol; Subramanya, Amarnag (2015). "Multilingual Language Processing from Bytes". arXiv:1512.00103 [cs.CL]..</span></p></li><li id="quote_107"><span class="references-num">[107]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Mikolov, T.; et al. (2010). "Recurrent neural network based language model" (PDF). Interspeech..</span></p></li><li id="quote_108"><span class="references-num">[108]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Learning Precise Timing with LSTM Recurrent Networks (PDF Download Available)". ResearchGate. Retrieved 2017-06-13..</span></p></li><li id="quote_109"><span class="references-num">[109]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">LeCun, Y.; et al. (1998). "Gradient-based learning applied to document recognition". Proceedings of the IEEE. 86 (11): 2278–2324. doi:10.1109/5.726791..</span></p></li><li id="quote_110"><span class="references-num">[110]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Bengio, Y.; Boulanger-Lewandowski, N.; Pascanu, R. (May 2013). "Advances in optimizing recurrent networks". 2013 IEEE International Conference on Acoustics, Speech and Signal Processing: 8624–8628. arXiv:1212.0901. CiteSeerX 10.1.1.752.9151. doi:10.1109/icassp.2013.6639349. ISBN 978-1-4799-0356-6..</span></p></li><li id="quote_111"><span class="references-num">[111]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Dahl, G.; et al. (2013). "Improving DNNs for LVCSR using rectified linear units and dropout" (PDF). ICASSP..</span></p></li><li id="quote_112"><span class="references-num">[112]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Data Augmentation - deeplearning.ai | Coursera". Coursera. Retrieved 2017-11-30..</span></p></li><li id="quote_113"><span class="references-num">[113]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Hinton, G. E. (2010). "A Practical Guide to Training Restricted Boltzmann Machines". Tech. Rep. UTML TR 2010-003..</span></p></li><li id="quote_114"><span class="references-num">[114]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">You, Yang; Buluç, Aydın; Demmel, James (November 2017). "Scaling deep learning on GPU and knights landing clusters". SC '17, ACM. Retrieved 5 March 2018..</span></p></li><li id="quote_115"><span class="references-num">[115]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Viebke, André; Memeti, Suejb; Pllana, Sabri; Abraham, Ajith (March 2017). "CHAOS: a parallelization scheme for training convolutional neural networks on Intel Xeon Phi". The Journal of Supercomputing. 75: 197–227. doi:10.1007/s11227-017-1994-x..</span></p></li><li id="quote_116"><span class="references-num">[116]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Ting Qin, et al. "A learning algorithm of CMAC based on RLS." Neural Processing Letters 19.1 (2004): 49-61..</span></p></li><li id="quote_117"><span class="references-num">[117]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Ting Qin, et al. "Continuous CMAC-QRLS and its systolic array." Neural Processing Letters 22.1 (2005): 1-16..</span></p></li><li id="quote_118"><span class="references-num">[118]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">TIMIT Acoustic-Phonetic Continuous Speech Corpus Linguistic Data Consortium, Philadelphia..</span></p></li><li id="quote_119"><span class="references-num">[119]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Robinson, Tony (30 September 1991). "Several Improvements to a Recurrent Error Propagation Network Phone Recognition System". Cambridge University Engineering Department Technical Report. CUED/F-INFENG/TR82. doi:10.13140/RG.2.2.15418.90567..</span></p></li><li id="quote_120"><span class="references-num">[120]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Abdel-Hamid, O.; et al. (2014). "Convolutional Neural Networks for Speech Recognition". IEEE/ACM Transactions on Audio, Speech, and Language Processing. 22 (10): 1533–1545. doi:10.1109/taslp.2014.2339736..</span></p></li><li id="quote_121"><span class="references-num">[121]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Deng, L.; Platt, J. (2014). "Ensemble Deep Learning for Speech Recognition" (PDF). Proc. Interspeech..</span></p></li><li id="quote_122"><span class="references-num">[122]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Tóth, Laszló (2015). "Phone Recognition with Hierarchical Convolutional Deep Maxout Networks" (PDF). EURASIP Journal on Audio, Speech, and Music Processing. 2015. doi:10.1186/s13636-015-0068-3..</span></p></li><li id="quote_123"><span class="references-num">[123]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"How Skype Used AI to Build Its Amazing New Language Translator | WIRED". www.wired.com. Retrieved 2017-06-14..</span></p></li><li id="quote_124"><span class="references-num">[124]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Hannun, Awni; Case, Carl; Casper, Jared; Catanzaro, Bryan; Diamos, Greg; Elsen, Erich; Prenger, Ryan; Satheesh, Sanjeev; Sengupta, Shubho; Coates, Adam; Ng, Andrew Y (2014). "Deep Speech: Scaling up end-to-end speech recognition". arXiv:1412.5567 [cs.CL]..</span></p></li><li id="quote_125"><span class="references-num">[125]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Plenary presentation at ICASSP-2016" (PDF)..</span></p></li><li id="quote_126"><span class="references-num">[126]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges". yann.lecun.com..</span></p></li><li id="quote_127"><span class="references-num">[127]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Cireşan, Dan; Meier, Ueli; Masci, Jonathan; Schmidhuber, Jürgen (August 2012). "Multi-column deep neural network for traffic sign classification". Neural Networks. Selected Papers from IJCNN 2011. 32: 333–338. CiteSeerX 10.1.1.226.8219. doi:10.1016/j.neunet.2012.02.023. PMID 22386783..</span></p></li><li id="quote_128"><span class="references-num">[128]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Nvidia Demos a Car Computer Trained with "Deep Learning" (2015-01-06), David Talbot, MIT Technology Review.</span></p></li><li id="quote_129"><span class="references-num">[129]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">G. W. Smith; Frederic Fol Leymarie (10 April 2017). "The Machine as Artist: An Introduction". Arts. Retrieved 4 October 2017..</span></p></li><li id="quote_130"><span class="references-num">[130]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Blaise Agüera y Arcas (29 September 2017). "Art in the Age of Machine Intelligence". Arts. Retrieved 4 October 2017..</span></p></li><li id="quote_131"><span class="references-num">[131]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Bengio, Yoshua; Ducharme, Réjean; Vincent, Pascal; Janvin, Christian (March 2003). "A Neural Probabilistic Language Model". J. Mach. Learn. Res. 3: 1137–1155. ISSN 1532-4435..</span></p></li><li id="quote_132"><span class="references-num">[132]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Goldberg, Yoav; Levy, Omar (2014). "word2vec Explained: Deriving Mikolov et al.'s Negative-Sampling Word-Embedding Method". arXiv:1402.3722 [cs.CL]..</span></p></li><li id="quote_133"><span class="references-num">[133]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Socher, Richard; Manning, Christopher. "Deep Learning for NLP" (PDF). Retrieved 26 October 2014..</span></p></li><li id="quote_134"><span class="references-num">[134]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Socher, Richard; Bauer, John; Manning, Christopher; Ng, Andrew (2013). "Parsing With Compositional Vector Grammars" (PDF). Proceedings of the ACL 2013 Conference..</span></p></li><li id="quote_135"><span class="references-num">[135]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Socher, Richard (2013). "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank" (PDF)..</span></p></li><li id="quote_136"><span class="references-num">[136]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Shen, Yelong; He, Xiaodong; Gao, Jianfeng; Deng, Li; Mesnil, Gregoire (2014-11-01). "A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval". Microsoft Research..</span></p></li><li id="quote_137"><span class="references-num">[137]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Huang, Po-Sen; He, Xiaodong; Gao, Jianfeng; Deng, Li; Acero, Alex; Heck, Larry (2013-10-01). "Learning Deep Structured Semantic Models for Web Search using Clickthrough Data". Microsoft Research..</span></p></li><li id="quote_138"><span class="references-num">[138]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Mesnil, G.; Dauphin, Y.; Yao, K.; Bengio, Y.; Deng, L.; Hakkani-Tur, D.; He, X.; Heck, L.; Tur, G.; Yu, D.; Zweig, G. (2015). "Using recurrent neural networks for slot filling in spoken language understanding". IEEE Transactions on Audio, Speech, and Language Processing. 23 (3): 530–539. doi:10.1109/taslp.2014.2383614..</span></p></li><li id="quote_139"><span class="references-num">[139]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Gao, Jianfeng; He, Xiaodong; Yih, Scott Wen-tau; Deng, Li (2014-06-01). "Learning Continuous Phrase Representations for Translation Modeling". Microsoft Research..</span></p></li><li id="quote_140"><span class="references-num">[140]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Brocardo, Marcelo Luiz; Traore, Issa; Woungang, Isaac; Obaidat, Mohammad S. (2017). "Authorship verification using deep belief network systems". International Journal of Communication Systems. 30 (12): e3259. doi:10.1002/dac.3259..</span></p></li><li id="quote_141"><span class="references-num">[141]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Deep Learning for Natural Language Processing: Theory and Practice (CIKM2014 Tutorial) - Microsoft Research". Microsoft Research. Retrieved 2017-06-14..</span></p></li><li id="quote_142"><span class="references-num">[142]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Turovsky, Barak (November 15, 2016). "Found in translation: More accurate, fluent sentences in Google Translate". The Keyword Google Blog. Retrieved March 23, 2017..</span></p></li><li id="quote_143"><span class="references-num">[143]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Schuster, Mike; Johnson, Melvin; Thorat, Nikhil (November 22, 2016). "Zero-Shot Translation with Google's Multilingual Neural Machine Translation System". Google Research Blog. Retrieved March 23, 2017..</span></p></li><li id="quote_144"><span class="references-num">[144]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Sepp Hochreiter; Jürgen Schmidhuber (1997). "Long short-term memory". Neural Computation. 9 (8): 1735–1780. doi:10.1162/neco.1997.9.8.1735. PMID 9377276..</span></p></li><li id="quote_145"><span class="references-num">[145]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Felix A. Gers; Jürgen Schmidhuber; Fred Cummins (2000). "Learning to Forget: Continual Prediction with LSTM". Neural Computation. 12 (10): 2451–2471. CiteSeerX 10.1.1.55.5709. doi:10.1162/089976600300015015..</span></p></li><li id="quote_146"><span class="references-num">[146]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Wu, Yonghui; Schuster, Mike; Chen, Zhifeng; Le, Quoc V; Norouzi, Mohammad; Macherey, Wolfgang; Krikun, Maxim; Cao, Yuan; Gao, Qin; Macherey, Klaus; Klingner, Jeff; Shah, Apurva; Johnson, Melvin; Liu, Xiaobing; Kaiser, Łukasz; Gouws, Stephan; Kato, Yoshikiyo; Kudo, Taku; Kazawa, Hideto; Stevens, Keith; Kurian, George; Patil, Nishant; Wang, Wei; Young, Cliff; Smith, Jason; Riesa, Jason; Rudnick, Alex; Vinyals, Oriol; Corrado, Greg; et al. (2016). "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation". arXiv:1609.08144 [cs.CL]..</span></p></li><li id="quote_147"><span class="references-num">[147]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"An Infusion of AI Makes Google Translate More Powerful Than Ever." Cade Metz, WIRED, Date of Publication: 09.27.16. https://www.wired.com/2016/09/google-claims-ai-breakthrough-machine-translation/.</span></p></li><li id="quote_148"><span class="references-num">[148]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Boitet, Christian; Blanchon, Hervé; Seligman, Mark; Bellynck, Valérie (2010). "MT on and for the Web" (PDF). Retrieved December 1, 2016..</span></p></li><li id="quote_149"><span class="references-num">[149]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Arrowsmith, J; Miller, P (2013). "Trial watch: Phase II and phase III attrition rates 2011-2012". Nature Reviews Drug Discovery. 12 (8): 569. doi:10.1038/nrd4090. PMID 23903212..</span></p></li><li id="quote_150"><span class="references-num">[150]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Verbist, B; Klambauer, G; Vervoort, L; Talloen, W; The Qstar, Consortium; Shkedy, Z; Thas, O; Bender, A; Göhlmann, H. W.; Hochreiter, S (2015). "Using transcriptomics to guide lead optimization in drug discovery projects: Lessons learned from the QSTAR project". Drug Discovery Today. 20 (5): 505–513. doi:10.1016/j.drudis.2014.12.014. PMID 25582842..</span></p></li><li id="quote_151"><span class="references-num">[151]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Wallach, Izhar; Dzamba, Michael; Heifets, Abraham (2015-10-09). "AtomNet: A Deep Convolutional Neural Network for Bioactivity Prediction in Structure-based Drug Discovery". arXiv:1510.02855 [cs.LG]..</span></p></li><li id="quote_152"><span class="references-num">[152]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Toronto startup has a faster way to discover effective medicines". The Globe and Mail. Retrieved 2015-11-09..</span></p></li><li id="quote_153"><span class="references-num">[153]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Startup Harnesses Supercomputers to Seek Cures". KQED Future of You. Retrieved 2015-11-09..</span></p></li><li id="quote_154"><span class="references-num">[154]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Toronto startup has a faster way to discover effective medicines"..</span></p></li><li id="quote_155"><span class="references-num">[155]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Tkachenko, Yegor (April 8, 2015). "Autonomous CRM Control via CLV Approximation with Deep Reinforcement Learning in Discrete and Continuous Action Space". arXiv:1504.01840 [cs.LG]..</span></p></li><li id="quote_156"><span class="references-num">[156]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">van den Oord, Aaron; Dieleman, Sander; Schrauwen, Benjamin (2013). Burges, C. J. C.; Bottou, L.; Welling, M.; Ghahramani, Z.; Weinberger, K. Q., eds. Advances in Neural Information Processing Systems 26 (PDF). Curran Associates, Inc. pp. 2643–2651..</span></p></li><li id="quote_157"><span class="references-num">[157]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Elkahky, Ali Mamdouh; Song, Yang; He, Xiaodong (2015-05-01). "A Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Systems". Microsoft Research..</span></p></li><li id="quote_158"><span class="references-num">[158]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Chicco, Davide; Sadowski, Peter; Baldi, Pierre (1 January 2014). Deep Autoencoder Neural Networks for Gene Ontology Annotation Predictions. Proceedings of the 5th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics - BCB '14. ACM. pp. 533–540. doi:10.1145/2649387.2649442. hdl:11311/964622. ISBN 9781450328944..</span></p></li><li id="quote_159"><span class="references-num">[159]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Sathyanarayana, Aarti (2016-01-01). "Sleep Quality Prediction From Wearable Data Using Deep Learning". JMIR mHealth and uHealth. 4 (4): e125. doi:10.2196/mhealth.6562. PMC 5116102. PMID 27815231..</span></p></li><li id="quote_160"><span class="references-num">[160]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Choi, Edward; Schuetz, Andy; Stewart, Walter F.; Sun, Jimeng (2016-08-13). "Using recurrent neural network models for early detection of heart failure onset". Journal of the American Medical Informatics Association. 24 (2): 361–370. doi:10.1093/jamia/ocw112. ISSN 1067-5027. PMC 5391725. PMID 27521897..</span></p></li><li id="quote_161"><span class="references-num">[161]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Deep Learning in Healthcare: Challenges and Opportunities". Medium. 2016-08-12. Retrieved 2018-04-10..</span></p></li><li id="quote_162"><span class="references-num">[162]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Litjens, Geert; Kooi, Thijs; Bejnordi, Babak Ehteshami; Setio, Arnaud Arindra Adiyoso; Ciompi, Francesco; Ghafoorian, Mohsen; van der Laak, Jeroen A.W.M.; van Ginneken, Bram; Sánchez, Clara I. (December 2017). "A survey on deep learning in medical image analysis". Medical Image Analysis. 42: 60–88. doi:10.1016/j.media.2017.07.005..</span></p></li><li id="quote_163"><span class="references-num">[163]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Forslid, Gustav; Wieslander, Hakan; Bengtsson, Ewert; Wahlby, Carolina; Hirsch, Jan-Michael; Stark, Christina Runow; Sadanandan, Sajith Kecheril (October 2017). "Deep Convolutional Neural Networks for Detecting Cellular Changes Due to Malignancy". 2017 IEEE International Conference on Computer Vision Workshops (ICCVW). Venice: IEEE: 82–89. doi:10.1109/ICCVW.2017.18. ISBN 9781538610343..</span></p></li><li id="quote_164"><span class="references-num">[164]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">De, Shaunak; Maity, Abhishek; Goel, Vritti; Shitole, Sanjay; Bhattacharya, Avik (2017). "Predicting the popularity of instagram posts for a lifestyle magazine using deep learning". 2nd IEEE Conference on Communication Systems, Computing and IT Applications: 174–177. doi:10.1109/CSCITA.2017.8066548. ISBN 978-1-5090-4381-1..</span></p></li><li id="quote_165"><span class="references-num">[165]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Schmidt, Uwe; Roth, Stefan. Shrinkage Fields for Effective Image Restoration (PDF). Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on..</span></p></li><li id="quote_166"><span class="references-num">[166]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Czech, Tomasz. "Deep learning: the next frontier for money laundering detection". Global Banking and Finance Review..</span></p></li><li id="quote_167"><span class="references-num">[167]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Army researchers develop new algorithms to train robots". EurekAlert!. Retrieved 2018-08-29..</span></p></li><li id="quote_168"><span class="references-num">[168]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Utgoff, P. E.; Stracuzzi, D. J. (2002). "Many-layered learning". Neural Computation. 14 (10): 2497–2529. doi:10.1162/08997660260293319. PMID 12396572..</span></p></li><li id="quote_169"><span class="references-num">[169]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Elman, Jeffrey L. (1998). Rethinking Innateness: A Connectionist Perspective on Development. MIT Press. ISBN 978-0-262-55030-7..</span></p></li><li id="quote_170"><span class="references-num">[170]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Shrager, J.; Johnson, MH (1996). "Dynamic plasticity influences the emergence of function in a simple cortical array". Neural Networks. 9 (7): 1119–1129. doi:10.1016/0893-6080(96)00033-0. PMID 12662587..</span></p></li><li id="quote_171"><span class="references-num">[171]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Quartz, SR; Sejnowski, TJ (1997). "The neural basis of cognitive development: A constructivist manifesto". Behavioral and Brain Sciences. 20 (4): 537–556. CiteSeerX 10.1.1.41.7854. doi:10.1017/s0140525x97001581..</span></p></li><li id="quote_172"><span class="references-num">[172]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">S. Blakeslee., "In brain's early growth, timetable may be critical," The New York Times, Science Section, pp. B5–B6, 1995..</span></p></li><li id="quote_173"><span class="references-num">[173]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Mazzoni, P.; Andersen, R. A.; Jordan, M. I. (1991-05-15). "A more biologically plausible learning rule for neural networks". Proceedings of the National Academy of Sciences. 88 (10): 4433–4437. Bibcode:1991PNAS...88.4433M. doi:10.1073/pnas.88.10.4433. ISSN 0027-8424. PMC 51674. PMID 1903542..</span></p></li><li id="quote_174"><span class="references-num">[174]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">O'Reilly, Randall C. (1996-07-01). "Biologically Plausible Error-Driven Learning Using Local Activation Differences: The Generalized Recirculation Algorithm". Neural Computation. 8 (5): 895–938. doi:10.1162/neco.1996.8.5.895. ISSN 0899-7667..</span></p></li><li id="quote_175"><span class="references-num">[175]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Testolin, Alberto; Zorzi, Marco (2016). "Probabilistic Models and Generative Neural Networks: Towards an Unified Framework for Modeling Normal and Impaired Neurocognitive Functions". Frontiers in Computational Neuroscience. 10: 73. doi:10.3389/fncom.2016.00073. ISSN 1662-5188. PMC 4943066. PMID 27468262..</span></p></li><li id="quote_176"><span class="references-num">[176]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Testolin, Alberto; Stoianov, Ivilin; Zorzi, Marco (September 2017). "Letter perception emerges from unsupervised deep learning and recycling of natural image features". Nature Human Behaviour. 1 (9): 657–664. doi:10.1038/s41562-017-0186-2. ISSN 2397-3374..</span></p></li><li id="quote_177"><span class="references-num">[177]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Buesing, Lars; Bill, Johannes; Nessler, Bernhard; Maass, Wolfgang (2011-11-03). "Neural Dynamics as Sampling: A Model for Stochastic Computation in Recurrent Networks of Spiking Neurons". PLOS Computational Biology. 7 (11): e1002211. Bibcode:2011PLSCB...7E2211B. doi:10.1371/journal.pcbi.1002211. ISSN 1553-7358. PMC 3207943. PMID 22096452..</span></p></li><li id="quote_178"><span class="references-num">[178]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Morel, Danielle; Singh, Chandan; Levy, William B. (2018-01-25). "Linearization of excitatory synaptic integration at no extra cost". Journal of Computational Neuroscience. 44 (2): 173–188. doi:10.1007/s10827-017-0673-5. ISSN 0929-5313. PMID 29372434..</span></p></li><li id="quote_179"><span class="references-num">[179]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Cash, S.; Yuste, R. (February 1999). "Linear summation of excitatory inputs by CA1 pyramidal neurons". Neuron. 22 (2): 383–394. doi:10.1016/s0896-6273(00)81098-3. ISSN 0896-6273. PMID 10069343..</span></p></li><li id="quote_180"><span class="references-num">[180]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Olshausen, B; Field, D (2004-08-01). "Sparse coding of sensory inputs". Current Opinion in Neurobiology. 14 (4): 481–487. doi:10.1016/j.conb.2004.07.007. ISSN 0959-4388..</span></p></li><li id="quote_181"><span class="references-num">[181]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Yamins, Daniel L K; DiCarlo, James J (March 2016). "Using goal-driven deep learning models to understand sensory cortex". Nature Neuroscience. 19 (3): 356–365. doi:10.1038/nn.4244. ISSN 1546-1726..</span></p></li><li id="quote_182"><span class="references-num">[182]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Zorzi, Marco; Testolin, Alberto (2018-02-19). "An emergentist perspective on the origin of number sense". Phil. Trans. R. Soc. B. 373 (1740): 20170043. doi:10.1098/rstb.2017.0043. ISSN 0962-8436. PMC 5784047. PMID 29292348..</span></p></li><li id="quote_183"><span class="references-num">[183]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Güçlü, Umut; van Gerven, Marcel A. J. (2015-07-08). "Deep Neural Networks Reveal a Gradient in the Complexity of Neural Representations across the Ventral Stream". Journal of Neuroscience. 35 (27): 10005–10014. arXiv:1411.6422. doi:10.1523/jneurosci.5023-14.2015. PMID 26157000..</span></p></li><li id="quote_184"><span class="references-num">[184]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Metz, C. (12 December 2013). "Facebook's 'Deep Learning' Guru Reveals the Future of AI". Wired..</span></p></li><li id="quote_185"><span class="references-num">[185]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Google AI algorithm masters ancient game of Go". Nature News &amp; Comment. Retrieved 2016-01-30..</span></p></li><li id="quote_186"><span class="references-num">[186]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Silver, David; Huang, Aja; Maddison, Chris J.; Guez, Arthur; Sifre, Laurent; Driessche, George van den; Schrittwieser, Julian; Antonoglou, Ioannis; Panneershelvam, Veda; Lanctot, Marc; Dieleman, Sander; Grewe, Dominik; Nham, John; Kalchbrenner, Nal; Sutskever, Ilya; Lillicrap, Timothy; Leach, Madeleine; Kavukcuoglu, Koray; Graepel, Thore; Hassabis, Demis (28 January 2016). "Mastering the game of Go with deep neural networks and tree search". Nature. 529 (7587): 484–489. Bibcode:2016Natur.529..484S. doi:10.1038/nature16961. ISSN 0028-0836. PMID 26819042..</span></p></li><li id="quote_187"><span class="references-num">[187]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"A Google DeepMind Algorithm Uses Deep Learning and More to Master the Game of Go | MIT Technology Review". MIT Technology Review. Retrieved 2016-01-30..</span></p></li><li id="quote_188"><span class="references-num">[188]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Blippar Demonstrates New Real-Time Augmented Reality App". TechCrunch..</span></p></li><li id="quote_189"><span class="references-num">[189]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"TAMER: Training an Agent Manually via Evaluative Reinforcement - IEEE Conference Publication". ieeexplore.ieee.org. Retrieved 2018-08-29..</span></p></li><li id="quote_190"><span class="references-num">[190]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Talk to the Algorithms: AI Becomes a Faster Learner". governmentciomedia.com. Retrieved 2018-08-29..</span></p></li><li id="quote_191"><span class="references-num">[191]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Marcus, Gary (2018-01-14). "In defense of skepticism about deep learning". Gary Marcus. Retrieved 2018-10-11..</span></p></li><li id="quote_192"><span class="references-num">[192]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Knight, Will (2017-03-14). "DARPA is funding projects that will try to open up AI's black boxes". MIT Technology Review. Retrieved 2017-11-02..</span></p></li><li id="quote_193"><span class="references-num">[193]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Marcus, Gary (November 25, 2012). "Is "Deep Learning" a Revolution in Artificial Intelligence?". The New Yorker. Retrieved 2017-06-14..</span></p></li><li id="quote_194"><span class="references-num">[194]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Smith, G. W. (March 27, 2015). "Art and Artificial Intelligence". ArtEnt. Archived from the original on June 25, 2017. Retrieved March 27, 2015.CS1 maint: BOT: original-url status unknown (link).</span></p></li><li id="quote_195"><span class="references-num">[195]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Mellars, Paul (February 1, 2005). "The Impossible Coincidence: A Single-Species Model for the Origins of Modern Human Behavior in Europe" (PDF). Evolutionary Anthropology: Issues, News, and Reviews. Retrieved April 5, 2017..</span></p></li><li id="quote_196"><span class="references-num">[196]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Alexander Mordvintsev; Christopher Olah; Mike Tyka (June 17, 2015). "Inceptionism: Going Deeper into Neural Networks". Google Research Blog. Retrieved June 20, 2015..</span></p></li><li id="quote_197"><span class="references-num">[197]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Alex Hern (June 18, 2015). "Yes, androids do dream of electric sheep". The Guardian. Retrieved June 20, 2015..</span></p></li><li id="quote_198"><span class="references-num">[198]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Goertzel, Ben (2015). "Are there Deep Reasons Underlying the Pathologies of Today's Deep Learning Algorithms?" (PDF)..</span></p></li><li id="quote_199"><span class="references-num">[199]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Nguyen, Anh; Yosinski, Jason; Clune, Jeff (2014). "Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images". arXiv:1412.1897 [cs.CV]..</span></p></li><li id="quote_200"><span class="references-num">[200]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Szegedy, Christian; Zaremba, Wojciech; Sutskever, Ilya; Bruna, Joan; Erhan, Dumitru; Goodfellow, Ian; Fergus, Rob (2013). "Intriguing properties of neural networks". arXiv:1312.6199 [cs.CV]..</span></p></li><li id="quote_201"><span class="references-num">[201]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Zhu, S.C.; Mumford, D. (2006). "A stochastic grammar of images". Found. Trends Comput. Graph. Vis. 2 (4): 259–362. CiteSeerX 10.1.1.681.2190. doi:10.1561/0600000018..</span></p></li><li id="quote_202"><span class="references-num">[202]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Miller, G. A., and N. Chomsky. "Pattern conception." Paper for Conference on pattern detection, University of Michigan. 1957..</span></p></li><li id="quote_203"><span class="references-num">[203]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Eisner, Jason. "Deep Learning of Recursive Structure: Grammar Induction"..</span></p></li><li id="quote_204"><span class="references-num">[204]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"AI Is Easy to Fool—Why That Needs to Change". Singularity Hub. 2017-10-10. Retrieved 2017-10-11..</span></p></li><li id="quote_205"><span class="references-num">[205]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Gibney, Elizabeth (2017). "The scientist who spots fake videos". Nature. doi:10.1038/nature.2017.22784..</span></p></li></ul></div><div class="read-num">阅读 <!-- -->4.2<!-- -->w</div></div><div class="right-side" id="rightSide"><div class="side" id="lemma-side"><div class="side-title">版本记录</div><ul class="side-lst"><li><p class="side-lst-txt">暂无</p></li></ul><div class="user-card userCard"></div></div><div class="side"><div class="side-event"></div></div></div></div><div class="footer-box"><div id="footer"><div class="footer-logo-wrap"><div class="footer-logo"></div><div class="footer-logo-text">知识·传播·科普</div></div><div class="footer-info">本网站内容采用<a target="_blank" href="https://web.archive.org/web/20221025113558/https://creativecommons.org/licenses/by-sa/3.0/deed.zh?tdsourcetag=s_pctim_aiomsg">CC-BY-SA 3.0</a>授权</div><div class="footer-btn-wrap"><a target="_blank" href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/help/#user_protocol">用户协议</a><a target="_blank" href="https://web.archive.org/web/20221025113558/http://www.sogou.com/docs/terms.htm?v=1">免责声明</a><a target="_blank" href="https://web.archive.org/web/20221025113558/http://corp.sogou.com/private.html">隐私政策</a><a target="_blank" href="https://web.archive.org/web/20221025113558/https://baike.sogou.com/kexue/intro.htm">关于我们</a></div></div></div><script>window.lemmaInfo ={"lemmaId":"10438","versionId":"14995350385328390","title":"深度学习","subtitle":"","abstracts":{"paragraphId":"14995109430952204","title":"简介","versionId":"14995350385328391","lemmaId":10438,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233924,"comment":null,"dependVersionId":0,"contentType":2,"content":"<p>深度学习（也称为深度结构化学习或分层学习）是基于人工神经网络的更广泛的机器学习方法族的一部分。学习可以是有监督的、半监督的或无监督的。<sup><a href=\"#quote_1\" class=\"kx_ref\">[1]</a></sup><sup><a href=\"#quote_2\" class=\"kx_ref\">[2]</a></sup><sup><a href=\"#quote_3\" class=\"kx_ref\">[3]</a></sup> </p>\n<p>深度学习架构，例如深度神经网络、深度信念网络、循环神经网络和卷积神经网络，已经被应用于包括计算机视觉、语音识别、自然语言处理、音频识别、社交网络过滤、机器翻译、生物信息学、药物设计、医学图像分析、材料检查和棋盘游戏程序在内的领域，在这些领域中，它们的成果可与人类专家媲美，并且在某些情况下胜过人类专家。<sup><a href=\"#quote_4\" class=\"kx_ref\">[4]</a></sup><sup><a href=\"#quote_5\" class=\"kx_ref\">[5]</a></sup><sup><a href=\"#quote_6\" class=\"kx_ref\">[6]</a></sup> </p>\n<p>神经网络受到生物系统中信息处理和分布式通信节点的启发。人工神经网络与生物大脑有各种不同。具体而言，神经网络往往是静态和象征性的，而大多数生物的大脑是动态(可塑)和模拟的。<sup><a href=\"#quote_7\" class=\"kx_ref\">[7]</a></sup><sup><a href=\"#quote_8\" class=\"kx_ref\">[8]</a></sup><sup><a href=\"#quote_9\" class=\"kx_ref\">[9]</a></sup> </p>","pics":null,"card":null,"references":[],"versionCount":0},"card":{"paragraphId":"0","title":null,"versionId":"0","lemmaId":0,"createType":0,"creator":null,"createTime":0,"versionEditor":null,"editTime":0,"comment":null,"dependVersionId":0,"contentType":0,"content":null,"pics":null,"card":null,"references":null,"versionCount":0},"categories":[{"id":1,"name":"计算机","parents":[]}],"creator":{"uid":10145103,"name":"柚子otto","pic":"https://web.archive.org/web/20221025113558/https://img02.sogoucdn.com/app/a/200698/1152_1152_1864088_20200427232849-1518843971.png","introduction":"","educations":[{"schoolName":"中国地质大学（北京）","major":"","degree":"本科","universityId":22,"universityLogo":"https://web.archive.org/web/20221025113558/https://img01.sogoucdn.com/app/a/200943/d3465c1c-6011-11e9-b353-fc4dd4f70029","majorLevel1":"理学","majorLevel2":"地理学","majorLevel3":"地图学与地理信息系统","majorLevel1Id":1,"majorLevel2Id":103,"majorLevel3Id":109,"state":"毕业","lab":"","researchField":""}],"jobs":[{"company":"搜狗","title":"产品经理"}],"works":null,"educationBrief":"中国地质大学（北京）","jobBrief":"产品经理","role":0,"roleName":null,"title":"中国地质大学（北京） · 地理学本科","professionalTitle":null,"phoneNo":null,"editable":true,"partnerId":139,"partnerIdCreateTime":1595844881,"partnerIdPoped":true},"createTime":1569227178,"editor":{"uid":10145103,"name":"柚子otto","pic":"https://web.archive.org/web/20221025113558/https://img02.sogoucdn.com/app/a/200698/1152_1152_1864088_20200427232849-1518843971.png","introduction":"","educations":[{"schoolName":"中国地质大学（北京）","major":"","degree":"本科","universityId":22,"universityLogo":"https://web.archive.org/web/20221025113558/https://img01.sogoucdn.com/app/a/200943/d3465c1c-6011-11e9-b353-fc4dd4f70029","majorLevel1":"理学","majorLevel2":"地理学","majorLevel3":"地图学与地理信息系统","majorLevel1Id":1,"majorLevel2Id":103,"majorLevel3Id":109,"state":"毕业","lab":"","researchField":""}],"jobs":[{"company":"搜狗","title":"产品经理"}],"works":null,"educationBrief":"中国地质大学（北京）","jobBrief":"产品经理","role":0,"roleName":null,"title":"中国地质大学（北京） · 地理学本科","professionalTitle":null,"phoneNo":null,"editable":true,"partnerId":139,"partnerIdCreateTime":1595844881,"partnerIdPoped":true},"editTime":1576233924,"state":1,"versionCount":2,"upNum":24,"downNum":0,"pics":[{"originalUrl":"https://web.archive.org/web/20221025113558/https://img04.sogoucdn.com/app/a/200698/sogou_science_11667?w=300&h=339&titlename=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%B8%AA%E5%AD%90%E9%9B%86%EF%BC%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%98%AF%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%AD%90%E9%9B%86","url":"https://web.archive.org/web/20221025113558/https://img04.sogoucdn.com/app/a/200698/sogou_science_11667","rw":300,"rh":339,"title":"深度学习是机器学习的一个子集，机器学习是人工智能的子集","alt":null,"width":0,"height":0}],"catalogs":[{"level":1,"title":"定义","paragraphId":"14995109447729414","subCatalogs":null},{"level":1,"title":"概览","paragraphId":"14995109464506635","subCatalogs":null},{"level":1,"title":"解释","paragraphId":"14995109464506636","subCatalogs":null},{"level":1,"title":"历史","paragraphId":"14995109481283848","subCatalogs":[{"level":2,"title":"深度学习革命","paragraphId":"14995109481283848","subCatalogs":null}]},{"level":1,"title":"神经网络","paragraphId":"14995109514838287","subCatalogs":[{"level":2,"title":"人工神经网络","paragraphId":"14995109514838287","subCatalogs":null},{"level":2,"title":"深度神经网络","paragraphId":"14995109514838287","subCatalogs":null}]},{"level":1,"title":"应用","paragraphId":"14995109514838288","subCatalogs":[{"level":2,"title":"自动语音识别","paragraphId":"14995109514838288","subCatalogs":null},{"level":2,"title":"图像识别","paragraphId":"14995109514838288","subCatalogs":null},{"level":2,"title":"视觉艺术处理","paragraphId":"14995109514838288","subCatalogs":null},{"level":2,"title":"自然语言处理","paragraphId":"14995109514838288","subCatalogs":null},{"level":2,"title":"药物发现和毒理学","paragraphId":"14995109514838288","subCatalogs":null},{"level":2,"title":"客户关系管理","paragraphId":"14995109514838288","subCatalogs":null},{"level":2,"title":"推荐系统","paragraphId":"14995109514838288","subCatalogs":null},{"level":2,"title":"生物信息学","paragraphId":"14995109514838288","subCatalogs":null},{"level":2,"title":"医学图像分析","paragraphId":"14995109514838288","subCatalogs":null},{"level":2,"title":"手机广告","paragraphId":"14995109514838288","subCatalogs":null},{"level":2,"title":"图像恢复","paragraphId":"14995109514838288","subCatalogs":null},{"level":2,"title":"金融欺诈检测","paragraphId":"14995109514838288","subCatalogs":null},{"level":2,"title":"军队","paragraphId":"14995109514838288","subCatalogs":null}]},{"level":1,"title":"与人类认知和大脑发育的关系","paragraphId":"14995109531615498","subCatalogs":null},{"level":1,"title":"商业活动","paragraphId":"14995109548392712","subCatalogs":null},{"level":1,"title":"批判和议论","paragraphId":"14995109565169923","subCatalogs":[{"level":2,"title":"理论","paragraphId":"14995109565169923","subCatalogs":null},{"level":2,"title":"错误","paragraphId":"14995109565169923","subCatalogs":null},{"level":2,"title":"网络威胁","paragraphId":"14995109565169923","subCatalogs":null}]},{"level":1,"title":"参考文献","paragraphId":"-1","subCatalogs":null}],"paragraphs":[{"paragraphId":"14995109447729414","title":"定义","versionId":"14995350385328392","lemmaId":10438,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233924,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>深度学习是一类机器学习算法：<sup><a href=\"#quote_10\" class=\"kx_ref\">[10]</a></sup> 使用多个层逐步从原始输入中逐步提取更高级别的特征。例如，在图像处理中，较低层可以识别边缘，而较高层可以识别对人类有意义的部分，例如数字/字母或面部。 </p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995109464506635","title":"概览","versionId":"14995350385328393","lemmaId":10438,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233924,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>大多数现代的深度学习模型基于人工神经网络，特别是卷积神经网络（CNN），尽管它们也可以包括命题公式或在深度生成模型中逐层组织的潜变量，例如深度信念网络和深度玻尔兹曼机中的节点。<sup><a href=\"#quote_11\" class=\"kx_ref\">[11]</a></sup> </p>\n<p>在深度学习中，每一级学习将其输入数据转换成稍微抽象和复合的表示。在图像识别应用中，原始输入可以是像素矩阵；第一代表层可以提取像素并编码边缘；第二层可以组成和编码边缘排列；第三层可以编码鼻子和眼睛；并且第四层可以识别包含人脸的图像。重要的是，深入的学习过程可以学习将哪些特征放在哪个级别上是最优的。(当然，这并不能完全避免需要手动调整；例如，不同的层数和层大小可以提供不同程度的抽象。)<sup><a href=\"#quote_1\" class=\"kx_ref\">[1]</a></sup><sup><a href=\"#quote_12\" class=\"kx_ref\">[12]</a></sup> </p>\n<p>“深度学习”中的“深度”是指数据转换的层数。更准确地说，深度学习系统有一个实质的<i>信用分配路径 （CAP）</i>深度。CAP是从输入到输出的转换链。CAP描述了输入和输出之间潜在的因果关系。对于前馈神经网络，CAP的深度是网络的深度，等于隐藏层的数量加上1(因为输出层也是参数化的)。对于递归神经网络，其中信号可能不止一次地通过一个层传播，CAP深度可能是无限的。<sup><a href=\"#quote_2\" class=\"kx_ref\">[2]</a></sup>没有普遍认同的深度阈值将浅层和深度学习区分开来，但是大多数研究者认同深度学习中的CAP深度&gt;2。深度为2的CAP已被证明是一个通用逼近器，因为它可以模拟任何函数。除此之外，更多的层不会增加网络的函数逼近能力。深度模型（CAP &gt; 2）能够提取比浅层模型更好的特征，因此，额外的层有助于学习特征。 </p>\n<p>深度学习架构通常是用贪婪逐层方法构建的。深度学习有助于理清这些抽象概念，并找出哪些特性可以提高性能。<sup><a href=\"#quote_1\" class=\"kx_ref\">[1]</a></sup> </p>\n<p>对于监督学习任务，深度学习方法通过将数据转换成类似于主成分的紧凑中间表示，并导出消除冗余表示后的分层结构，从而避免了特征工程。 </p>\n<p>深度学习算法可以应用于无监督的学习任务。这是一个重要的好处，因为未标记的数据比标记的数据更丰富。可以无监督方式训练的深层结构的例子有神经历史压缩器<sup><a href=\"#quote_13\" class=\"kx_ref\">[13]</a></sup>和深度信念网络。<sup><a href=\"#quote_1\" class=\"kx_ref\">[1]</a></sup><sup><a href=\"#quote_14\" class=\"kx_ref\">[14]</a></sup> </p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995109464506636","title":"解释","versionId":"14995350385328394","lemmaId":10438,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233924,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>深度神经网络通常用万能近似定理或者概率推理<sup><a href=\"#quote_10\" class=\"kx_ref\">[10]</a></sup><sup><a href=\"#quote_11\" class=\"kx_ref\">[11]</a></sup><sup><a href=\"#quote_1\" class=\"kx_ref\">[1]</a></sup><sup><a href=\"#quote_2\" class=\"kx_ref\">[2]</a></sup><sup><a href=\"#quote_14\" class=\"kx_ref\">[14]</a></sup><sup><a href=\"#quote_15\" class=\"kx_ref\">[15]</a></sup><sup><a href=\"#quote_16\" class=\"kx_ref\">[16]</a></sup>来解释。<sup><a href=\"#quote_17\" class=\"kx_ref\">[17]</a></sup><sup><a href=\"#quote_18\" class=\"kx_ref\">[18]</a></sup><sup><a href=\"#quote_19\" class=\"kx_ref\">[19]</a></sup><sup><a href=\"#quote_20\" class=\"kx_ref\">[20]</a></sup><sup><a href=\"#quote_21\" class=\"kx_ref\">[21]</a></sup><sup><a href=\"#quote_22\" class=\"kx_ref\">[22]</a></sup> </p>\n<p>经典的万用近似定理关注具有有限大小的单个隐藏层的前馈神经网络逼近连续函数的能力。<sup><a href=\"#quote_17\" class=\"kx_ref\">[17]</a></sup><sup><a href=\"#quote_18\" class=\"kx_ref\">[18]</a></sup><sup><a href=\"#quote_19\" class=\"kx_ref\">[19]</a></sup><sup><a href=\"#quote_20\" class=\"kx_ref\">[20]</a></sup><sup><a href=\"#quote_21\" class=\"kx_ref\">[21]</a></sup>1989年，乔治·赛本科发表了关于sigmoid激活函数的首个证明<sup><a href=\"#quote_18\" class=\"kx_ref\">[18]</a></sup>，库尔特·霍尼克在1991年将其推广到前馈多层体系结构。<sup><a href=\"#quote_19\" class=\"kx_ref\">[19]</a></sup> </p>\n<p>深度神经网络的万用近似定理涉及有限宽度但深度可增长的网络的容量。Lu等人<sup><a href=\"#quote_22\" class=\"kx_ref\">[22]</a></sup>证明了如果具有ReLU激活的深度神经网络的宽度严格大于输入维数，则网络可以近似任何勒贝格可积函数；如果宽度小于或等于输入维数，那么深度神经网络不是一个通用逼近器。 </p>\n<p>概率解释<sup><a href=\"#quote_15\" class=\"kx_ref\">[15]</a></sup>源自机器学习领域。它的特点是推理，<sup><a href=\"#quote_10\" class=\"kx_ref\">[10]</a></sup><sup><a href=\"#quote_11\" class=\"kx_ref\">[11]</a></sup><sup><a href=\"#quote_1\" class=\"kx_ref\">[1]</a></sup><sup><a href=\"#quote_2\" class=\"kx_ref\">[2]</a></sup><sup><a href=\"#quote_14\" class=\"kx_ref\">[14]</a></sup><sup><a href=\"#quote_15\" class=\"kx_ref\">[15]</a></sup>以及分别与拟合和泛化相关的训练和测试的优化概念。更具体地说，概率解释将非线性激活函数视为累积分布函数。<sup><a href=\"#quote_15\" class=\"kx_ref\">[15]</a></sup>概率解释导致在神经网络中引入损失作为正则化。<sup><a href=\"#quote_23\" class=\"kx_ref\">[23]</a></sup>概率解释由霍普菲尔德、维卓尔和纳伦德拉等研究人员引入，并在毕晓普等人的调查中得到推广。<sup><a href=\"#quote_24\" class=\"kx_ref\">[24]</a></sup> </p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995109481283848","title":"历史","versionId":"14995350385328395","lemmaId":10438,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233924,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p><i>深度学习</i>这个术语由Rina Dechter于1986年引入机器学习社区，<sup><a href=\"#quote_25\" class=\"kx_ref\">[25]</a></sup><sup><a href=\"#quote_13\" class=\"kx_ref\">[13]</a></sup>伊戈尔·艾森堡和他的同事于2000年在布尔阈值神经元的背景下引入人工神经网络。<sup><a href=\"#quote_26\" class=\"kx_ref\">[26]</a></sup><sup><a href=\"#quote_27\" class=\"kx_ref\">[27]</a></sup> </p>\n<p>Alexey Ivakhnenko和帕拉在1965年发表了第一个用于监督的、深度的、前馈的多层感知器的通用工作学习算法。<sup><a href=\"#quote_28\" class=\"kx_ref\">[28]</a></sup>1971年的一篇论文描述了一个由数据处理算法的分组方法训练的8层深度网络。<sup><a href=\"#quote_29\" class=\"kx_ref\">[29]</a></sup> </p>\n<p>其他深度学习工作架构，特别是那些为计算机视觉而构建的架构，始于1980年由福岛国彦引入的神经认知机。<sup><a href=\"#quote_30\" class=\"kx_ref\">[30]</a></sup>1989年，扬·勒丘恩等人对深度神经网络应用了标准的反向传播算法，这种算法自1970年以来一直是自动微分的反向模式，<sup><a href=\"#quote_31\" class=\"kx_ref\">[31]</a></sup><sup><a href=\"#quote_32\" class=\"kx_ref\">[32]</a></sup><sup><a href=\"#quote_33\" class=\"kx_ref\">[33]</a></sup><sup><a href=\"#quote_34\" class=\"kx_ref\">[34]</a></sup>目的是识别邮件上手写的邮政编码。算法工作需要3天的训练。<sup><a href=\"#quote_35\" class=\"kx_ref\">[35]</a></sup> </p>\n<p>到1991年，这种系统被用于识别孤立的二维手写数字，而识别三维物体是通过将二维图像与手工制作的三维物体模型相匹配来完成的。翁等人提出人脑并不使用单一的三维对象模型，1992年，他们发表了Cresceptron，<sup><a href=\"#quote_36\" class=\"kx_ref\">[36]</a></sup><sup><a href=\"#quote_37\" class=\"kx_ref\">[37]</a></sup><sup><a href=\"#quote_38\" class=\"kx_ref\">[38]</a></sup>一种在复杂场景中进行三维物体识别的方法。因为它直接使用自然图像，Cresceptron开启了自然3D世界的通用视觉学习。与神经认知机相似，Cresceptron是一多层的级联。但是，虽然神经认知机需要人类程序员手工合并特征，Cresceptron却在没有监督的情况下在每一层中学习了大量的特征，其中每个特征都由卷积核表示。Cresceptron通过网络进行反分析，从杂乱的场景中分割出每个学习对象。最大池化(Max pooling)现在经常被深度神经网络采用(例如图像网测试)，最早在Cresceptron中通过级联用来将位置分辨率降低(2x2)到1倍，以便更好地泛化。 </p>\n<p>1994年，安德烈德·卡瓦略与迈克·法尔赫斯特和大卫·比塞特一起发表了多层布尔神经网络（也称为失重神经网络）的实验结果，该网络由三层自组织特征提取神经网络模块(SOFT)和多层分类神经网络模块（GSN）组成，并经过独立训练。特征提取模块中的每一层提取的特征与前一层相比更加复杂。<sup><a href=\"#quote_39\" class=\"kx_ref\">[39]</a></sup> </p>\n<p>1995年，布兰登·弗雷证明，使用由彼得·达扬和辛顿共同开发的唤醒睡眠算法，可以训练(超过两天)一个包含六个全连接的层和数百个隐藏单元的网络。<sup><a href=\"#quote_40\" class=\"kx_ref\">[40]</a></sup>许多因素导致了速度的缓慢，包括Sepp Hochreiter在1991年分析的梯度消失问题。<sup><a href=\"#quote_41\" class=\"kx_ref\">[41]</a></sup><sup><a href=\"#quote_42\" class=\"kx_ref\">[42]</a></sup> </p>\n<p>由于人工神经网络的计算成本和对大脑如何连接生物网络缺乏理解，使用特定任务的手工特征（如Gabor滤波器和支持向量机）的简单模型在20世纪90年代和2000年代是一个流行的选择。 </p>\n<p>人工神经网络的浅层和深度学习(如循环网络)经历了多年的探索。<sup><a href=\"#quote_43\" class=\"kx_ref\">[43]</a></sup><sup><a href=\"#quote_44\" class=\"kx_ref\">[44]</a></sup><sup><a href=\"#quote_45\" class=\"kx_ref\">[45]</a></sup>这些方法从未优于非均匀内部手工高斯混合模型/隐马尔可夫模型（HMM）技术，它们基于区别训练的语音生成模型。包括梯度递减<sup><a href=\"#quote_41\" class=\"kx_ref\">[41]</a></sup>和神经预测模型中的弱时间相关结构在内的<sup><a href=\"#quote_46\" class=\"kx_ref\">[46]</a></sup>关键困难也已经得到分析。<sup><a href=\"#quote_47\" class=\"kx_ref\">[47]</a></sup><sup><a href=\"#quote_48\" class=\"kx_ref\">[48]</a></sup>另外的困难是缺乏训练数据和有限的计算能力。 </p>\n<p>大多数语音识别研究人员从神经网络转向了生成模型。一个例外是20世纪90年代末的斯坦福国际研究院（SRI International）。在美国国家安全局和美国国防部高级研究计划局的资助下，SRI研究了语音和说话人识别中的深度神经网络。Heck的说话人识别团队在1998年的国家标准与技术研究所说话人识别评估中，首次在语音处理中使用深度神经网络取得了重大成功。<sup><a href=\"#quote_49\" class=\"kx_ref\">[49]</a></sup>虽然SRI在说话人识别中使用深度神经网络取得了成功，但在语音识别中却没有取得类似的成功。在20世纪90年代后期的“原始”谱图或线性滤波器组特征的深度自动编码器的架构中，首次成功地探索到将“原始”特征提升到手工优化之上的原理，<sup><a href=\"#quote_49\" class=\"kx_ref\">[49]</a></sup>并表现出它优于包含光谱图固定变换阶段的Mel-Cepstral特征。语音、波形的原始特征后来产生了大规模卓越成果。<sup><a href=\"#quote_50\" class=\"kx_ref\">[50]</a></sup> </p>\n<p>语音识别的许多方面被一种叫做长短期记忆(LSTM)的深度学习方法所取代，这是一种由霍克雷特和施密休伯在1997年发表的循环神经网络。<sup><a href=\"#quote_51\" class=\"kx_ref\">[51]</a></sup>LSTM神经网络避免了梯度消失问题，可以学习“非常深入学习”任务<sup><a href=\"#quote_2\" class=\"kx_ref\">[2]</a></sup>，这需要对之前发生的几千个离散时间步长的事件进行记忆，这对语音识别很重要。2003年，LSTM开始在某些特定任务上与传统的语音识别器竞争。<sup><a href=\"#quote_52\" class=\"kx_ref\">[52]</a></sup>后来，它与联结主义时间分类(CTC)相结合<sup><a href=\"#quote_53\" class=\"kx_ref\">[53]</a></sup>为成堆的LSTM循环神经网络。<sup><a href=\"#quote_54\" class=\"kx_ref\">[54]</a></sup> 据报道，在2015年，谷歌的语音识别通过CTC的LSTM产生了49%的惊人性能提升，并将它用于Google语音搜索。<sup><a href=\"#quote_55\" class=\"kx_ref\">[55]</a></sup> </p>\n<p>2006年，杰夫·辛顿、鲁斯兰·萨拉赫丁诺夫、奥辛德罗和特赫的出版物<sup><a href=\"#quote_56\" class=\"kx_ref\">[56]</a></sup><sup><a href=\"#quote_57\" class=\"kx_ref\">[57]</a></sup><sup><a href=\"#quote_58\" class=\"kx_ref\">[58]</a></sup>展示了多层前馈神经网络如何有效地一次预训练一层，依次将每层视为无监督的受限玻尔兹曼机，然后使用有监督的反向传播对其进行微调。<sup><a href=\"#quote_59\" class=\"kx_ref\">[59]</a></sup>他们的论文参考了<i>《learning for deep belief nets》。</i> </p>\n<p>深度学习是各学科最先进系统的一部分，特别是计算机视觉和自动语音识别(ASR)。TIMIT（ASR）和MNIST（图像分类）等常用评估集以及一系列大词汇量语音识别任务的结果都在稳步改善。<sup><a href=\"#quote_60\" class=\"kx_ref\">[60]</a></sup><sup><a href=\"#quote_61\" class=\"kx_ref\">[61]</a></sup><sup><a href=\"#quote_62\" class=\"kx_ref\">[62]</a></sup>ASR中的卷积神经网络被CTC取代<sup><a href=\"#quote_53\" class=\"kx_ref\">[53]</a></sup>为LSTM。<sup><a href=\"#quote_51\" class=\"kx_ref\">[51]</a></sup><sup><a href=\"#quote_55\" class=\"kx_ref\">[55]</a></sup><sup><a href=\"#quote_63\" class=\"kx_ref\">[63]</a></sup><sup><a href=\"#quote_64\" class=\"kx_ref\">[64]</a></sup><sup><a href=\"#quote_65\" class=\"kx_ref\">[65]</a></sup><sup><a href=\"#quote_66\" class=\"kx_ref\">[66]</a></sup><sup><a href=\"#quote_67\" class=\"kx_ref\">[67]</a></sup>但是在计算机视觉方面取得了更大成功。 </p>\n<p>据扬·勒丘恩称，行业中深度学习的影响始于21世纪初，当时CNN已经处理了大约10%至20%的美国手写支票。<sup><a href=\"#quote_68\" class=\"kx_ref\">[68]</a></sup>深度学习在大规模语音识别中的产业应用始于2010年左右。 </p>\n<p>2009年NIPS语音识别深度学习大会<sup><a href=\"#quote_69\" class=\"kx_ref\">[69]</a></sup>的动机是深层语音生成模型的局限性，以及给定更强力的硬件和大规模数据集使得深层神经网络（DNN）变实用的可能性。人们认为，使用深层信念网络（DBN）的生成模型预先训练深度神经网络将克服神经网络的主要困难。<sup><a href=\"#quote_70\" class=\"kx_ref\">[70]</a></sup>然而，当使用具有大的上下文相关输出层的深度神经网络时，发现用大量训练数据代替预训练用于直接反向传播，产生的错误率大大低于当时最先进的高斯混合模型(GMM)/隐马尔可夫模型(HMM)，也低于更先进的基于生成模型的系统。<sup><a href=\"#quote_60\" class=\"kx_ref\">[60]</a></sup><sup><a href=\"#quote_71\" class=\"kx_ref\">[71]</a></sup>这两种系统产生的识别错误的性质是不同的，<sup><a href=\"#quote_72\" class=\"kx_ref\">[72]</a></sup><sup><a href=\"#quote_69\" class=\"kx_ref\">[69]</a></sup>这为如何将深度学习集成到所有主要语音识别系统部署的现有高效运行语音解码系统中提供了技术见解。<sup><a href=\"#quote_10\" class=\"kx_ref\">[10]</a></sup><sup><a href=\"#quote_73\" class=\"kx_ref\">[73]</a></sup><sup><a href=\"#quote_74\" class=\"kx_ref\">[74]</a></sup>2009-2010年左右的分析对比了GMM（和其他生成性语音模型）和DNN模型，刺激了早期产业对语音识别深度学习的投资，<sup><a href=\"#quote_72\" class=\"kx_ref\">[72]</a></sup><sup><a href=\"#quote_69\" class=\"kx_ref\">[69]</a></sup>最终导致该行业的普遍和主导使用。这一分析是在判别性DNN和生成性模型之间进行的，他们具有相当的性能（错误率不到1.5%）。<sup><a href=\"#quote_60\" class=\"kx_ref\">[60]</a></sup><sup><a href=\"#quote_72\" class=\"kx_ref\">[72]</a></sup><sup><a href=\"#quote_70\" class=\"kx_ref\">[70]</a></sup><sup><a href=\"#quote_75\" class=\"kx_ref\">[75]</a></sup> </p>\n<p>2010年，研究人员基于决策树构造的上下文相关隐马尔可夫模型，采用DNN的大输出层，将TIMIT的深度学习扩展到大词汇量语音识别。<sup><a href=\"#quote_76\" class=\"kx_ref\">[76]</a></sup><sup><a href=\"#quote_77\" class=\"kx_ref\">[77]</a></sup><sup><a href=\"#quote_78\" class=\"kx_ref\">[78]</a></sup><sup><a href=\"#quote_73\" class=\"kx_ref\">[73]</a></sup> </p>\n<p>硬件的发展使人们重新燃起了兴趣。2009年，英伟达参与了所谓的深度学习“大爆炸”，因为深度学习神经网络是由英伟达图形处理单元(GPU)训练的。<sup><a href=\"#quote_79\" class=\"kx_ref\">[79]</a></sup>那一年，谷歌大脑使用英伟达GPU创建了高性能深度神经网络。其中吴恩达确定GPU可以将深度学习系统的速度提高大约100倍。<sup><a href=\"#quote_80\" class=\"kx_ref\">[80]</a></sup>具体而言，GPU非常适合机器学习中涉及的矩阵/向量数学。<sup><a href=\"#quote_81\" class=\"kx_ref\">[81]</a></sup><sup><a href=\"#quote_82\" class=\"kx_ref\">[82]</a></sup>GPU能将训练算法的速度提高几个数量级，将运行时间从数周缩短到数天。<sup><a href=\"#quote_83\" class=\"kx_ref\">[83]</a></sup><sup><a href=\"#quote_84\" class=\"kx_ref\">[84]</a></sup>专用硬件和算法优化可用于高效处理。<sup><a href=\"#quote_85\" class=\"kx_ref\">[85]</a></sup> </p> \n<h3>深度学习革命</h3> \n<p></p><p><img alt=\"\" class=\"fileimage kx_img ed_imgfloat_right\" img_height=\"339\" img_width=\"300\" titlename=\"深度学习是机器学习的一个子集，机器学习是人工智能的子集\" data-src=\"https://img04.sogoucdn.com/app/a/200698/sogou_science_11667\"> </p><p></p> \n<p>2012年，达尔领导的团队利用多任务深层神经网络预测一种药物的生物分子靶并以此赢得了“默克分子活性挑战”。<sup><a href=\"#quote_86\" class=\"kx_ref\">[86]</a></sup><sup><a href=\"#quote_87\" class=\"kx_ref\">[87]</a></sup>2014年，霍克雷特的团队利用深度学习来检测营养素、家用产品和药物中环境化学品的脱靶和毒性效应，并赢得了美国国家卫生研究院、美国食品和药物管理局和NCATS的“Tox21数据挑战”。<sup><a href=\"#quote_88\" class=\"kx_ref\">[88]</a></sup><sup><a href=\"#quote_89\" class=\"kx_ref\">[89]</a></sup><sup><a href=\"#quote_90\" class=\"kx_ref\">[90]</a></sup> </p>\n<p>从2011年到2012年，深度学习在图像或物体识别方面产生了显著的额外影响。虽然通过反向传播训练的卷积神经网络已经出现了几十年，GPU实现的网络也已经出现了几年，包括卷积伸进网络，但要在计算机视觉上取得进展，还需要以Ciresan和同事的方式在GPU上实现最大池化的快速网络。<sup><a href=\"#quote_81\" class=\"kx_ref\">[81]</a></sup><sup><a href=\"#quote_82\" class=\"kx_ref\">[82]</a></sup><sup><a href=\"#quote_35\" class=\"kx_ref\">[35]</a></sup><sup><a href=\"#quote_91\" class=\"kx_ref\">[91]</a></sup><sup><a href=\"#quote_2\" class=\"kx_ref\">[2]</a></sup>2011年，这种方法首次在视觉模式识别竞赛中实现了惊人的表现。同为2011年，它赢得了ICDAR中文手写比赛，并在2012年5月赢得了ISBI图像分割比赛。<sup><a href=\"#quote_92\" class=\"kx_ref\">[92]</a></sup>直到2011年，卷积神经网络还没有在计算机视觉会议上大展拳脚，但在2012年6月，Ciresan等人在CVPR的主要会议上发表了一篇论文<sup><a href=\"#quote_4\" class=\"kx_ref\">[4]</a></sup>说明了如何在GPU上最大限度地汇集CNN可以显著改善许多视觉基准记录。2012年10月，克里兹夫斯基等人提出了一个类似的系统。<sup><a href=\"#quote_5\" class=\"kx_ref\">[5]</a></sup>在大规模的图像网竞赛中以绝对优势战胜了浅层机器学习方法。2012年11月，西雷森等人的系统还在ICPR癌症检测大型医学图像分析竞赛中胜出，并在第二年赢得了同一主题的MICCAI大挑战。<sup><a href=\"#quote_93\" class=\"kx_ref\">[93]</a></sup>在2013年和2014年，使用深度学习的图像网任务的错误率进一步降低，这与大规模语音识别的趋势相近。沃尔夫勒姆图像识别项目公布了这些改进。<sup><a href=\"#quote_94\" class=\"kx_ref\">[94]</a></sup> </p>\n<p>然后，图像分类被扩展到更具挑战性的任务，为图像生成描述（字幕），通常是由CNN和LSTM的组合进行。<sup><a href=\"#quote_95\" class=\"kx_ref\">[95]</a></sup><sup><a href=\"#quote_96\" class=\"kx_ref\">[96]</a></sup><sup><a href=\"#quote_97\" class=\"kx_ref\">[97]</a></sup><sup><a href=\"#quote_98\" class=\"kx_ref\">[98]</a></sup> </p>\n<p>一些研究人员估计，2012年10月图像网的胜利标志着一场“深度学习革命”的开始，这场革命改变了人工智能行业。<sup><a href=\"#quote_99\" class=\"kx_ref\">[99]</a></sup> </p>\n<p>2019年3月，约书亚·本希奥、杰弗里·辛顿和扬·勒丘恩因概念和工程突破而被授予图灵奖，这些突破使深度神经网络成为计算的关键组成部分。 </p>","pics":[{"originalUrl":"https://web.archive.org/web/20221025113558/https://img04.sogoucdn.com/app/a/200698/sogou_science_11667?w=300&h=339&titlename=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%B8%AA%E5%AD%90%E9%9B%86%EF%BC%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%98%AF%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%AD%90%E9%9B%86","url":"https://web.archive.org/web/20221025113558/https://img04.sogoucdn.com/app/a/200698/sogou_science_11667","rw":300,"rh":339,"title":"深度学习是机器学习的一个子集，机器学习是人工智能的子集","alt":null,"width":0,"height":0}],"card":null,"references":[],"versionCount":0},{"paragraphId":"14995109514838287","title":"神经网络","versionId":"14995350385328396","lemmaId":10438,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233924,"comment":null,"dependVersionId":0,"contentType":1,"content":"<h3>人工神经网络</h3> \n<p>人工神经网络（ANN）或联结系统是由构成动物大脑的生物神经网络启发的计算系统。这种系统通过考虑示例来学习（逐步提高它们的能力）完成任务，通常不需要特定任务的编程。例如，在图像识别中，他们可以通过分析手动标记为“猫”或“没有猫”的示例图像，并使用分析结果来识别其他图像中的猫，从而学会识别包含猫的图像。它们大多数使用于很难用传统的基于规则编程的计算机算法来表达的应用。 </p>\n<p>人工神经网络基于被称为人造神经元的连接单元的集合（类似于生物大脑中的生物神经元）。神经元之间的每个连接(突触)都可以向另一个神经元传递信号。接收（后突触）神经元可以处理信号，然后向与之相连的下游神经元发送信号。神经元可能有状态，通常用实数表示，一般在0和1之间。神经元和突触的权重也可能随着学习的进行而变化，这会增加或减少它向下游发送的信号的强度。 </p>\n<p>通常，神经元是分层组织的。不同的层可以对它们的输入执行不同种类的转换。信号可能在多次穿过这些层之后从第一（输入）层传播到最后一个（输出）层。 </p>\n<p>神经网络方法的起初目的是像人脑一样解决问题。随着时间的推移，重心集中在匹配特定的思维能力上，导致与生物学的偏差，例如反向传播，或者以相反的方向传递信息，并调整网络以反映这些信息。 </p>\n<p>神经网络已经用于各种任务，包括计算机视觉、语音识别、机器翻译、社交网络过滤、棋盘和视频游戏以及医学诊断。 </p>\n<p>截至2017年，神经网络通常有几千到几百万个单元和几百万个连接。尽管这个数字比人脑中的神经元数量少几个数量级，但这些网络可以在超出人类水平的水平上执行许多任务（例如，人脸识别，下围棋<sup><a href=\"#quote_100\" class=\"kx_ref\">[100]</a></sup> )。 </p> \n<h3>深度神经网络</h3> \n<p>深度神经网络（DNN）是一个在输入层和输出层之间有多层的人工神经网络。<sup><a href=\"#quote_11\" class=\"kx_ref\">[11]</a></sup><sup><a href=\"#quote_2\" class=\"kx_ref\">[2]</a></sup>DNN找到了将输入转化为输出的正确数学操作，无论是线性关系还是非线性关系。网络遍历各层并计算每个输出的概率。例如，被训练识别狗品种的DNN将检查给定的图像，并计算图像中的狗是某个品种的概率。用户可以查看结果并选择网络应显示的概率（高于某个阈值等）并返回建议的标签。每一个这样的数学操作都被认为是一个层，而复杂的DNN有许多层次，因此被称为“深度”网络。 </p>\n<p>DNN可以模拟复杂的非线性关系。DNN架构生成组合模型，其中对象被表示为图元的分层组合。<sup><a href=\"#quote_101\" class=\"kx_ref\">[101]</a></sup>额外的层使得能够从较低层合成特征，用比执行类似操作的浅层网络更少的单元来建模复杂数据。<sup><a href=\"#quote_11\" class=\"kx_ref\">[11]</a></sup> </p>\n<p>深层架构包括一些基本方法的许多变体。每个架构都在特定领域取得了成功。除非对相同的数据集进行了评估，否则不可能总能比较多个体系结构的性能。 </p>\n<p>DNN是一种典型的前馈网络，数据从输入层流向输出层而不返回。首先，DNN创建了一个虚拟神经元的映射，并为它们之间的联系分配随机数值或者说“权重”。权重和输入相乘，返回0到1之间的输出。如果网络不能准确识别特定模式，算法会调整权重。<sup><a href=\"#quote_102\" class=\"kx_ref\">[102]</a></sup>这样，算法可以使某些参数更有影响力，直到它确定正确的数学操作来完全处理数据。 </p>\n<p>循环神经网络（RNN）中数据可以向任何方向流动，用于诸如语言建模的应用。<sup><a href=\"#quote_103\" class=\"kx_ref\">[103]</a></sup><sup><a href=\"#quote_104\" class=\"kx_ref\">[104]</a></sup><sup><a href=\"#quote_105\" class=\"kx_ref\">[105]</a></sup><sup><a href=\"#quote_106\" class=\"kx_ref\">[106]</a></sup><sup><a href=\"#quote_107\" class=\"kx_ref\">[107]</a></sup>长短期记忆在这方面特别有效。<sup><a href=\"#quote_51\" class=\"kx_ref\">[51]</a></sup><sup><a href=\"#quote_108\" class=\"kx_ref\">[108]</a></sup> </p>\n<p>深度卷积神经网络用于计算机视觉。<sup><a href=\"#quote_109\" class=\"kx_ref\">[109]</a></sup> CNN也被用于自动语音识别（ASR）的声学建模。<sup><a href=\"#quote_67\" class=\"kx_ref\">[67]</a></sup> </p> \n<p><strong>挑战</strong></p> \n<p>与人工神经网络一样，训练不完善的深度神经网络中可能会出现许多问题。两个常见的问题是过拟合和计算时间。 </p>\n<p>DNN倾向于过拟合，因为增加了抽象层，允许它们对训练数据中罕见的依赖关系建模。正则化方法如Ivakhnenko的单元剪枝<sup><a href=\"#quote_29\" class=\"kx_ref\">[29]</a></sup>或者权重衰减（<span class=\"kx_formula\" alt=\"{\\displaystyle \\ell _{2}}\">\n  <svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" style=\"fill-opacity:1; color-rendering:auto; color-interpolation:auto; text-rendering:auto; stroke:black; stroke-linecap:square; stroke-miterlimit:10; shape-rendering:auto; stroke-opacity:1; fill:black; stroke-dasharray:none; font-weight:normal; stroke-width:1; font-family:&#39;Dialog&#39;; font-style:normal; stroke-linejoin:miter; font-size:12px; stroke-dashoffset:0; image-rendering:auto;\" width=\"16\" height=\"23\" xmlns=\"http://www.w3.org/2000/svg\" class=\"transfer_formula\">\n   <!--Generated by the Batik Graphics2D SVG Generator-->\n   <defs id=\"genericDefs\"></defs>\n   <g>\n    <g transform=\"scale(20,20) translate(0,0.8444)\" style=\"font-size:1px; text-rendering:geometricPrecision; color-rendering:optimizeQuality; image-rendering:optimizeQuality; font-family:&#39;jlm_cmmi10&#39;; color-interpolation:linearRGB;\">\n     <path style=\"stroke:none;\" d=\"M0.0156 -0.0938 L0.0156 -0.0938 L0.0938 -0.1719 Q0.0938 -0.3438 0.1719 -0.5156 Q0.2188 -0.6406 0.2812 -0.6875 Q0.3125 -0.7031 0.3438 -0.7031 Q0.3906 -0.7031 0.3906 -0.625 Q0.3906 -0.4688 0.2188 -0.2812 Q0.2031 -0.25 0.1719 -0.2188 Q0.1562 -0.2031 0.1562 -0.2031 Q0.1406 -0.1875 0.1406 -0.1406 Q0.1406 -0.0156 0.2031 -0.0156 Q0.2656 -0.0156 0.3438 -0.0938 Q0.3438 -0.0938 0.3594 -0.0938 Q0.3594 -0.0938 0.3594 -0.0781 Q0.3594 -0.0781 0.3125 -0.0312 L0.3125 -0.0312 Q0.3125 -0.0312 0.2969 -0.0312 Q0.25 0.0156 0.2031 0.0156 Q0.1094 0.0156 0.0938 -0.1406 Q0.0781 -0.125 0.0625 -0.1094 Q0.0312 -0.0781 0.0156 -0.0781 Q0.0156 -0.0781 0.0156 -0.0938 Q0.0156 -0.0938 0.0156 -0.0938 ZM0.1562 -0.2344 Q0.375 -0.4688 0.375 -0.625 Q0.375 -0.6875 0.3438 -0.6875 Q0.3125 -0.6875 0.2812 -0.625 L0.2812 -0.625 L0.2656 -0.5938 Q0.2031 -0.4688 0.1562 -0.25 L0.1562 -0.25 Q0.1562 -0.2344 0.1562 -0.2344 Z\"></path>\n    </g>\n    <g transform=\"matrix(20,0,0,20,0,0) translate(0.4167,0.9944) scale(0.07,0.07)\" style=\"font-size:1px; text-rendering:geometricPrecision; color-rendering:optimizeQuality; image-rendering:optimizeQuality; font-family:&#39;jlm_cmmi10&#39;; color-interpolation:linearRGB;\">\n     <path style=\"stroke:none;\" d=\"M4.5781 -1.2812 L4.125 0 L0.2188 0 L0.2188 -0.1875 Q1.9375 -1.75 2.6406 -2.75 Q3.3438 -3.75 3.3438 -4.5781 Q3.3438 -5.2031 2.9609 -5.6094 Q2.5781 -6.0156 2.0312 -6.0156 Q1.5469 -6.0156 1.1562 -5.7266 Q0.7656 -5.4375 0.5938 -4.8906 L0.4062 -4.8906 Q0.5312 -5.7969 1.0312 -6.2812 Q1.5312 -6.7656 2.2969 -6.7656 Q3.0938 -6.7656 3.6406 -6.2422 Q4.1875 -5.7188 4.1875 -5.0156 Q4.1875 -4.5156 3.9531 -4.0156 Q3.5781 -3.2188 2.7812 -2.3438 Q1.5625 -1.0156 1.25 -0.7344 L2.9844 -0.7344 Q3.5156 -0.7344 3.7266 -0.7734 Q3.9375 -0.8125 4.1094 -0.9375 Q4.2812 -1.0625 4.4062 -1.2812 L4.5781 -1.2812 Z\"></path>\n    </g>\n   </g>\n  </svg> </span>-正则化）或稀疏化（<span class=\"kx_formula\" alt=\"{\\displaystyle \\ell _{1}}\">\n  <svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" style=\"fill-opacity:1; color-rendering:auto; color-interpolation:auto; text-rendering:auto; stroke:black; stroke-linecap:square; stroke-miterlimit:10; shape-rendering:auto; stroke-opacity:1; fill:black; stroke-dasharray:none; font-weight:normal; stroke-width:1; font-family:&#39;Dialog&#39;; font-style:normal; stroke-linejoin:miter; font-size:12px; stroke-dashoffset:0; image-rendering:auto;\" width=\"15\" height=\"23\" xmlns=\"http://www.w3.org/2000/svg\" class=\"transfer_formula\">\n   <!--Generated by the Batik Graphics2D SVG Generator-->\n   <defs id=\"genericDefs\"></defs>\n   <g>\n    <g transform=\"scale(20,20) translate(0,0.8444)\" style=\"font-size:1px; text-rendering:geometricPrecision; color-rendering:optimizeQuality; image-rendering:optimizeQuality; font-family:&#39;jlm_cmmi10&#39;; color-interpolation:linearRGB;\">\n     <path style=\"stroke:none;\" d=\"M0.0156 -0.0938 L0.0156 -0.0938 L0.0938 -0.1719 Q0.0938 -0.3438 0.1719 -0.5156 Q0.2188 -0.6406 0.2812 -0.6875 Q0.3125 -0.7031 0.3438 -0.7031 Q0.3906 -0.7031 0.3906 -0.625 Q0.3906 -0.4688 0.2188 -0.2812 Q0.2031 -0.25 0.1719 -0.2188 Q0.1562 -0.2031 0.1562 -0.2031 Q0.1406 -0.1875 0.1406 -0.1406 Q0.1406 -0.0156 0.2031 -0.0156 Q0.2656 -0.0156 0.3438 -0.0938 Q0.3438 -0.0938 0.3594 -0.0938 Q0.3594 -0.0938 0.3594 -0.0781 Q0.3594 -0.0781 0.3125 -0.0312 L0.3125 -0.0312 Q0.3125 -0.0312 0.2969 -0.0312 Q0.25 0.0156 0.2031 0.0156 Q0.1094 0.0156 0.0938 -0.1406 Q0.0781 -0.125 0.0625 -0.1094 Q0.0312 -0.0781 0.0156 -0.0781 Q0.0156 -0.0781 0.0156 -0.0938 Q0.0156 -0.0938 0.0156 -0.0938 ZM0.1562 -0.2344 Q0.375 -0.4688 0.375 -0.625 Q0.375 -0.6875 0.3438 -0.6875 Q0.3125 -0.6875 0.2812 -0.625 L0.2812 -0.625 L0.2656 -0.5938 Q0.2031 -0.4688 0.1562 -0.25 L0.1562 -0.25 Q0.1562 -0.2344 0.1562 -0.2344 Z\"></path>\n    </g>\n    <g transform=\"matrix(20,0,0,20,0,0) translate(0.4167,0.9944) scale(0.07,0.07)\" style=\"font-size:1px; text-rendering:geometricPrecision; color-rendering:optimizeQuality; image-rendering:optimizeQuality; font-family:&#39;jlm_cmmi10&#39;; color-interpolation:linearRGB;\">\n     <path style=\"stroke:none;\" d=\"M1.1719 -5.9688 L2.7812 -6.7656 L2.9375 -6.7656 L2.9375 -1.1719 Q2.9375 -0.6094 2.9844 -0.4766 Q3.0312 -0.3438 3.1797 -0.2656 Q3.3281 -0.1875 3.7812 -0.1875 L3.7812 0 L1.2969 0 L1.2969 -0.1875 Q1.7656 -0.1875 1.8984 -0.2578 Q2.0312 -0.3281 2.0859 -0.4531 Q2.1406 -0.5781 2.1406 -1.1719 L2.1406 -4.7344 Q2.1406 -5.4688 2.0938 -5.6719 Q2.0625 -5.8281 1.9688 -5.8984 Q1.875 -5.9688 1.75 -5.9688 Q1.5625 -5.9688 1.25 -5.8281 L1.1719 -5.9688 Z\"></path>\n    </g>\n   </g>\n  </svg> </span>正规化）可以在避免过拟合的训练中使用。<sup><a href=\"#quote_110\" class=\"kx_ref\">[110]</a></sup>另外，在训练过程中，dropout正则化会随机省略隐藏层中的单元。这有助于排除罕见的依赖性。<sup><a href=\"#quote_111\" class=\"kx_ref\">[111]</a></sup>最后，可以通过剪枝和旋转等方法来增加数据，从而可以增加较小的训练集，以减少过拟合的机会。<sup><a href=\"#quote_112\" class=\"kx_ref\">[112]</a></sup> </p>\n<p>DNN必须考虑许多训练参数，例如大小（层数和每层单元数）、学习速率和初始权重。由于时间和计算资源的成本，在参数空间中搜索最优参数可能是不可行的。有各种技巧如批处理（一次计算几个训练示例的梯度，而不是单个示例）<sup><a href=\"#quote_113\" class=\"kx_ref\">[113]</a></sup>加速计算。多核架构（如GPU或英特尔Xeon Phi）的强大处理能力大大加快了训练速度，因为这种处理架构适合矩阵和向量计算。<sup><a href=\"#quote_114\" class=\"kx_ref\">[114]</a></sup><sup><a href=\"#quote_115\" class=\"kx_ref\">[115]</a></sup> </p>\n<p>另外，工程师可以寻找其他具有更直接和收敛的训练算法的神经网络。CMAC（小脑神经网络）就是这样一种神经网络。CMAC不需要学习率或随机初始权重。可以保证训练过程与新的一批数据一步收敛，并且训练算法的计算复杂度与涉及的神经元数量成线性关系。<sup><a href=\"#quote_116\" class=\"kx_ref\">[116]</a></sup><sup><a href=\"#quote_117\" class=\"kx_ref\">[117]</a></sup> </p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995109514838288","title":"应用","versionId":"14995350385328397","lemmaId":10438,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233924,"comment":null,"dependVersionId":0,"contentType":1,"content":"<h3>自动语音识别</h3> \n<p>大规模自动语音识别是深度学习的第一个也是最有说服力的成功案例。LSTM神经网络可以学习“非常深入学习”任务<sup><a href=\"#quote_2\" class=\"kx_ref\">[2]</a></sup>，这涉及包含由数千个离散时间步长分隔的语音事件的多秒间隔，其中一个时间步长对应约10ms。具有遗忘门的LSTM<sup><a href=\"#quote_108\" class=\"kx_ref\">[108]</a></sup>在特定任务上可以与传统的语音识别器相媲美。<sup><a href=\"#quote_52\" class=\"kx_ref\">[52]</a></sup> </p>\n<p>语音识别的最初成功是基于TIMIT的小规模识别任务。该数据集包含来自美国英语八种主要方言的630名说话者，每个说话者读10个句子。<sup><a href=\"#quote_118\" class=\"kx_ref\">[118]</a></sup>它的小规模允许尝试许多配置。更重要的是，TIMIT任务涉及音素序列识别，这与单词序列识别不同，它允许弱音素二元语言模型。这使得语音识别的声学建模方面的强度更容易分析。以下列出的错误率，包括这些早期结果，以及以音素错误率百分比(PER)衡量的错误率，自1991年以来一直在汇总。 </p> \n<table class=\"wikitable\"> \n <tbody>\n  <tr> \n   <th>方法</th> \n   <th>声音误差率（PER，%) </th>\n  </tr> \n  <tr> \n   <td>随机初始化RNN<sup><a href=\"#quote_119\" class=\"kx_ref\">[119]</a></sup></td> \n   <td>26.1 </td>\n  </tr> \n  <tr> \n   <td>贝叶斯三音子GMM-HMM</td> \n   <td>25.6 </td>\n  </tr> \n  <tr> \n   <td>隐藏轨迹（生成）模型</td> \n   <td>24.8 </td>\n  </tr> \n  <tr> \n   <td>单音子重复初始化DNN</td> \n   <td>23.4 </td>\n  </tr> \n  <tr> \n   <td>单音子DBN-DNN</td> \n   <td>22.4 </td>\n  </tr> \n  <tr> \n   <td>带BMMI训练的三音子GMM-HMM</td> \n   <td>21.7 </td>\n  </tr> \n  <tr> \n   <td>共享池上的单音子DBN-DNN</td> \n   <td>20.7 </td>\n  </tr> \n  <tr> \n   <td>卷积DNN<sup><a href=\"#quote_120\" class=\"kx_ref\">[120]</a></sup></td> \n   <td>20.0 </td>\n  </tr> \n  <tr> \n   <td>卷积DNN w。异构池</td> \n   <td>18.7 </td>\n  </tr> \n  <tr> \n   <td>DNN / CNN / RNN合奏<sup><a href=\"#quote_121\" class=\"kx_ref\">[121]</a></sup></td> \n   <td>18.3 </td>\n  </tr> \n  <tr> \n   <td>双向LSTM</td> \n   <td>17.9 </td>\n  </tr> \n  <tr> \n   <td>分层卷积深度超出网络<sup><a href=\"#quote_122\" class=\"kx_ref\">[122]</a></sup></td> \n   <td>16.5 </td>\n  </tr>\n </tbody>\n</table> \n<p>20世纪90年代末首次出现用于说话人识别的深度神经网络，2009-2011年前后首次出现用于语音识别的深度神经网络，2003-2007年前后首次出现用于LSTM的深度神经网络，加速了八个主要领域的进展:<sup><a href=\"#quote_10\" class=\"kx_ref\">[10]</a></sup><sup><a href=\"#quote_75\" class=\"kx_ref\">[75]</a></sup><sup><a href=\"#quote_73\" class=\"kx_ref\">[73]</a></sup> </p> \n<ul>\n <li>放大/缩小和加速DNN训练和解码</li> \n <li>序列辨别训练</li> \n <li>通过对潜在机制有深刻理解的深层模型进行特征处理</li> \n <li>DNN和相关深度模型的适应</li> \n <li>基于DnS和相关深层模型的多任务迁移学习</li> \n <li>卷积神经网络以及如何设计它们来最好地利用语音领域知识</li> \n <li>RNN及其丰富的LSTM变体</li> \n <li>其他类型的深层模型包括基于张量的模型和集成的深层生成/判别模型。</li>\n</ul> \n<p>所有主要的商业语音识别系统（如微软小娜、Xbox、Skype翻译器、亚马逊Alexa、Google Now、苹果Siri、百度和iFlyTek语音搜索，以及一系列Nuance语音产品等）都建立在深度学习的基础上。<sup><a href=\"#quote_10\" class=\"kx_ref\">[10]</a></sup><sup><a href=\"#quote_123\" class=\"kx_ref\">[123]</a></sup><sup><a href=\"#quote_124\" class=\"kx_ref\">[124]</a></sup><sup><a href=\"#quote_125\" class=\"kx_ref\">[125]</a></sup> </p> \n<h3>图像识别</h3> \n<p>图像分类的常用评估集是MNIST数据库数据集。MNIST由手写数字组成，包括60000个训练示例和10000个测试示例。和TIMIT一样，它的小尺寸让用户可以测试多种配置。这个集合的完整结果列表是可获得的。<sup><a href=\"#quote_126\" class=\"kx_ref\">[126]</a></sup> </p>\n<p>基于深度学习的图像识别已经成为“超人”，可以获得比人类参赛者更准确的结果。这首次出现在2011年。<sup><a href=\"#quote_127\" class=\"kx_ref\">[127]</a></sup> </p>\n<p>经过深度学习训练的车辆现在可以理解360度摄像头的视角。<sup><a href=\"#quote_128\" class=\"kx_ref\">[128]</a></sup>另一个例子是面部畸形分析（FDNA），用于分析与一个大型遗传综合征数据库相关的人类畸形病例。 </p> \n<h3>视觉艺术处理</h3> \n<p>与图像识别取得的进展密切相关的是深度学习技术在各种视觉艺术任务中的日益应用。DNN的强大能力已经得到证明，例如，a）识别给定绘画的风格周期，b）神经风格迁移-捕捉给定艺术品的风格，并以愉悦视觉方式将其应用于任意照片或视频，以及c）基于随机视觉输入字段生成醒目的图像。<sup><a href=\"#quote_129\" class=\"kx_ref\">[129]</a></sup><sup><a href=\"#quote_130\" class=\"kx_ref\">[130]</a></sup> </p> \n<h3>自然语言处理</h3> \n<p>自21世纪初以来，神经网络就被用于实现语言模型。<sup><a href=\"#quote_103\" class=\"kx_ref\">[103]</a></sup><sup><a href=\"#quote_131\" class=\"kx_ref\">[131]</a></sup>LSTM帮助改进了机器翻译和语言建模。<sup><a href=\"#quote_104\" class=\"kx_ref\">[104]</a></sup><sup><a href=\"#quote_105\" class=\"kx_ref\">[105]</a></sup><sup><a href=\"#quote_106\" class=\"kx_ref\">[106]</a></sup> </p>\n<p>该领域的其他关键技术是负采样<sup><a href=\"#quote_132\" class=\"kx_ref\">[132]</a></sup>和单词嵌入。词嵌入如<i>word2vec</i>，可以被认为是深度学习体系结构中的表示层，该体系结构将原子单词转换为该单词相对于数据集中其他单词的位置表示；该位置表示为向量空间中的一个点。使用单词嵌入作为RNN输入层允许网络使用有效的合成向量语法来解析句子和短语。成分向量语法可以被认为是由RNN实现的概率上下文无关文法（PCFG）。<sup><a href=\"#quote_133\" class=\"kx_ref\">[133]</a></sup>建立在单词嵌入之上的递归自动编码器可以评估句子相似性并检测语义。<sup><a href=\"#quote_133\" class=\"kx_ref\">[133]</a></sup>深层神经架构为选区分析，<sup><a href=\"#quote_134\" class=\"kx_ref\">[134]</a></sup>情绪分析，<sup><a href=\"#quote_135\" class=\"kx_ref\">[135]</a></sup>信息检索，<sup><a href=\"#quote_136\" class=\"kx_ref\">[136]</a></sup><sup><a href=\"#quote_137\" class=\"kx_ref\">[137]</a></sup>口语理解，<sup><a href=\"#quote_138\" class=\"kx_ref\">[138]</a></sup>机器翻译，<sup><a href=\"#quote_104\" class=\"kx_ref\">[104]</a></sup><sup><a href=\"#quote_139\" class=\"kx_ref\">[139]</a></sup>上下文实体链接，<sup><a href=\"#quote_139\" class=\"kx_ref\">[139]</a></sup>写作风格识别，<sup><a href=\"#quote_140\" class=\"kx_ref\">[140]</a></sup>文本分类等<sup><a href=\"#quote_141\" class=\"kx_ref\">[141]</a></sup>提供了最佳结果。 </p>\n<p>最近的发展将单词嵌入推广到句子嵌入。 </p>\n<p>谷歌翻译使用大型端到端长短期记忆网络。<sup><a href=\"#quote_142\" class=\"kx_ref\">[142]</a></sup><sup><a href=\"#quote_143\" class=\"kx_ref\">[143]</a></sup><sup><a href=\"#quote_144\" class=\"kx_ref\">[144]</a></sup><sup><a href=\"#quote_145\" class=\"kx_ref\">[145]</a></sup><sup><a href=\"#quote_146\" class=\"kx_ref\">[146]</a></sup><sup><a href=\"#quote_147\" class=\"kx_ref\">[147]</a></sup>Google神经机器翻译系统（GNMT）使用基于实例的机器翻译方法，其中系统“从数百万个实例中学习”<sup><a href=\"#quote_143\" class=\"kx_ref\">[143]</a></sup>它一次翻译“整个句子，而非片段”。谷歌翻译支持一百多种语言。<sup><a href=\"#quote_143\" class=\"kx_ref\">[143]</a></sup>网络对“句子的语义，而非简单地记忆短语的翻译”进行编码。<sup><a href=\"#quote_143\" class=\"kx_ref\">[143]</a></sup><sup><a href=\"#quote_148\" class=\"kx_ref\">[148]</a></sup>GT使用英语作为大多数语言对之间的中间语言。<sup><a href=\"#quote_148\" class=\"kx_ref\">[148]</a></sup> </p> \n<h3>药物发现和毒理学</h3> \n<p>很大一部分候选药物未能获得监管部门的批准。这些失败是由功效不足（靶点效应）、意料之外的相互作用（脱靶效应）或意外的毒性效应引起的。<sup><a href=\"#quote_149\" class=\"kx_ref\">[149]</a></sup><sup><a href=\"#quote_150\" class=\"kx_ref\">[150]</a></sup>研究已经探索了使用深度学习来预测生物分子目标，<sup><a href=\"#quote_86\" class=\"kx_ref\">[86]</a></sup><sup><a href=\"#quote_87\" class=\"kx_ref\">[87]</a></sup>营养物、家用产品和药物中环境化学物质的脱靶和毒性影响。<sup><a href=\"#quote_88\" class=\"kx_ref\">[88]</a></sup><sup><a href=\"#quote_89\" class=\"kx_ref\">[89]</a></sup><sup><a href=\"#quote_90\" class=\"kx_ref\">[90]</a></sup> </p>\n<p>AtomNet是一个基于结构的合理药物设计的深度学习系统。<sup><a href=\"#quote_151\" class=\"kx_ref\">[151]</a></sup>AtomNet用于预测埃博拉病毒等疾病靶标的新候选生物分子<sup><a href=\"#quote_152\" class=\"kx_ref\">[152]</a></sup>和多发性硬化症。<sup><a href=\"#quote_153\" class=\"kx_ref\">[153]</a></sup><sup><a href=\"#quote_154\" class=\"kx_ref\">[154]</a></sup> </p> \n<h3>客户关系管理</h3> \n<p>深度强化学习已被用于估算可能的直销活动的价值，这是根据RFM变量定义的。估计价值函数显示为客户终身价值的自然解释。<sup><a href=\"#quote_155\" class=\"kx_ref\">[155]</a></sup> </p> \n<h3>推荐系统</h3> \n<p>推荐系统已经使用深度学习为基于内容的音乐推荐提取潜在因素模型的有意义的特征。<sup><a href=\"#quote_156\" class=\"kx_ref\">[156]</a></sup>多视角深度学习已经应用于从多个领域学习用户偏好。<sup><a href=\"#quote_157\" class=\"kx_ref\">[157]</a></sup>该模型使用了一种基于内容和协作的混合方法，并在多个任务中增强推荐。 </p> \n<h3>生物信息学</h3> \n<p>自动编码器人工神经网络用于生物信息学，预测基因本体注释和基因功能关系。<sup><a href=\"#quote_158\" class=\"kx_ref\">[158]</a></sup> </p>\n<p>在医学信息学中，深度学习被用来根据可穿戴设备的数据预测睡眠质量<sup><a href=\"#quote_159\" class=\"kx_ref\">[159]</a></sup>以及根据电子健康记录数据对健康并发症进行预测。<sup><a href=\"#quote_160\" class=\"kx_ref\">[160]</a></sup>深度学习也显示出医疗保健的功效。<sup><a href=\"#quote_161\" class=\"kx_ref\">[161]</a></sup> </p> \n<h3>医学图像分析</h3> \n<p>深度学习在医学应用例如癌细胞分类、病变检测、器官分割和图像增强<sup><a href=\"#quote_162\" class=\"kx_ref\">[162]</a></sup><sup><a href=\"#quote_163\" class=\"kx_ref\">[163]</a></sup>中产生的结果已经与其他方法相当。 </p> \n<h3>手机广告</h3> \n<p>为移动广告寻找合适的移动受众总是具有挑战性的，因为在任何广告服务器创建并在广告服务中使用目标片段之前，必须考虑和吸收许多数据点。<sup><a href=\"#quote_164\" class=\"kx_ref\">[164]</a></sup>深度学习已经被用于解释大的、多维的广告数据集。许多数据点是在请求/服务/点击互联网广告周期中收集的。这些信息可以形成机器学习的基础数据，以改进广告的选择。 </p> \n<h3>图像恢复</h3> \n<p>深度学习已成功应用于反问题，如去噪、超分辨率、修复和胶片着色。这些应用包括学习方法如在图像数据集上进行训练的“有效图像恢复的收缩字段”<sup><a href=\"#quote_165\" class=\"kx_ref\">[165]</a></sup>方法和训练需要恢复的图像的深度图像先验方法。 </p> \n<h3>金融欺诈检测</h3> \n<p>深度学习正成功应用于金融欺诈检测和反洗钱。“深度反洗钱检测系统可以发现和识别数据之间的关系和相似性，并在未来学习检测异常或分类和预测特定事件”。该解决方案利用监督学习（如可疑交易的分类）和非监督学习（如异常检测）技术。<sup><a href=\"#quote_166\" class=\"kx_ref\">[166]</a></sup> </p> \n<h3>军队</h3> \n<p>美国国防部通过观察应用深度学习来训练机器人完成新任务。<sup><a href=\"#quote_167\" class=\"kx_ref\">[167]</a></sup> </p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995109531615498","title":"与人类认知和大脑发育的关系","versionId":"14995350385328398","lemmaId":10438,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233924,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>深度学习与认知神经科学家在20世纪90年代早期提出的一类大脑发育理论（特别是新皮质发育）密切相关。<sup><a href=\"#quote_168\" class=\"kx_ref\">[168]</a></sup><sup><a href=\"#quote_169\" class=\"kx_ref\">[169]</a></sup><sup><a href=\"#quote_170\" class=\"kx_ref\">[170]</a></sup><sup><a href=\"#quote_171\" class=\"kx_ref\">[171]</a></sup>这些发展理论在计算模型中被实例化，使它们成为深度学习系统的前身。这些发展模型的共同特点是，大脑中各种提议的学习动力学（例如，神经生长因子波）支持自组织，这在某种程度上类似于深度学习模型中使用的神经网络。与新皮质一样，神经网络采用分层过滤器的层次结构，其中每一层考虑来自前一层（或操作环境）的信息，然后将其输出（可能还含有原始输入）传递给其他层。这一过程产生了一个自组织的传感器堆栈，可以很好地适应它们的工作环境。一份1995年的描述指出，“...婴儿的大脑似乎在所谓营养因子波的影响下自我组织...大脑的不同区域依次相连，一层组织先于另一层成熟，依此类推，直到整个大脑成熟。”<sup><a href=\"#quote_172\" class=\"kx_ref\">[172]</a></sup> </p>\n<p>从神经生物学的角度研究深度学习模型的合理性已经使用了各种各样的方法。一方面，为了提高反向传播算法的处理真实感提出了几种反向传播算法的变体。<sup><a href=\"#quote_173\" class=\"kx_ref\">[173]</a></sup><sup><a href=\"#quote_174\" class=\"kx_ref\">[174]</a></sup>其他研究人员认为，无监督形式的深度学习，例如基于层次生成模型和深度信念网络的学习，可能更接近生物现实。<sup><a href=\"#quote_175\" class=\"kx_ref\">[175]</a></sup><sup><a href=\"#quote_176\" class=\"kx_ref\">[176]</a></sup>在这方面，生成性神经网络模型已经与大脑皮层中基于样本的处理的神经生物学证据相关联。<sup><a href=\"#quote_177\" class=\"kx_ref\">[177]</a></sup> </p>\n<p>虽然人类大脑组织和深度网络中神经元编码之间的系统比较尚未建立，但报告中已有几个类比。例如，深度学习单元执行的计算可能类似于实际神经元的计算<sup><a href=\"#quote_178\" class=\"kx_ref\">[178]</a></sup><sup><a href=\"#quote_179\" class=\"kx_ref\">[179]</a></sup>和神经群。<sup><a href=\"#quote_180\" class=\"kx_ref\">[180]</a></sup>类似地，由深度学习模型开发的表示类似于灵长类视觉系统<sup><a href=\"#quote_181\" class=\"kx_ref\">[181]</a></sup>在单一单元<sup><a href=\"#quote_182\" class=\"kx_ref\">[182]</a></sup>和在种群<sup><a href=\"#quote_183\" class=\"kx_ref\">[183]</a></sup>等级上测量的表示。 </p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995109548392712","title":"商业活动","versionId":"14995350385328399","lemmaId":10438,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233924,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>许多组织对特定的应用采用深度学习。脸书的人工智能实验室进行了一些任务如自动给上传的图片贴上标签，上面有人物的名字。<sup><a href=\"#quote_184\" class=\"kx_ref\">[184]</a></sup> </p>\n<p>谷歌的DeepMind科技公司开发了一个系统，它能够学习如何只用像素作为数据输入来玩雅达利电子游戏。2015年，他们展示了他们的AlphaGo系统，该系统下围棋的能力足以击败职业围棋选手。<sup><a href=\"#quote_185\" class=\"kx_ref\">[185]</a></sup><sup><a href=\"#quote_186\" class=\"kx_ref\">[186]</a></sup><sup><a href=\"#quote_187\" class=\"kx_ref\">[187]</a></sup>谷歌翻译使用LSTM翻译100多种语言。 </p>\n<p>2015年，Blippar展示了一个移动增强现实应用，它使用深度学习实时识别物体。<sup><a href=\"#quote_188\" class=\"kx_ref\">[188]</a></sup> </p>\n<p>截至2008年，<sup><a href=\"#quote_189\" class=\"kx_ref\">[189]</a></sup>德克萨斯大学奥斯汀分校（UT）的研究人员开发了一个名为“通过评估强化手动训练代理”的机器学习框架，该框架为机器人或计算机程序提供了通过与人类教师交互来学习如何执行任务的新方法。<sup><a href=\"#quote_167\" class=\"kx_ref\">[167]</a></sup> </p>\n<p>最初作为TAMER开发、后来在2018年美国陆军研究实验室（ARL）和UT研究人员的合作中引入了一种称为Deep TAMER的新算法。Deep TAMER使用深度学习为机器人提供通过观察学习新任务的能力。<sup><a href=\"#quote_167\" class=\"kx_ref\">[167]</a></sup> </p>\n<p>使用Deep TAMER，机器人与人类教练一起学习任务，观看视频流或观察人类亲自执行任务。机器人后来在教练的指导下练习了这项任务，教练在这个过程中提供了“做得好”和“做得不好”等反馈<sup><a href=\"#quote_190\" class=\"kx_ref\">[190]</a></sup>。 </p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995109565169923","title":"批判和议论","versionId":"14995350385328400","lemmaId":10438,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233924,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>深度学习吸引了批判和评论，在某些情况下来自计算机科学领域之外。 </p> \n<h3>理论</h3> \n<p>一个主要的批评是缺乏围绕某些方法的理论。<sup><a href=\"#quote_191\" class=\"kx_ref\">[191]</a></sup>在最常见的深层架构中的学习是使用众所周知的梯度下降来实现的。然而，围绕其他算法的理论，如对比散度算法，则不太清楚。（例如，它会收敛吗？如果是，有多快？它近似于何值？)深度学习方法通常被视为一个黑盒，大多数证实是凭经验进行的，而不是理论上的。<sup><a href=\"#quote_192\" class=\"kx_ref\">[192]</a></sup> </p>\n<p> 其他人指出，深度学习应该被视为实现强人工智能的一个步骤，而不是一个包罗万象的解决方案。尽管有深度学习方法的力量，但它们仍然缺乏完全实现这一目标所需的许多功能。研究心理学家加里·马库斯指出:</p>\n<p>“事实上，深度学习只是构建智能机的更大挑战的一部分。这些技术缺乏表述因果关系的方式（……）没有显式的方法进行逻辑推理，而且它们距整合抽象知识还有很长的路要走，例如关于什么是对象、它们的用途和它们通常如何使用。最强大的人工智能系统如Watson（……）将深度学习等技术作为相当复杂的技术集合中的一个元素，涉及从贝叶斯推理的统计技术到演绎推理。”<sup><a href=\"#quote_193\" class=\"kx_ref\">[193]</a></sup></p>\n<p>作为对深度学习极限的重点的可选项，一位作者推测，训练机器视觉堆栈来执行区分“老主人”和业余人物的绘图的复杂任务是可能的，并且假设这样的灵敏度可能代表了不平凡的机器共感的雏形。<sup><a href=\"#quote_194\" class=\"kx_ref\">[194]</a></sup>这位作者提出，这与人类学是一致的，人类学将美学视为行为现代性的一个关键要素。<sup><a href=\"#quote_195\" class=\"kx_ref\">[195]</a></sup> </p>\n<p>在进一步提到艺术敏感性可能存在于相对较低的认知层次的观点时，一系列已发表的深层（20-30层）神经网络内部状态图表示试图在本质上是随机的数据中辨别它们所训练的图像<sup><a href=\"#quote_196\" class=\"kx_ref\">[196]</a></sup>中展现出了视觉吸引力：最初的研究通知收到了超过1000条评论，并且是<i>《卫报》</i><sup><a href=\"#quote_197\" class=\"kx_ref\">[197]</a></sup>网站上一段时间内最常被访问的文章主题。 </p> \n<h3>错误</h3> \n<p>一些深度学习架构显现出了有问题的行为，<sup><a href=\"#quote_198\" class=\"kx_ref\">[198]</a></sup>例如自信地将不可识别的图像分类为属于熟悉的普通图像类别<sup><a href=\"#quote_199\" class=\"kx_ref\">[199]</a></sup>以及对正确分类图像的微小扰动进行错误分类。<sup><a href=\"#quote_200\" class=\"kx_ref\">[200]</a></sup>戈泽尔假设，这些行为是由于其内部表现的限制，这些限制将抑制集成到异构多组件通用人工智能（AGI）架构。<sup><a href=\"#quote_198\" class=\"kx_ref\">[198]</a></sup>这些问题可以通过深度学习架构来解决，这种架构内部形成与观察到的实体和事件的图像-语法分解同源的状态<sup><a href=\"#quote_201\" class=\"kx_ref\">[201]</a></sup>。<sup><a href=\"#quote_198\" class=\"kx_ref\">[198]</a></sup>从训练数据中学习语法（视觉或语言的）相当于将系统限制在常识推理上，常识推理根据语法产生规则对概念进行操作，并且是人类语言习得和人工智能的基本目标<sup><a href=\"#quote_202\" class=\"kx_ref\">[202]</a></sup>。<sup><a href=\"#quote_203\" class=\"kx_ref\">[203]</a></sup> </p> \n<h3>网络威胁</h3> \n<p>随着深度学习从实验室走向世界，研究和经验表明，人工神经网络容易被黑客攻击和欺骗。通过识别这些系统运行的模式，攻击者可以修改人工神经网络的输入，使得人工神经网络找到人类观察者无法识别的匹配对象。例如，攻击者可以对图像进行细微的更改，使得人工神经网络能够找到匹配的图像，即使该图像在人类看来与搜索目标完全不同。这种操纵被称为“对抗性攻击”。2016年，研究人员使用一个人工神经网络以反复试验的方式对图像进行修改，识别另一个人工神经网络的焦点，从而生成欺骗它的图像。修改后的图像在人眼看来没有什么不同。另一组显示，打印出的篡改图像成功地欺骗了图像分类系统。<sup><a href=\"#quote_204\" class=\"kx_ref\">[204]</a></sup>一种防御方式是反向图像搜索，其中一个可能的假图像被提交到一个网站，如TinEye，然后可以找到它的其他实例。一种改进是只使用图像的一部分进行搜索，以识别可能拍摄到的图像。<sup><a href=\"#quote_205\" class=\"kx_ref\">[205]</a></sup> </p>\n<p>另一组研究表明，某些迷惑现象可以愚弄面部识别系统，使其认为普通人是名人，这可能会让一个人冒充另一个人。2017年，研究人员在停车标志上添加了标签，导致人工神经网络对它们进行了错误分类。<sup><a href=\"#quote_204\" class=\"kx_ref\">[204]</a></sup> </p>\n<p>然而，人工神经网络可以被进一步训练以检测欺骗意图，潜在地导致攻击者和防御者进入类似于一个已经定义恶意软件防御行业的军备竞赛。人工神经网络已经被训练来击败基于人工神经网络的反恶意软件，通过反复攻击反恶意软件的防御，该网络被遗传算法不断地改变，直到它成功欺骗了反恶意软件，同时保持其破坏目标的能力。<sup><a href=\"#quote_204\" class=\"kx_ref\">[204]</a></sup> </p>\n<p>另一个小组证明了某些声音可以让Google即时语音指挥系统打开一个特定的网址来下载恶意软件。<sup><a href=\"#quote_204\" class=\"kx_ref\">[204]</a></sup> </p>\n<p>在“数据中毒”中，错误数据不断地被偷放入机器学习系统的训练集中，以防止它掌握这个模型。<sup><a href=\"#quote_204\" class=\"kx_ref\">[204]</a></sup> </p>","pics":null,"card":null,"references":[],"versionCount":0}],"references":[{"id":1,"type":"book","title":"Bengio, Y.; Courville, A.; Vincent, P. (2013). \"Representation Learning: A Review and New Perspectives\". IEEE Transactions on Pattern Analysis and Machine Intelligence. 35 (8): 1798–1828. arXiv:1206.5538. doi:10.1109/tpami.2013.50. PMID 23787338.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":2,"type":"book","title":"Schmidhuber, J. (2015). \"Deep Learning in Neural Networks: An Overview\". Neural Networks. 61: 85–117. arXiv:1404.7828. doi:10.1016/j.neunet.2014.09.003. PMID 25462637.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":3,"type":"book","title":"Bengio, Yoshua; LeCun, Yann; Hinton, Geoffrey (2015). \"Deep Learning\". Nature. 521 (7553): 436–444. Bibcode:2015Natur.521..436L. doi:10.1038/nature14539. PMID 26017442.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":4,"type":"book","title":"Ciresan, Dan; Meier, U.; Schmidhuber, J. (June 2012). \"Multi-column deep neural networks for image classification\". 2012 IEEE Conference on Computer Vision and Pattern Recognition: 3642–3649. arXiv:1202.2745. doi:10.1109/cvpr.2012.6248110. ISBN 978-1-4673-1228-8.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":5,"type":"book","title":"Krizhevsky, Alex; Sutskever, Ilya; Hinton, Geoffry (2012). \"ImageNet Classification with Deep Convolutional Neural Networks\" (PDF). NIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":6,"type":"book","title":"\"Google's AlphaGo AI wins three-match series against the world's best Go player\". TechCrunch. 25 May 2017.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":7,"type":"book","title":"Marblestone, Adam H.; Wayne, Greg; Kording, Konrad P. (2016). \"Toward an Integration of Deep Learning and Neuroscience\". Frontiers in Computational Neuroscience. 10: 94. doi:10.3389/fncom.2016.00094. PMC 5021692. PMID 27683554.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":8,"type":"book","title":"Olshausen, B. A. (1996). \"Emergence of simple-cell receptive field properties by learning a sparse code for natural images\". Nature. 381 (6583): 607–609. Bibcode:1996Natur.381..607O. doi:10.1038/381607a0. PMID 8637596.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":9,"type":"book","title":"Bengio, Yoshua; Lee, Dong-Hyun; Bornschein, Jorg; Mesnard, Thomas; Lin, Zhouhan (2015-02-13). \"Towards Biologically Plausible Deep Learning\". arXiv:1502.04156 [cs.LG].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":10,"type":"book","title":"Deng, L.; Yu, D. (2014). \"Deep Learning: Methods and Applications\" (PDF). Foundations and Trends in Signal Processing. 7 (3–4): 1–199. doi:10.1561/2000000039.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":11,"type":"book","title":"Bengio, Yoshua (2009). \"Learning Deep Architectures for AI\" (PDF). Foundations and Trends in Machine Learning. 2 (1): 1–127. CiteSeerX 10.1.1.701.9550. doi:10.1561/2200000006.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":12,"type":"book","title":"LeCun, Yann; Bengio, Yoshua; Hinton, Geoffrey (28 May 2015). \"Deep learning\". Nature. 521 (7553): 436–444. Bibcode:2015Natur.521..436L. doi:10.1038/nature14539. PMID 26017442.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":13,"type":"book","title":"Jürgen Schmidhuber (2015). Deep Learning. Scholarpedia, 10(11):32832. Online","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":14,"type":"book","title":"Hinton, G.E. (2009). \"Deep belief networks\". Scholarpedia. 4 (5): 5947. Bibcode:2009SchpJ...4.5947H. doi:10.4249/scholarpedia.5947.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":15,"type":"book","title":"Murphy, Kevin P. (24 August 2012). Machine Learning: A Probabilistic Perspective. MIT Press. ISBN 978-0-262-01802-9.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":16,"type":"book","title":"Patel, Ankit; Nguyen, Tan; Baraniuk, Richard (2016). \"A Probabilistic Framework for Deep Learning\" (PDF). Advances in Neural Information Processing Systems.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":17,"type":"book","title":"Balázs Csanád Csáji (2001). Approximation with Artificial Neural Networks; Faculty of Sciences; Eötvös Loránd University, Hungary","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":18,"type":"book","title":"Cybenko (1989). \"Approximations by superpositions of sigmoidal functions\" (PDF). Mathematics of Control, Signals, and Systems. 2 (4): 303–314. doi:10.1007/bf02551274. Archived from the original (PDF) on 2015-10-10.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":19,"type":"book","title":"Hornik, Kurt (1991). \"Approximation Capabilities of Multilayer Feedforward Networks\". Neural Networks. 4 (2): 251–257. doi:10.1016/0893-6080(91)90009-t.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":20,"type":"book","title":"Haykin, Simon S. (1999). Neural Networks: A Comprehensive Foundation. Prentice Hall. ISBN 978-0-13-273350-2.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":21,"type":"book","title":"Hassoun, Mohamad H. (1995). Fundamentals of Artificial Neural Networks. MIT Press. p. 48. ISBN 978-0-262-08239-6.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":22,"type":"book","title":"Lu, Z., Pu, H., Wang, F., Hu, Z., & Wang, L. (2017). The Expressive Power of Neural Networks: A View from the Width. Neural Information Processing Systems, 6231-6239.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":23,"type":"book","title":"Hinton, G. E.; Srivastava, N.; Krizhevsky, A.; Sutskever, I.; Salakhutdinov, R.R. (2012). \"Improving neural networks by preventing co-adaptation of feature detectors\". arXiv:1207.0580 [math.LG].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":24,"type":"book","title":"Bishop, Christopher M. (2006). Pattern Recognition and Machine Learning (PDF). Springer. ISBN 978-0-387-31073-2.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":25,"type":"book","title":"Rina Dechter (1986). Learning while searching in constraint-satisfaction problems. University of California, Computer Science Department, Cognitive Systems Laboratory.Online","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":26,"type":"book","title":"Igor Aizenberg, Naum N. Aizenberg, Joos P.L. Vandewalle (2000). Multi-Valued and Universal Binary Neurons: Theory, Learning and Applications. Springer Science & Business Media.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":27,"type":"book","title":"Co-evolving recurrent neurons learn deep memory POMDPs. Proc. GECCO, Washington, D. C., pp. 1795-1802, ACM Press, New York, NY, USA, 2005.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":28,"type":"book","title":"Ivakhnenko, A. G. (1973). Cybernetic Predicting Devices. CCM Information Corporation.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":29,"type":"book","title":"Ivakhnenko, Alexey (1971). \"Polynomial theory of complex systems\". IEEE Transactions on Systems, Man and Cybernetics. 1 (4): 364–378. doi:10.1109/TSMC.1971.4308320.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":30,"type":"book","title":"Fukushima, K. (1980). \"Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position\". Biol. Cybern. 36 (4): 193–202. doi:10.1007/bf00344251. PMID 7370364.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":31,"type":"book","title":"Seppo Linnainmaa (1970). The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors. Master's Thesis (in Finnish), Univ. Helsinki, 6-7.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":32,"type":"book","title":"Griewank, Andreas (2012). \"Who Invented the Reverse Mode of Differentiation?\" (PDF). Documenta Matematica (Extra Volume ISMP): 389–400.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":33,"type":"book","title":"Werbos, P. (1974). \"Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences\". Harvard University. Retrieved 12 June 2017.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":34,"type":"book","title":"Werbos, Paul (1982). \"Applications of advances in nonlinear sensitivity analysis\" (PDF). System modeling and optimization. Springer. pp. 762–770.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":35,"type":"book","title":"LeCun et al., \"Backpropagation Applied to Handwritten Zip Code Recognition,\" Neural Computation, 1, pp. 541–551, 1989.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":36,"type":"book","title":"J. Weng, N. Ahuja and T. S. Huang, \"Cresceptron: a self-organizing neural network which grows adaptively,\" Proc. International Joint Conference on Neural Networks, Baltimore, Maryland, vol I, pp. 576-581, June, 1992.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":37,"type":"book","title":"J. Weng, N. Ahuja and T. S. Huang, \"Learning recognition and segmentation of 3-D objects from 2-D images,\" Proc. 4th International Conf. Computer Vision, Berlin, Germany, pp. 121-128, May, 1993.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":38,"type":"book","title":"J. Weng, N. Ahuja and T. S. Huang, \"Learning recognition and segmentation using the Cresceptron,\" International Journal of Computer Vision, vol. 25, no. 2, pp. 105-139, Nov. 1997.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":39,"type":"book","title":"de Carvalho, Andre C. L. F.; Fairhurst, Mike C.; Bisset, David (1994-08-08). \"An integrated Boolean neural network for pattern classification\". Pattern Recognition Letters. 15 (8): 807–813. doi:10.1016/0167-8655(94)90009-4.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":40,"type":"book","title":"Hinton, Geoffrey E.; Dayan, Peter; Frey, Brendan J.; Neal, Radford (1995-05-26). \"The wake-sleep algorithm for unsupervised neural networks\". Science. 268 (5214): 1158–1161. Bibcode:1995Sci...268.1158H. doi:10.1126/science.7761831.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":41,"type":"book","title":"S. Hochreiter., \"Untersuchungen zu dynamischen neuronalen Netzen,\" Diploma thesis. Institut f. Informatik, Technische Univ. Munich. Advisor: J. Schmidhuber, 1991.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":42,"type":"book","title":"Hochreiter, S.; et al. (15 January 2001). \"Gradient flow in recurrent nets: the difficulty of learning long-term dependencies\". In Kolen, John F.; Kremer, Stefan C. A Field Guide to Dynamical Recurrent Networks. John Wiley & Sons. ISBN 978-0-7803-5369-5.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":43,"type":"book","title":"Morgan, Nelson; Bourlard, Hervé; Renals, Steve; Cohen, Michael; Franco, Horacio (1993-08-01). \"Hybrid neural network/hidden markov model systems for continuous speech recognition\". International Journal of Pattern Recognition and Artificial Intelligence. 07 (4): 899–916. doi:10.1142/s0218001493000455. ISSN 0218-0014.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":44,"type":"book","title":"Robinson, T. (1992). \"A real-time recurrent error propagation network word recognition system\". ICASSP: 617–620.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":45,"type":"book","title":"Waibel, A.; Hanazawa, T.; Hinton, G.; Shikano, K.; Lang, K. J. (March 1989). \"Phoneme recognition using time-delay neural networks\". IEEE Transactions on Acoustics, Speech, and Signal Processing. 37 (3): 328–339. doi:10.1109/29.21701. ISSN 0096-3518.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":46,"type":"book","title":"Baker, J.; Deng, Li; Glass, Jim; Khudanpur, S.; Lee, C.-H.; Morgan, N.; O'Shaughnessy, D. (2009). \"Research Developments and Directions in Speech Recognition and Understanding, Part 1\". IEEE Signal Processing Magazine. 26 (3): 75–80. Bibcode:2009ISPM...26...75B. doi:10.1109/msp.2009.932166.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":47,"type":"book","title":"Bengio, Y. (1991). \"Artificial Neural Networks and their Application to Speech/Sequence Recognition\". McGill University Ph.D. thesis.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":48,"type":"book","title":"Deng, L.; Hassanein, K.; Elmasry, M. (1994). \"Analysis of correlation structure for a neural predictive model with applications to speech recognition\". Neural Networks. 7 (2): 331–339. doi:10.1016/0893-6080(94)90027-2.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":49,"type":"book","title":"Heck, L.; Konig, Y.; Sonmez, M.; Weintraub, M. (2000). \"Robustness to Telephone Handset Distortion in Speaker Recognition by Discriminative Feature Design\". Speech Communication. 31 (2): 181–192. doi:10.1016/s0167-6393(99)00077-1.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":50,"type":"book","title":"\"Acoustic Modeling with Deep Neural Networks Using Raw Time Signal for LVCSR (PDF Download Available)\". ResearchGate. Retrieved 2017-06-14.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":51,"type":"book","title":"Hochreiter, Sepp; Schmidhuber, Jürgen (1997-11-01). \"Long Short-Term Memory\". Neural Computation. 9 (8): 1735–1780. doi:10.1162/neco.1997.9.8.1735. ISSN 0899-7667. PMID 9377276.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":52,"type":"book","title":"Graves, Alex; Eck, Douglas; Beringer, Nicole; Schmidhuber, Jürgen (2003). \"Biologically Plausible Speech Recognition with LSTM Neural Nets\" (PDF). 1st Intl. Workshop on Biologically Inspired Approaches to Advanced Information Technology, Bio-ADIT 2004, Lausanne, Switzerland. pp. 175–184.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":53,"type":"book","title":"Graves, Alex; Fernández, Santiago; Gomez, Faustino (2006). \"Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks\". Proceedings of the International Conference on Machine Learning, ICML 2006: 369–376. CiteSeerX 10.1.1.75.6306.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":54,"type":"book","title":"Santiago Fernandez, Alex Graves, and Jürgen Schmidhuber (2007). An application of recurrent neural networks to discriminative keyword spotting. Proceedings of ICANN (2), pp. 220–229.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":55,"type":"book","title":"Sak, Haşim; Senior, Andrew; Rao, Kanishka; Beaufays, Françoise; Schalkwyk, Johan (September 2015). \"Google voice search: faster and more accurate\".","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":56,"type":"book","title":"Hinton, Geoffrey E. (2007-10-01). \"Learning multiple layers of representation\". Trends in Cognitive Sciences. 11 (10): 428–434. doi:10.1016/j.tics.2007.09.004. ISSN 1364-6613. PMID 17921042.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":57,"type":"book","title":"Hinton, G. E.; Osindero, S.; Teh, Y. W. (2006). \"A Fast Learning Algorithm for Deep Belief Nets\" (PDF). Neural Computation. 18 (7): 1527–1554. doi:10.1162/neco.2006.18.7.1527. PMID 16764513.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":58,"type":"book","title":"Bengio, Yoshua (2012). \"Practical recommendations for gradient-based training of deep architectures\". arXiv:1206.5533 [cs.LG].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":59,"type":"book","title":"G. E. Hinton., \"Learning multiple layers of representation,\" Trends in Cognitive Sciences, 11, pp. 428–434, 2007.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":60,"type":"book","title":"Hinton, G.; Deng, L.; Yu, D.; Dahl, G.; Mohamed, A.; Jaitly, N.; Senior, A.; Vanhoucke, V.; Nguyen, P.; Sainath, T.; Kingsbury, B. (2012). \"Deep Neural Networks for Acoustic Modeling in Speech Recognition --- The shared views of four research groups\". IEEE Signal Processing Magazine. 29 (6): 82–97. doi:10.1109/msp.2012.2205597.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":61,"type":"book","title":"Deng, Li; Hinton, Geoffrey; Kingsbury, Brian (1 May 2013). \"New types of deep neural network learning for speech recognition and related applications: An overview\" – via research.microsoft.com.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":62,"type":"book","title":"Deng, L.; Li, J.; Huang, J. T.; Yao, K.; Yu, D.; Seide, F.; Seltzer, M.; Zweig, G.; He, X. (May 2013). \"Recent advances in deep learning for speech research at Microsoft\". 2013 IEEE International Conference on Acoustics, Speech and Signal Processing: 8604–8608. doi:10.1109/icassp.2013.6639345. ISBN 978-1-4799-0356-6.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":63,"type":"book","title":"Sak, Hasim; Senior, Andrew; Beaufays, Francoise (2014). \"Long Short-Term Memory recurrent neural network architectures for large scale acoustic modeling\" (PDF).","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":64,"type":"book","title":"Li, Xiangang; Wu, Xihong (2014). \"Constructing Long Short-Term Memory based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition\". arXiv:1410.4281 [cs.CL].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":65,"type":"book","title":"Zen, Heiga; Sak, Hasim (2015). \"Unidirectional Long Short-Term Memory Recurrent Neural Network with Recurrent Output Layer for Low-Latency Speech Synthesis\" (PDF). Google.com. ICASSP. pp. 4470–4474.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":66,"type":"book","title":"Deng, L.; Abdel-Hamid, O.; Yu, D. (2013). \"A deep convolutional neural network using heterogeneous pooling for trading acoustic invariance with phonetic confusion\" (PDF). Google.com. ICASSP.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":67,"type":"book","title":"Sainath, T. N.; Mohamed, A. r; Kingsbury, B.; Ramabhadran, B. (May 2013). \"Deep convolutional neural networks for LVCSR\". 2013 IEEE International Conference on Acoustics, Speech and Signal Processing: 8614–8618. doi:10.1109/icassp.2013.6639347. ISBN 978-1-4799-0356-6.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":68,"type":"book","title":"Yann LeCun (2016). Slides on Deep Learning Online","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":69,"type":"book","title":"NIPS Workshop: Deep Learning for Speech Recognition and Related Applications, Whistler, BC, Canada, Dec. 2009 (Organizers: Li Deng, Geoff Hinton, D. Yu).","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":70,"type":"book","title":"Keynote talk: Recent Developments in Deep Neural Networks. ICASSP, 2013 (by Geoff Hinton).","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":71,"type":"book","title":"D. Yu, L. Deng, G. Li, and F. Seide (2011). \"Discriminative pretraining of deep neural networks,\" U.S. Patent Filing.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":72,"type":"book","title":"Deng, L.; Hinton, G.; Kingsbury, B. (2013). \"New types of deep neural network learning for speech recognition and related applications: An overview (ICASSP)\" (PDF).","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":73,"type":"book","title":"Yu, D.; Deng, L. (2014). Automatic Speech Recognition: A Deep Learning Approach (Publisher: Springer). ISBN 978-1-4471-5779-3.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":74,"type":"book","title":"\"Deng receives prestigious IEEE Technical Achievement Award - Microsoft Research\". Microsoft Research. 3 December 2015.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":75,"type":"book","title":"Li, Deng (September 2014). \"Keynote talk: 'Achievements and Challenges of Deep Learning - From Speech Analysis and Recognition To Language and Multimodal Processing'\". Interspeech.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":76,"type":"book","title":"Yu, D.; Deng, L. (2010). \"Roles of Pre-Training and Fine-Tuning in Context-Dependent DBN-HMMs for Real-World Speech Recognition\". NIPS Workshop on Deep Learning and Unsupervised Feature Learning.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":77,"type":"book","title":"Seide, F.; Li, G.; Yu, D. (2011). \"Conversational speech transcription using context-dependent deep neural networks\". Interspeech.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":78,"type":"book","title":"Deng, Li; Li, Jinyu; Huang, Jui-Ting; Yao, Kaisheng; Yu, Dong; Seide, Frank; Seltzer, Mike; Zweig, Geoff; He, Xiaodong (2013-05-01). \"Recent Advances in Deep Learning for Speech Research at Microsoft\". Microsoft Research.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":79,"type":"book","title":"\"Nvidia CEO bets big on deep learning and VR\". Venture Beat. April 5, 2016.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":80,"type":"book","title":"\"From not working to neural networking\". The Economist.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":81,"type":"book","title":"Oh, K.-S.; Jung, K. (2004). \"GPU implementation of neural networks\". Pattern Recognition. 37 (6): 1311–1314. doi:10.1016/j.patcog.2004.01.013.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":82,"type":"book","title":"Chellapilla, K., Puri, S., and Simard, P. (2006). High performance convolutional neural networks for document processing. International Workshop on Frontiers in Handwriting Recognition.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":83,"type":"book","title":"Cireşan, Dan Claudiu; Meier, Ueli; Gambardella, Luca Maria; Schmidhuber, Jürgen (2010-09-21). \"Deep, Big, Simple Neural Nets for Handwritten Digit Recognition\". Neural Computation. 22 (12): 3207–3220. arXiv:1003.0358. doi:10.1162/neco_a_00052. ISSN 0899-7667. PMID 20858131.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":84,"type":"book","title":"Raina, Rajat; Madhavan, Anand; Ng, Andrew Y. (2009). \"Large-scale Deep Unsupervised Learning Using Graphics Processors\". Proceedings of the 26th Annual International Conference on Machine Learning. ICML '09. New York, NY, USA: ACM: 873–880. CiteSeerX 10.1.1.154.372. doi:10.1145/1553374.1553486. ISBN 9781605585161.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":85,"type":"book","title":"Sze, Vivienne; Chen, Yu-Hsin; Yang, Tien-Ju; Emer, Joel (2017). \"Efficient Processing of Deep Neural Networks: A Tutorial and Survey\". arXiv:1703.09039 [cs.CV].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":86,"type":"book","title":"\"Announcement of the winners of the Merck Molecular Activity Challenge\".","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":87,"type":"book","title":"\"Multi-task Neural Networks for QSAR Predictions | Data Science Association\". www.datascienceassn.org. Retrieved 2017-06-14.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":88,"type":"book","title":"\"Toxicology in the 21st century Data Challenge\"","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":89,"type":"book","title":"\"NCATS Announces Tox21 Data Challenge Winners\".","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":90,"type":"book","title":"\"Archived copy\". Archived from the original on 2015-02-28. Retrieved 2015-03-05.CS1 maint: Archived copy as title (link)","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":91,"type":"book","title":"Ciresan, D. C.; Meier, U.; Masci, J.; Gambardella, L. M.; Schmidhuber, J. (2011). \"Flexible, High Performance Convolutional Neural Networks for Image Classification\" (PDF). International Joint Conference on Artificial Intelligence. doi:10.5591/978-1-57735-516-8/ijcai11-210.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":92,"type":"book","title":"Ciresan, Dan; Giusti, Alessandro; Gambardella, Luca M.; Schmidhuber, Juergen (2012). Pereira, F.; Burges, C. J. C.; Bottou, L.; Weinberger, K. Q., eds. Advances in Neural Information Processing Systems 25 (PDF). Curran Associates, Inc. pp. 2843–2851.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":93,"type":"book","title":"Ciresan, D.; Giusti, A.; Gambardella, L.M.; Schmidhuber, J. (2013). \"Mitosis Detection in Breast Cancer Histology Images using Deep Neural Networks\". Proceedings MICCAI. Lecture Notes in Computer Science. 7908: 411–418. doi:10.1007/978-3-642-40763-5_51. ISBN 978-3-642-38708-1.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":94,"type":"book","title":"\"The Wolfram Language Image Identification Project\". www.imageidentify.com. Retrieved 2017-03-22.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":95,"type":"book","title":"Vinyals, Oriol; Toshev, Alexander; Bengio, Samy; Erhan, Dumitru (2014). \"Show and Tell: A Neural Image Caption Generator\". arXiv:1411.4555 [cs.CV]..","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":96,"type":"book","title":"Fang, Hao; Gupta, Saurabh; Iandola, Forrest; Srivastava, Rupesh; Deng, Li; Dollár, Piotr; Gao, Jianfeng; He, Xiaodong; Mitchell, Margaret; Platt, John C; Lawrence Zitnick, C; Zweig, Geoffrey (2014). \"From Captions to Visual Concepts and Back\". arXiv:1411.4952 [cs.CV]..","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":97,"type":"book","title":"Kiros, Ryan; Salakhutdinov, Ruslan; Zemel, Richard S (2014). \"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\". arXiv:1411.2539 [cs.LG]..","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":98,"type":"book","title":"Zhong, Sheng-hua; Liu, Yan; Liu, Yang (2011). \"Bilinear Deep Learning for Image Classification\". Proceedings of the 19th ACM International Conference on Multimedia. MM '11. New York, NY, USA: ACM: 343–352. doi:10.1145/2072298.2072344. ISBN 9781450306164.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":99,"type":"book","title":"\"Why Deep Learning Is Suddenly Changing Your Life\". Fortune. 2016. Retrieved 13 April 2018.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":100,"type":"book","title":"Silver, David; Huang, Aja; Maddison, Chris J.; Guez, Arthur; Sifre, Laurent; Driessche, George van den; Schrittwieser, Julian; Antonoglou, Ioannis; Panneershelvam, Veda (January 2016). \"Mastering the game of Go with deep neural networks and tree search\". Nature. 529 (7587): 484–489. Bibcode:2016Natur.529..484S. doi:10.1038/nature16961. ISSN 1476-4687. PMID 26819042.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":101,"type":"book","title":"Szegedy, Christian; Toshev, Alexander; Erhan, Dumitru (2013). \"Deep neural networks for object detection\". Advances in Neural Information Processing Systems.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":102,"type":"book","title":"Hof, Robert D. \"Is Artificial Intelligence Finally Coming into Its Own?\". MIT Technology Review. Retrieved 2018-07-10.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":103,"type":"book","title":"Gers, Felix A.; Schmidhuber, Jürgen (2001). \"LSTM Recurrent Networks Learn Simple Context Free and Context Sensitive Languages\". IEEE Trans. Neural Netw. 12 (6): 1333–1340. doi:10.1109/72.963769. PMID 18249962.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":104,"type":"book","title":"Sutskever, L.; Vinyals, O.; Le, Q. (2014). \"Sequence to Sequence Learning with Neural Networks\" (PDF). Proc. NIPS.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":105,"type":"book","title":"Jozefowicz, Rafal; Vinyals, Oriol; Schuster, Mike; Shazeer, Noam; Wu, Yonghui (2016). \"Exploring the Limits of Language Modeling\". arXiv:1602.02410 [cs.CL].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":106,"type":"book","title":"Gillick, Dan; Brunk, Cliff; Vinyals, Oriol; Subramanya, Amarnag (2015). \"Multilingual Language Processing from Bytes\". arXiv:1512.00103 [cs.CL].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":107,"type":"book","title":"Mikolov, T.; et al. (2010). \"Recurrent neural network based language model\" (PDF). Interspeech.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":108,"type":"book","title":"\"Learning Precise Timing with LSTM Recurrent Networks (PDF Download Available)\". ResearchGate. Retrieved 2017-06-13.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":109,"type":"book","title":"LeCun, Y.; et al. (1998). \"Gradient-based learning applied to document recognition\". Proceedings of the IEEE. 86 (11): 2278–2324. doi:10.1109/5.726791.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":110,"type":"book","title":"Bengio, Y.; Boulanger-Lewandowski, N.; Pascanu, R. (May 2013). \"Advances in optimizing recurrent networks\". 2013 IEEE International Conference on Acoustics, Speech and Signal Processing: 8624–8628. arXiv:1212.0901. CiteSeerX 10.1.1.752.9151. doi:10.1109/icassp.2013.6639349. ISBN 978-1-4799-0356-6.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":111,"type":"book","title":"Dahl, G.; et al. (2013). \"Improving DNNs for LVCSR using rectified linear units and dropout\" (PDF). ICASSP.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":112,"type":"book","title":"\"Data Augmentation - deeplearning.ai | Coursera\". Coursera. Retrieved 2017-11-30.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":113,"type":"book","title":"Hinton, G. E. (2010). \"A Practical Guide to Training Restricted Boltzmann Machines\". Tech. Rep. UTML TR 2010-003.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":114,"type":"book","title":"You, Yang; Buluç, Aydın; Demmel, James (November 2017). \"Scaling deep learning on GPU and knights landing clusters\". SC '17, ACM. Retrieved 5 March 2018.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":115,"type":"book","title":"Viebke, André; Memeti, Suejb; Pllana, Sabri; Abraham, Ajith (March 2017). \"CHAOS: a parallelization scheme for training convolutional neural networks on Intel Xeon Phi\". The Journal of Supercomputing. 75: 197–227. doi:10.1007/s11227-017-1994-x.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":116,"type":"book","title":"Ting Qin, et al. \"A learning algorithm of CMAC based on RLS.\" Neural Processing Letters 19.1 (2004): 49-61.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":117,"type":"book","title":"Ting Qin, et al. \"Continuous CMAC-QRLS and its systolic array.\" Neural Processing Letters 22.1 (2005): 1-16.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":118,"type":"book","title":"TIMIT Acoustic-Phonetic Continuous Speech Corpus Linguistic Data Consortium, Philadelphia.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":119,"type":"book","title":"Robinson, Tony (30 September 1991). \"Several Improvements to a Recurrent Error Propagation Network Phone Recognition System\". Cambridge University Engineering Department Technical Report. CUED/F-INFENG/TR82. doi:10.13140/RG.2.2.15418.90567.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":120,"type":"book","title":"Abdel-Hamid, O.; et al. (2014). \"Convolutional Neural Networks for Speech Recognition\". IEEE/ACM Transactions on Audio, Speech, and Language Processing. 22 (10): 1533–1545. doi:10.1109/taslp.2014.2339736.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":121,"type":"book","title":"Deng, L.; Platt, J. (2014). \"Ensemble Deep Learning for Speech Recognition\" (PDF). Proc. Interspeech.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":122,"type":"book","title":"Tóth, Laszló (2015). \"Phone Recognition with Hierarchical Convolutional Deep Maxout Networks\" (PDF). EURASIP Journal on Audio, Speech, and Music Processing. 2015. doi:10.1186/s13636-015-0068-3.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":123,"type":"book","title":"\"How Skype Used AI to Build Its Amazing New Language Translator | WIRED\". www.wired.com. Retrieved 2017-06-14.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":124,"type":"book","title":"Hannun, Awni; Case, Carl; Casper, Jared; Catanzaro, Bryan; Diamos, Greg; Elsen, Erich; Prenger, Ryan; Satheesh, Sanjeev; Sengupta, Shubho; Coates, Adam; Ng, Andrew Y (2014). \"Deep Speech: Scaling up end-to-end speech recognition\". arXiv:1412.5567 [cs.CL].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":125,"type":"book","title":"\"Plenary presentation at ICASSP-2016\" (PDF).","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":126,"type":"book","title":"\"MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges\". yann.lecun.com.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":127,"type":"book","title":"Cireşan, Dan; Meier, Ueli; Masci, Jonathan; Schmidhuber, Jürgen (August 2012). \"Multi-column deep neural network for traffic sign classification\". Neural Networks. Selected Papers from IJCNN 2011. 32: 333–338. CiteSeerX 10.1.1.226.8219. doi:10.1016/j.neunet.2012.02.023. PMID 22386783.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":128,"type":"book","title":"Nvidia Demos a Car Computer Trained with \"Deep Learning\" (2015-01-06), David Talbot, MIT Technology Review","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":129,"type":"book","title":"G. W. Smith; Frederic Fol Leymarie (10 April 2017). \"The Machine as Artist: An Introduction\". Arts. Retrieved 4 October 2017.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":130,"type":"book","title":"Blaise Agüera y Arcas (29 September 2017). \"Art in the Age of Machine Intelligence\". Arts. Retrieved 4 October 2017.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":131,"type":"book","title":"Bengio, Yoshua; Ducharme, Réjean; Vincent, Pascal; Janvin, Christian (March 2003). \"A Neural Probabilistic Language Model\". J. Mach. Learn. Res. 3: 1137–1155. ISSN 1532-4435.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":132,"type":"book","title":"Goldberg, Yoav; Levy, Omar (2014). \"word2vec Explained: Deriving Mikolov et al.'s Negative-Sampling Word-Embedding Method\". arXiv:1402.3722 [cs.CL].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":133,"type":"book","title":"Socher, Richard; Manning, Christopher. \"Deep Learning for NLP\" (PDF). Retrieved 26 October 2014.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":134,"type":"book","title":"Socher, Richard; Bauer, John; Manning, Christopher; Ng, Andrew (2013). \"Parsing With Compositional Vector Grammars\" (PDF). Proceedings of the ACL 2013 Conference.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":135,"type":"book","title":"Socher, Richard (2013). \"Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank\" (PDF).","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":136,"type":"book","title":"Shen, Yelong; He, Xiaodong; Gao, Jianfeng; Deng, Li; Mesnil, Gregoire (2014-11-01). \"A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval\". Microsoft Research.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":137,"type":"book","title":"Huang, Po-Sen; He, Xiaodong; Gao, Jianfeng; Deng, Li; Acero, Alex; Heck, Larry (2013-10-01). \"Learning Deep Structured Semantic Models for Web Search using Clickthrough Data\". Microsoft Research.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":138,"type":"book","title":"Mesnil, G.; Dauphin, Y.; Yao, K.; Bengio, Y.; Deng, L.; Hakkani-Tur, D.; He, X.; Heck, L.; Tur, G.; Yu, D.; Zweig, G. (2015). \"Using recurrent neural networks for slot filling in spoken language understanding\". IEEE Transactions on Audio, Speech, and Language Processing. 23 (3): 530–539. doi:10.1109/taslp.2014.2383614.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":139,"type":"book","title":"Gao, Jianfeng; He, Xiaodong; Yih, Scott Wen-tau; Deng, Li (2014-06-01). \"Learning Continuous Phrase Representations for Translation Modeling\". Microsoft Research.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":140,"type":"book","title":"Brocardo, Marcelo Luiz; Traore, Issa; Woungang, Isaac; Obaidat, Mohammad S. (2017). \"Authorship verification using deep belief network systems\". International Journal of Communication Systems. 30 (12): e3259. doi:10.1002/dac.3259.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":141,"type":"book","title":"\"Deep Learning for Natural Language Processing: Theory and Practice (CIKM2014 Tutorial) - Microsoft Research\". Microsoft Research. Retrieved 2017-06-14.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":142,"type":"book","title":"Turovsky, Barak (November 15, 2016). \"Found in translation: More accurate, fluent sentences in Google Translate\". The Keyword Google Blog. Retrieved March 23, 2017.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":143,"type":"book","title":"Schuster, Mike; Johnson, Melvin; Thorat, Nikhil (November 22, 2016). \"Zero-Shot Translation with Google's Multilingual Neural Machine Translation System\". Google Research Blog. Retrieved March 23, 2017.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":144,"type":"book","title":"Sepp Hochreiter; Jürgen Schmidhuber (1997). \"Long short-term memory\". Neural Computation. 9 (8): 1735–1780. doi:10.1162/neco.1997.9.8.1735. PMID 9377276.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":145,"type":"book","title":"Felix A. Gers; Jürgen Schmidhuber; Fred Cummins (2000). \"Learning to Forget: Continual Prediction with LSTM\". Neural Computation. 12 (10): 2451–2471. CiteSeerX 10.1.1.55.5709. doi:10.1162/089976600300015015.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":146,"type":"book","title":"Wu, Yonghui; Schuster, Mike; Chen, Zhifeng; Le, Quoc V; Norouzi, Mohammad; Macherey, Wolfgang; Krikun, Maxim; Cao, Yuan; Gao, Qin; Macherey, Klaus; Klingner, Jeff; Shah, Apurva; Johnson, Melvin; Liu, Xiaobing; Kaiser, Łukasz; Gouws, Stephan; Kato, Yoshikiyo; Kudo, Taku; Kazawa, Hideto; Stevens, Keith; Kurian, George; Patil, Nishant; Wang, Wei; Young, Cliff; Smith, Jason; Riesa, Jason; Rudnick, Alex; Vinyals, Oriol; Corrado, Greg; et al. (2016). \"Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\". arXiv:1609.08144 [cs.CL].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":147,"type":"book","title":"\"An Infusion of AI Makes Google Translate More Powerful Than Ever.\" Cade Metz, WIRED, Date of Publication: 09.27.16. https://www.wired.com/2016/09/google-claims-ai-breakthrough-machine-translation/","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":148,"type":"book","title":"Boitet, Christian; Blanchon, Hervé; Seligman, Mark; Bellynck, Valérie (2010). \"MT on and for the Web\" (PDF). Retrieved December 1, 2016.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":149,"type":"book","title":"Arrowsmith, J; Miller, P (2013). \"Trial watch: Phase II and phase III attrition rates 2011-2012\". Nature Reviews Drug Discovery. 12 (8): 569. doi:10.1038/nrd4090. PMID 23903212.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":150,"type":"book","title":"Verbist, B; Klambauer, G; Vervoort, L; Talloen, W; The Qstar, Consortium; Shkedy, Z; Thas, O; Bender, A; Göhlmann, H. W.; Hochreiter, S (2015). \"Using transcriptomics to guide lead optimization in drug discovery projects: Lessons learned from the QSTAR project\". Drug Discovery Today. 20 (5): 505–513. doi:10.1016/j.drudis.2014.12.014. PMID 25582842.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":151,"type":"book","title":"Wallach, Izhar; Dzamba, Michael; Heifets, Abraham (2015-10-09). \"AtomNet: A Deep Convolutional Neural Network for Bioactivity Prediction in Structure-based Drug Discovery\". arXiv:1510.02855 [cs.LG].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":152,"type":"book","title":"\"Toronto startup has a faster way to discover effective medicines\". The Globe and Mail. Retrieved 2015-11-09.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":153,"type":"book","title":"\"Startup Harnesses Supercomputers to Seek Cures\". KQED Future of You. Retrieved 2015-11-09.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":154,"type":"book","title":"\"Toronto startup has a faster way to discover effective medicines\".","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":155,"type":"book","title":"Tkachenko, Yegor (April 8, 2015). \"Autonomous CRM Control via CLV Approximation with Deep Reinforcement Learning in Discrete and Continuous Action Space\". arXiv:1504.01840 [cs.LG].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":156,"type":"book","title":"van den Oord, Aaron; Dieleman, Sander; Schrauwen, Benjamin (2013). Burges, C. J. C.; Bottou, L.; Welling, M.; Ghahramani, Z.; Weinberger, K. Q., eds. Advances in Neural Information Processing Systems 26 (PDF). Curran Associates, Inc. pp. 2643–2651.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":157,"type":"book","title":"Elkahky, Ali Mamdouh; Song, Yang; He, Xiaodong (2015-05-01). \"A Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Systems\". Microsoft Research.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":158,"type":"book","title":"Chicco, Davide; Sadowski, Peter; Baldi, Pierre (1 January 2014). Deep Autoencoder Neural Networks for Gene Ontology Annotation Predictions. Proceedings of the 5th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics - BCB '14. ACM. pp. 533–540. doi:10.1145/2649387.2649442. hdl:11311/964622. ISBN 9781450328944.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":159,"type":"book","title":"Sathyanarayana, Aarti (2016-01-01). \"Sleep Quality Prediction From Wearable Data Using Deep Learning\". JMIR mHealth and uHealth. 4 (4): e125. doi:10.2196/mhealth.6562. PMC 5116102. PMID 27815231.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":160,"type":"book","title":"Choi, Edward; Schuetz, Andy; Stewart, Walter F.; Sun, Jimeng (2016-08-13). \"Using recurrent neural network models for early detection of heart failure onset\". Journal of the American Medical Informatics Association. 24 (2): 361–370. doi:10.1093/jamia/ocw112. ISSN 1067-5027. PMC 5391725. PMID 27521897.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":161,"type":"book","title":"\"Deep Learning in Healthcare: Challenges and Opportunities\". Medium. 2016-08-12. Retrieved 2018-04-10.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":162,"type":"book","title":"Litjens, Geert; Kooi, Thijs; Bejnordi, Babak Ehteshami; Setio, Arnaud Arindra Adiyoso; Ciompi, Francesco; Ghafoorian, Mohsen; van der Laak, Jeroen A.W.M.; van Ginneken, Bram; Sánchez, Clara I. (December 2017). \"A survey on deep learning in medical image analysis\". Medical Image Analysis. 42: 60–88. doi:10.1016/j.media.2017.07.005.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":163,"type":"book","title":"Forslid, Gustav; Wieslander, Hakan; Bengtsson, Ewert; Wahlby, Carolina; Hirsch, Jan-Michael; Stark, Christina Runow; Sadanandan, Sajith Kecheril (October 2017). \"Deep Convolutional Neural Networks for Detecting Cellular Changes Due to Malignancy\". 2017 IEEE International Conference on Computer Vision Workshops (ICCVW). Venice: IEEE: 82–89. doi:10.1109/ICCVW.2017.18. ISBN 9781538610343.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":164,"type":"book","title":"De, Shaunak; Maity, Abhishek; Goel, Vritti; Shitole, Sanjay; Bhattacharya, Avik (2017). \"Predicting the popularity of instagram posts for a lifestyle magazine using deep learning\". 2nd IEEE Conference on Communication Systems, Computing and IT Applications: 174–177. doi:10.1109/CSCITA.2017.8066548. ISBN 978-1-5090-4381-1.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":165,"type":"book","title":"Schmidt, Uwe; Roth, Stefan. Shrinkage Fields for Effective Image Restoration (PDF). Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":166,"type":"book","title":"Czech, Tomasz. \"Deep learning: the next frontier for money laundering detection\". Global Banking and Finance Review.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":167,"type":"book","title":"\"Army researchers develop new algorithms to train robots\". EurekAlert!. Retrieved 2018-08-29.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":168,"type":"book","title":"Utgoff, P. E.; Stracuzzi, D. J. (2002). \"Many-layered learning\". Neural Computation. 14 (10): 2497–2529. doi:10.1162/08997660260293319. PMID 12396572.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":169,"type":"book","title":"Elman, Jeffrey L. (1998). Rethinking Innateness: A Connectionist Perspective on Development. MIT Press. ISBN 978-0-262-55030-7.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":170,"type":"book","title":"Shrager, J.; Johnson, MH (1996). \"Dynamic plasticity influences the emergence of function in a simple cortical array\". Neural Networks. 9 (7): 1119–1129. doi:10.1016/0893-6080(96)00033-0. PMID 12662587.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":171,"type":"book","title":"Quartz, SR; Sejnowski, TJ (1997). \"The neural basis of cognitive development: A constructivist manifesto\". Behavioral and Brain Sciences. 20 (4): 537–556. CiteSeerX 10.1.1.41.7854. doi:10.1017/s0140525x97001581.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":172,"type":"book","title":"S. Blakeslee., \"In brain's early growth, timetable may be critical,\" The New York Times, Science Section, pp. B5–B6, 1995.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":173,"type":"book","title":"Mazzoni, P.; Andersen, R. A.; Jordan, M. I. (1991-05-15). \"A more biologically plausible learning rule for neural networks\". Proceedings of the National Academy of Sciences. 88 (10): 4433–4437. Bibcode:1991PNAS...88.4433M. doi:10.1073/pnas.88.10.4433. ISSN 0027-8424. PMC 51674. PMID 1903542.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":174,"type":"book","title":"O'Reilly, Randall C. (1996-07-01). \"Biologically Plausible Error-Driven Learning Using Local Activation Differences: The Generalized Recirculation Algorithm\". Neural Computation. 8 (5): 895–938. doi:10.1162/neco.1996.8.5.895. ISSN 0899-7667.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":175,"type":"book","title":"Testolin, Alberto; Zorzi, Marco (2016). \"Probabilistic Models and Generative Neural Networks: Towards an Unified Framework for Modeling Normal and Impaired Neurocognitive Functions\". Frontiers in Computational Neuroscience. 10: 73. doi:10.3389/fncom.2016.00073. ISSN 1662-5188. PMC 4943066. PMID 27468262.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":176,"type":"book","title":"Testolin, Alberto; Stoianov, Ivilin; Zorzi, Marco (September 2017). \"Letter perception emerges from unsupervised deep learning and recycling of natural image features\". Nature Human Behaviour. 1 (9): 657–664. doi:10.1038/s41562-017-0186-2. ISSN 2397-3374.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":177,"type":"book","title":"Buesing, Lars; Bill, Johannes; Nessler, Bernhard; Maass, Wolfgang (2011-11-03). \"Neural Dynamics as Sampling: A Model for Stochastic Computation in Recurrent Networks of Spiking Neurons\". PLOS Computational Biology. 7 (11): e1002211. Bibcode:2011PLSCB...7E2211B. doi:10.1371/journal.pcbi.1002211. ISSN 1553-7358. PMC 3207943. PMID 22096452.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":178,"type":"book","title":"Morel, Danielle; Singh, Chandan; Levy, William B. (2018-01-25). \"Linearization of excitatory synaptic integration at no extra cost\". Journal of Computational Neuroscience. 44 (2): 173–188. doi:10.1007/s10827-017-0673-5. ISSN 0929-5313. PMID 29372434.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":179,"type":"book","title":"Cash, S.; Yuste, R. (February 1999). \"Linear summation of excitatory inputs by CA1 pyramidal neurons\". Neuron. 22 (2): 383–394. doi:10.1016/s0896-6273(00)81098-3. ISSN 0896-6273. PMID 10069343.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":180,"type":"book","title":"Olshausen, B; Field, D (2004-08-01). \"Sparse coding of sensory inputs\". Current Opinion in Neurobiology. 14 (4): 481–487. doi:10.1016/j.conb.2004.07.007. ISSN 0959-4388.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":181,"type":"book","title":"Yamins, Daniel L K; DiCarlo, James J (March 2016). \"Using goal-driven deep learning models to understand sensory cortex\". Nature Neuroscience. 19 (3): 356–365. doi:10.1038/nn.4244. ISSN 1546-1726.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":182,"type":"book","title":"Zorzi, Marco; Testolin, Alberto (2018-02-19). \"An emergentist perspective on the origin of number sense\". Phil. Trans. R. Soc. B. 373 (1740): 20170043. doi:10.1098/rstb.2017.0043. ISSN 0962-8436. PMC 5784047. PMID 29292348.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":183,"type":"book","title":"Güçlü, Umut; van Gerven, Marcel A. J. (2015-07-08). \"Deep Neural Networks Reveal a Gradient in the Complexity of Neural Representations across the Ventral Stream\". Journal of Neuroscience. 35 (27): 10005–10014. arXiv:1411.6422. doi:10.1523/jneurosci.5023-14.2015. PMID 26157000.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":184,"type":"book","title":"Metz, C. (12 December 2013). \"Facebook's 'Deep Learning' Guru Reveals the Future of AI\". Wired.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":185,"type":"book","title":"\"Google AI algorithm masters ancient game of Go\". Nature News & Comment. Retrieved 2016-01-30.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":186,"type":"book","title":"Silver, David; Huang, Aja; Maddison, Chris J.; Guez, Arthur; Sifre, Laurent; Driessche, George van den; Schrittwieser, Julian; Antonoglou, Ioannis; Panneershelvam, Veda; Lanctot, Marc; Dieleman, Sander; Grewe, Dominik; Nham, John; Kalchbrenner, Nal; Sutskever, Ilya; Lillicrap, Timothy; Leach, Madeleine; Kavukcuoglu, Koray; Graepel, Thore; Hassabis, Demis (28 January 2016). \"Mastering the game of Go with deep neural networks and tree search\". Nature. 529 (7587): 484–489. Bibcode:2016Natur.529..484S. doi:10.1038/nature16961. ISSN 0028-0836. PMID 26819042.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":187,"type":"book","title":"\"A Google DeepMind Algorithm Uses Deep Learning and More to Master the Game of Go | MIT Technology Review\". MIT Technology Review. Retrieved 2016-01-30.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":188,"type":"book","title":"\"Blippar Demonstrates New Real-Time Augmented Reality App\". TechCrunch.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":189,"type":"book","title":"\"TAMER: Training an Agent Manually via Evaluative Reinforcement - IEEE Conference Publication\". ieeexplore.ieee.org. Retrieved 2018-08-29.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":190,"type":"book","title":"\"Talk to the Algorithms: AI Becomes a Faster Learner\". governmentciomedia.com. Retrieved 2018-08-29.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":191,"type":"book","title":"Marcus, Gary (2018-01-14). \"In defense of skepticism about deep learning\". Gary Marcus. Retrieved 2018-10-11.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":192,"type":"book","title":"Knight, Will (2017-03-14). \"DARPA is funding projects that will try to open up AI's black boxes\". MIT Technology Review. Retrieved 2017-11-02.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":193,"type":"book","title":"Marcus, Gary (November 25, 2012). \"Is \"Deep Learning\" a Revolution in Artificial Intelligence?\". The New Yorker. Retrieved 2017-06-14.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":194,"type":"book","title":"Smith, G. W. (March 27, 2015). \"Art and Artificial Intelligence\". ArtEnt. Archived from the original on June 25, 2017. Retrieved March 27, 2015.CS1 maint: BOT: original-url status unknown (link)","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":195,"type":"book","title":"Mellars, Paul (February 1, 2005). \"The Impossible Coincidence: A Single-Species Model for the Origins of Modern Human Behavior in Europe\" (PDF). Evolutionary Anthropology: Issues, News, and Reviews. Retrieved April 5, 2017.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":196,"type":"book","title":"Alexander Mordvintsev; Christopher Olah; Mike Tyka (June 17, 2015). \"Inceptionism: Going Deeper into Neural Networks\". Google Research Blog. Retrieved June 20, 2015.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":197,"type":"book","title":"Alex Hern (June 18, 2015). \"Yes, androids do dream of electric sheep\". The Guardian. Retrieved June 20, 2015.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":198,"type":"book","title":"Goertzel, Ben (2015). \"Are there Deep Reasons Underlying the Pathologies of Today's Deep Learning Algorithms?\" (PDF).","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":199,"type":"book","title":"Nguyen, Anh; Yosinski, Jason; Clune, Jeff (2014). \"Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images\". arXiv:1412.1897 [cs.CV].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":200,"type":"book","title":"Szegedy, Christian; Zaremba, Wojciech; Sutskever, Ilya; Bruna, Joan; Erhan, Dumitru; Goodfellow, Ian; Fergus, Rob (2013). \"Intriguing properties of neural networks\". arXiv:1312.6199 [cs.CV].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":201,"type":"book","title":"Zhu, S.C.; Mumford, D. (2006). \"A stochastic grammar of images\". Found. Trends Comput. Graph. Vis. 2 (4): 259–362. CiteSeerX 10.1.1.681.2190. doi:10.1561/0600000018.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":202,"type":"book","title":"Miller, G. A., and N. Chomsky. \"Pattern conception.\" Paper for Conference on pattern detection, University of Michigan. 1957.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":203,"type":"book","title":"Eisner, Jason. \"Deep Learning of Recursive Structure: Grammar Induction\".","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":204,"type":"book","title":"\"AI Is Easy to Fool—Why That Needs to Change\". Singularity Hub. 2017-10-10. Retrieved 2017-10-11.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":205,"type":"book","title":"Gibney, Elizabeth (2017). \"The scientist who spots fake videos\". Nature. doi:10.1038/nature.2017.22784.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false}],"recommendReferences":null,"auditState":2,"lemmaLevel":1,"origin":0,"originEnTitle":null,"originZhTitle":null,"pv":42044,"auditType":0,"synonyms":["Deep Learning"],"showEditTime":"2019.12.13 18:45","auditors":[{"uid":0,"name":"Ki.κe","pic":"https://web.archive.org/web/20221025113558/https://wx.qlogo.cn/mmopen/vi_32/y67kfr32Doib4wg71Jiau7jVWvharic3nRKgdRRQSl6koeQJCo0GQs2Krw0vwdFRsOWnHIQOwAZsSg5lIkIrFCOcQ/132","introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":"","jobBrief":"","role":0,"roleName":null,"title":"","professionalTitle":null,"phoneNo":null,"editable":true,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false}],"hasZhishiNav":false,"auditInfos":{},"isHistory":false};</script><script crossorigin="anonymous" src="./438.深度学习 - 搜狗科学百科_files/aegis.min.js.download"></script><script crossorigin="anonymous" src="./438.深度学习 - 搜狗科学百科_files/main_2020092401.js.download"></script><script crossorigin="anonymous" src="./438.深度学习 - 搜狗科学百科_files/react.production.min.js.download"></script><script crossorigin="anonymous" src="./438.深度学习 - 搜狗科学百科_files/react-dom.production.min.js.download"></script><script crossorigin="anonymous" src="./438.深度学习 - 搜狗科学百科_files/jquery-1.11.1.min.js.download"></script><script crossorigin="anonymous" src="./438.深度学习 - 搜狗科学百科_files/main_2022062701.js.download"></script><script crossorigin="anonymous" src="./438.深度学习 - 搜狗科学百科_files/main_66bbe21.js.download"></script><script crossorigin="anonymous" src="./438.深度学习 - 搜狗科学百科_files/react.production.min.js.download"></script><script crossorigin="anonymous" src="./438.深度学习 - 搜狗科学百科_files/react-dom.production.min.js.download"></script><script crossorigin="anonymous" src="./438.深度学习 - 搜狗科学百科_files/main_edf0f08.js.download"></script>
</body></html>