<!DOCTYPE html>
<!-- saved from url=(0083)https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm -->
<html class="" data-reactroot=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script src="./546.神经架构搜索 - 搜狗科学百科_files/analytics.js.download" type="text/javascript"></script>
<script type="text/javascript">window.addEventListener('DOMContentLoaded',function(){var v=archive_analytics.values;v.service='wb';v.server_name='wwwb-app218.us.archive.org';v.server_ms=4080;archive_analytics.send_pageview({});});</script>
<script type="text/javascript" src="./546.神经架构搜索 - 搜狗科学百科_files/bundle-playback.js.download" charset="utf-8"></script>
<script type="text/javascript" src="./546.神经架构搜索 - 搜狗科学百科_files/wombat.js.download" charset="utf-8"></script>
<script type="text/javascript">
  __wm.init("https://web.archive.org/web");
  __wm.wombat("https://baike.sogou.com/kexue/d10546.htm","20221025114110","https://web.archive.org/","web","/_static/",
	      "1666698070");
</script>
<link rel="stylesheet" type="text/css" href="./546.神经架构搜索 - 搜狗科学百科_files/banner-styles.css">
<link rel="stylesheet" type="text/css" href="./546.神经架构搜索 - 搜狗科学百科_files/iconochive.css">
<!-- End Wayback Rewrite JS Include -->
<meta name="save" content="history"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="baidu-site-verification" content="VWGb6TyYx8"><meta content="神经架构搜索 - 搜狗科学百科" name="keywords"><meta content="搜狗科学百科是一部有着平等、协作、分享、自由理念的网络科学全书，为每一个互联网用户创造一个涵盖所有领域知识、服务的中文知识性平台。" name="description"><meta http-equiv="x-dns-prefetch-control" content="on"><meta name="server" baike="235" ip="210" env="online"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114110/https://cache.soso.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114110/https://hhy.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114110/https://pic.baike.soso.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114110/https://ugc.qpic.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114110/https://xui.ptlogin2.qq.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114110/https://q1.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114110/https://q2.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114110/https://q3.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114110/https://q4.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114110/https://q.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114110/https://img01.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114110/https://img02.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114110/https://img03.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114110/https://img04.sogoucdn.com/"><link rel="Shortcut Icon" href="https://web.archive.org/web/20221025114110im_/https://www.sogou.com/images/logo/new/favicon.ico?v=4"><link rel="Bookmark" href="https://www.sogou.com/images/logo/new/favicon.ico?v=4"><link href="./546.神经架构搜索 - 搜狗科学百科_files/base_b849887.css" rel="stylesheet"><link href="./546.神经架构搜索 - 搜狗科学百科_files/detail_378aed5.css" rel="stylesheet"><link href="./546.神经架构搜索 - 搜狗科学百科_files/inviteAudit_7894507.css" rel="stylesheet"><link rel="stylesheet" href="./546.神经架构搜索 - 搜狗科学百科_files/highlight.min.css"><title>神经架构搜索 - 搜狗科学百科</title><style>.onekey-close {
	position: absolute;
	top: 16px;
	right: 16px;
	width: 24px;
	height: 24px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	text-indent: -999em;
	background-size: 84px;
	background-position: -63px 0;
}

.onekey-login {
	position: absolute;
	top: 16.4%;
	left: 0;
	right: 0;
	width: 100%;
}

/* .onekey-login-img {
    width: 75px;
    height: 75px;
    background: url("https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/images/sprite_wap_baike.png") no-repeat;
    background-size: 100px 91px;
    background-position: 0 0;
    background-repeat: no-repeat;
    margin: 0 auto;
} */

.onekey-login-title {
	text-align: center;
	padding-bottom: 3px;
	font-size: 21px;
	font-weight: bold;
	line-height: 30px;
	color: #000;
}

.onekey-login-txt {
	text-align: center;
	font-family: PingFangSC;
	font-size: 14px;
	line-height: 20px;
	color: #8f8f8f;
}

.onekey-login-qq,
.onekey-login-wx,
.onekey-login-phone {
	display: block;
	width: 245px;
	height: 54px;
	border-radius: 45px;
	text-align: center;

	margin: 0 auto;
	font-size: 17px;
	line-height: 24px;
	color: #000;
	/* padding: 16px 77px; */
	border-radius: 12px;
	border: solid 1px #e0e0e0;
}
.onekey-qq-content,
.onekey-vx-content,
.onekey-phone-content {
	display: inline-block;
	margin-top: 16px;
}
.onekey-qq-content {
	padding: 0 5px;
}

.onekey-login-qq {
	margin-top: 48px;
	margin-bottom: 24px;
}

.onekey-login-qq:before {
	display: inline-block;
	content: "";
	width: 20px;
	height: 20px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 80px;
	background-position: -20px 0;
	vertical-align: top;
	margin: 17px 8px 0 0;
}

.onekey-login-wx {
	margin-bottom: 24px;
}

.onekey-login-wx:before {
	display: inline-block;
	content: "";
	width: 21px;
	height: 21px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 84px;
	background-position: 0 0;
	vertical-align: top;
	margin: 17px 10px 0 0;
}

.onekey-login-phone {
}

.onekey-login-phone:before {
	display: inline-block;
	content: "";
	width: 21px;
	height: 21px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 84px;
	background-position: -42px 0;
	vertical-align: top;
	margin: 17px 10px 0 0;
}

.onekey-fixed {
	z-index: 100;
	position: fixed;
	top: 0;
	bottom: 0;
	left: 0;
	right: 0;
	background: #fff;
	width: 100%;
	height: 100%;
}

.onekey-fixed.forbid {
	z-index: 100;
	position: fixed;
	top: auto;
	bottom: 68px;
	left: 9%;
	right: 0;
	background: rgba(0, 0, 0, 0.7);
	width: 82%;
	height: 43px;
	border-radius: 25px;
	color: #ffffff;
}
.onekey-login-title.forbid {
	text-align: center;
	padding-bottom: 3px;
	font-size: 14px;
	font-weight: normal;
	line-height: 30px;
	color: white;
}
</style><style>#login_mask {
  background: #000;
  opacity: 0.5;
  filter: alpha(opacity=50);
  position: fixed;
  /*fixed好像在哪个IE上有BUG，先用用*/
  left: 0;
  top: 0;
  z-index: 999;
  height: 100%;
}

#login_iframe_container {
  position: fixed;
  width: 550px;
  height: 360px;
  z-index: 1020;
  background-color: #ffffff;
}

@media screen and (max-width: 828px) {
  #login_iframe_container {
    top: 50% !important;
    left: 50% !important;
    transform: translate(-50%, -50%);
  }
}

#login_iframe_container.new-login {
  width: 550px;
  height: 360px;
  background-image: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/background_2a4a8a6.png);
}

#login_iframe_container.new-login.no-bg {
  background: #fff;
}

#login_iframe_container.new-login .login-title {
  width: 100%;
  height: 42px;
  line-height: 42px;
  text-align: center;
  font-size: 30px;
  letter-spacing: 0.19px;
  color: #ffffff;
  margin-top: 62px;
}
#login_iframe_container.new-login .forbid-title {
  width: 100%;
  height: 42px;
  line-height: 42px;
  text-align: center;
  font-size: 24px;
  letter-spacing: 0.19px;
  color: #333333;
  margin-top: 150px;
}

#login_iframe_container.new-login.no-bg .login-title {
  color: #333333;
}

#login_iframe_container.new-login .login-subtitle {
  width: 100%;
  height: 18px;
  line-height: 18px;
  font-size: 13px;
  letter-spacing: 0.08px;
  color: #ffffff;
  text-align: center;
  margin-top: 9px;
  margin-bottom: 43px;
}

#login_iframe_container.new-login.no-bg .login-subtitle {
  color: #999999;
}

#login_iframe_container.new-login .login-subtitle::before {
  content: '';
  display: inline-block;
  width: 10px;
  height: 1px;
  background-color: #ffffff;
  position: relative;
  top: -4px;
  left: -5px;
}

#login_iframe_container.new-login .login-subtitle::after {
  content: '';
  display: inline-block;
  width: 10px;
  height: 1px;
  background-color: #ffffff;
  position: relative;
  top: -4px;
  left: 5px;
}

#login_iframe_container.new-login.no-bg .login-subtitle::before {
  background-color: #999999;
}

#login_iframe_container.new-login.no-bg .login-subtitle::after {
  background-color: #999999;
}

#login_iframe_container.new-login .close-btn {
  position: absolute;
  top: 20px;
  right: 20px;
  width: 12px;
  height: 12px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -59px -10px;
  background-size: 81px 91px;
  cursor: pointer;
}

#login_iframe_container.new-login .login-btn {
  width: 220px;
  height: 47px;
  border-radius: 24px;
  border: solid 1px #dddddd;
  background-color: #ffffff;
  margin: 0 auto;
  margin-top: 28px;
  position: relative;
  display: block;
}

#login_iframe_container.new-login .login-btn .login-icon {
  position: absolute;
}

#login_iframe_container.new-login .login-btn .login-text {
  width: 61px;
  height: 47px;
  line-height: 47px;
  vertical-align: middle;
  font-size: 15px;
  letter-spacing: 0.1px;
  color: #666666;
  position: absolute;
  right: 62px;
}

#login_iframe_container.new-login .login-btn.qq-btn .login-icon {
  width: 22px;
  height: 27px;
  top: 10px;
  left: 67px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -10px -54px;
  background-size: 81px 91px;
}

#login_iframe_container.new-login .login-btn.qq-btn .login-text {
  right: 59px;
}

#login_iframe_container.new-login .login-btn.wechat-btn .login-icon {
  width: 29px;
  height: 24px;
  top: 12px;
  left: 62px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -10px -10px;
  background-size: 81px 91px;
}</style><style>/* -- container -- */
.rodal,
.rodal-mask {
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: 100;
}

.rodal {
    position: fixed;
}

/* -- mask -- */
.rodal-mask {
    position: fixed;
    background: rgba(0, 0, 0, .5);
}

/* -- dialog -- */
.rodal-dialog {
    position: absolute;
    z-index: 101;
    background: #fff;
    border-radius: 3px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, .2);
}

.rodal-center {
    top: 50%;
    transform: translateY(-50%);
    left: 0;
    right: 0;
    margin: 0 auto;
}

.rodal-bottom {
    left: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

.rodal-top {
    left: 0;
    right: 0;
    top: 0;
    margin: auto;
}

.rodal-left {
    top: 0;
    left: 0;
    bottom: 0;
    margin: auto;
}

.rodal-right {
    top: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

/* -- close button -- */
.rodal-close {
    position: absolute;
    cursor: pointer;
    top: 16px;
    right: 16px;
    width: 16px;
    height: 16px;
}

.rodal-close:before,
.rodal-close:after {
    position: absolute;
    content: '';
    height: 2px;
    width: 100%;
    top: 50%;
    left: 0;
    margin-top: -1px;
    background: #999;
    border-radius: 100%;
    -webkit-transition: background .2s;
    transition: background .2s;
}

.rodal-close:before {
    -webkit-transform: rotate(45deg);
    transform: rotate(45deg);
}

.rodal-close:after {
    -webkit-transform: rotate(-45deg);
    transform: rotate(-45deg);
}

.rodal-close:hover:before,
.rodal-close:hover:after {
    background: #333;
}

/* -- fade -- */
/* @-webkit-keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

@keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

.rodal-fade-enter {
    -webkit-animation: rodal-fade-enter both ease-in;
    animation: rodal-fade-enter both ease-in;
} */

@-webkit-keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

@keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

.rodal-fade-leave {
    -webkit-animation: rodal-fade-leave both ease-out;
    animation: rodal-fade-leave both ease-out;
}

/* -- zoom -- */
@-webkit-keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-enter {
    -webkit-animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-leave {
    -webkit-animation: rodal-zoom-leave both;
    animation: rodal-zoom-leave both;
}

/* -- slideDown -- */
@-webkit-keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-enter {
    -webkit-animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-leave {
    -webkit-animation: rodal-slideDown-leave both;
    animation: rodal-slideDown-leave both;
}

/* -- slideLeft -- */
@-webkit-keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-enter {
    -webkit-animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-leave {
    -webkit-animation: rodal-slideLeft-leave both;
    animation: rodal-slideLeft-leave both;
}

/* -- slideRight -- */
@-webkit-keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-enter {
    -webkit-animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-leave {
    -webkit-animation: rodal-slideRight-leave both;
    animation: rodal-slideRight-leave both;
}

/* -- slideUp -- */
@-webkit-keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-enter {
    -webkit-animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
    animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
}

@-webkit-keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-leave {
    -webkit-animation: rodal-slideUp-leave both;
    animation: rodal-slideUp-leave both;
}

/* -- flip -- */
@-webkit-keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

@keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

.rodal-flip-enter {
    -webkit-animation: rodal-flip-enter both ease-in;
    animation: rodal-flip-enter both ease-in;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

@-webkit-keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

@keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

.rodal-flip-leave {
    -webkit-animation: rodal-flip-leave both;
    animation: rodal-flip-leave both;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

/* -- rotate -- */
@-webkit-keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-enter {
    -webkit-animation: rodal-rotate-enter both;
    animation: rodal-rotate-enter both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

@-webkit-keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-leave {
    -webkit-animation: rodal-rotate-leave both;
    animation: rodal-rotate-leave both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

/* -- door -- */
@-webkit-keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

@keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

.rodal-door-enter {
    -webkit-animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

@keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

.rodal-door-leave {
    -webkit-animation: rodal-door-leave both;
    animation: rodal-door-leave both;
}</style><style>/* -- container -- */
.rodal,
.rodal-mask {
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: 100;
}

.rodal {
    position: fixed;
}

/* -- mask -- */
.rodal-mask {
    position: fixed;
    background: rgba(0, 0, 0, .5);
}

/* -- dialog -- */
.rodal-dialog {
    position: absolute;
    z-index: 101;
    background: #fff;
    border-radius: 3px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, .2);
}

.rodal-center {
    top: 50%;
    transform: translateY(-50%);
    left: 0;
    right: 0;
    margin: 0 auto;
}

.rodal-bottom {
    left: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

.rodal-top {
    left: 0;
    right: 0;
    top: 0;
    margin: auto;
}

.rodal-left {
    top: 0;
    left: 0;
    bottom: 0;
    margin: auto;
}

.rodal-right {
    top: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

/* -- close button -- */
.rodal-close {
    position: absolute;
    cursor: pointer;
    top: 16px;
    right: 16px;
    width: 16px;
    height: 16px;
}

.rodal-close:before,
.rodal-close:after {
    position: absolute;
    content: '';
    height: 2px;
    width: 100%;
    top: 50%;
    left: 0;
    margin-top: -1px;
    background: #999;
    border-radius: 100%;
    -webkit-transition: background .2s;
    transition: background .2s;
}

.rodal-close:before {
    -webkit-transform: rotate(45deg);
    transform: rotate(45deg);
}

.rodal-close:after {
    -webkit-transform: rotate(-45deg);
    transform: rotate(-45deg);
}

.rodal-close:hover:before,
.rodal-close:hover:after {
    background: #333;
}

/* -- fade -- */
/* @-webkit-keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

@keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

.rodal-fade-enter {
    -webkit-animation: rodal-fade-enter both ease-in;
    animation: rodal-fade-enter both ease-in;
} */

@-webkit-keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

@keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

.rodal-fade-leave {
    -webkit-animation: rodal-fade-leave both ease-out;
    animation: rodal-fade-leave both ease-out;
}

/* -- zoom -- */
@-webkit-keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-enter {
    -webkit-animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-leave {
    -webkit-animation: rodal-zoom-leave both;
    animation: rodal-zoom-leave both;
}

/* -- slideDown -- */
@-webkit-keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-enter {
    -webkit-animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-leave {
    -webkit-animation: rodal-slideDown-leave both;
    animation: rodal-slideDown-leave both;
}

/* -- slideLeft -- */
@-webkit-keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-enter {
    -webkit-animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-leave {
    -webkit-animation: rodal-slideLeft-leave both;
    animation: rodal-slideLeft-leave both;
}

/* -- slideRight -- */
@-webkit-keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-enter {
    -webkit-animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-leave {
    -webkit-animation: rodal-slideRight-leave both;
    animation: rodal-slideRight-leave both;
}

/* -- slideUp -- */
@-webkit-keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-enter {
    -webkit-animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
    animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
}

@-webkit-keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-leave {
    -webkit-animation: rodal-slideUp-leave both;
    animation: rodal-slideUp-leave both;
}

/* -- flip -- */
@-webkit-keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

@keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

.rodal-flip-enter {
    -webkit-animation: rodal-flip-enter both ease-in;
    animation: rodal-flip-enter both ease-in;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

@-webkit-keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

@keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

.rodal-flip-leave {
    -webkit-animation: rodal-flip-leave both;
    animation: rodal-flip-leave both;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

/* -- rotate -- */
@-webkit-keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-enter {
    -webkit-animation: rodal-rotate-enter both;
    animation: rodal-rotate-enter both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

@-webkit-keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-leave {
    -webkit-animation: rodal-rotate-leave both;
    animation: rodal-rotate-leave both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

/* -- door -- */
@-webkit-keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

@keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

.rodal-door-enter {
    -webkit-animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

@keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

.rodal-door-leave {
    -webkit-animation: rodal-door-leave both;
    animation: rodal-door-leave both;
}</style>
<!--百度统计-->
<script>
   var _hmt = _hmt || [];
   (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?3c7614be3026469d5a60f41ab30b5082";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
      })();
</script>
</head>
<body class=""><!-- BEGIN WAYBACK TOOLBAR INSERT -->
<style type="text/css">
body {
  margin-top:0 !important;
  padding-top:0 !important;
  /*min-width:800px !important;*/
}
</style>
<script>__wm.rw(0);</script>
<div id="wm-ipp-base" lang="en" style="display: block; direction: ltr;">
</div><div id="wm-ipp-print">The Wayback Machine - https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm</div>
<script type="text/javascript">//<![CDATA[
__wm.bt(675,27,25,2,"web","https://baike.sogou.com/kexue/d10546.htm","20221025114110",1996,"/_static/",["/_static/css/banner-styles.css?v=S1zqJCYt","/_static/css/iconochive.css?v=qtvMKcIJ"], false);
  __wm.rw(1);
//]]></script>
<!-- END WAYBACK TOOLBAR INSERT --><script>window._gtag=window._gtag||{};window._gtag.shouldGrayed = false;if ('9473f1e1686c45d4b8510668ec42710d') window._gtag.traceId = '9473f1e1686c45d4b8510668ec42710d';if ({"illegality":true}) window.userInfo = {"illegality":true};</script><div class="topnavbox"><ul class="topnav"><li><a href="https://web.archive.org/web/20221025114110/https://www.sogou.com/web?query=">网页</a></li><li><a href="https://web.archive.org/web/20221025114110/https://weixin.sogou.com/weixin?p=75351201">微信</a></li><li><a href="https://web.archive.org/web/20221025114110/https://zhihu.sogou.com/zhihu?p=75351218">知乎</a></li><li><a href="https://web.archive.org/web/20221025114110/https://pic.sogou.com/pics?query=">图片</a></li><li><a href="https://web.archive.org/web/20221025114110/https://v.sogou.com/v?query=">视频</a></li><li><a href="https://web.archive.org/web/20221025114110/https://mingyi.sogou.com/">医疗</a></li><li class="cur"><strong>科学</strong></li><li><a href="https://web.archive.org/web/20221025114110/https://hanyu.sogou.com/">汉语</a></li><li><a href="https://web.archive.org/web/20221025114110/https://wenwen.sogou.com/">问问</a></li><li><a href="https://web.archive.org/web/20221025114110/https://www.sogou.com/docs/more.htm">更多<span class="topraquo">»</span></a></li></ul></div><div id="header"><div class="header-wrap"><a class="header-logo" href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue"></a><div class="header-search"><div class="querybox" id="suggBox"><form><input id="searchInput" class="query" type="text" placeholder="搜科学领域专业百科词条" name="query" autocomplete="off" value=""><a href="javascript:;" class="query-search"></a></form></div></div><div class="header-rgt"><span class="btn-header-rgt btn-edit" id="editLemma">创建</span><div class="header-user no-login"></div></div></div></div><div class="fixed-placeholder" style="visibility:none"></div><div id="container" class=""><div class="content lemma-level1"><div class="detail-title" id="abstract-title"><h1>神经架构搜索</h1><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#!" class="detail-edit">编辑</a></div><div class="section_content" data-id="14995399475462673"><div><p>神经网络架构搜索(NAS)<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_1" class="kx_ref">[1]</a></sup><sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_2" class="kx_ref">[2]</a></sup> 是一种用于自动设计<b>人工神经网络</b>(ANN)的技术，其中人工神经网络是机器学习领域中广泛使用的模型。神经网络架构搜索已被用来设计与手工设计的体系结构性能相当或优于手工设计的体系结构的网络。<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_3" class="kx_ref">[3]</a></sup><sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_4" class="kx_ref">[4]</a></sup> 神经网络架构搜索的方法可以根据搜索空间、搜索策略和使用的性能评估策略进行分类:<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_1" class="kx_ref">[1]</a></sup> </p>
<p>-搜索空间定义了可以设计和优化的人工神经网络的类型。</p>
<p>- 搜索策略定义了用于探索搜索空间的方法。</p>
<p>- 性能评估策略从设计上评估可能的人工神经网络的性能(无需构建和训练神经网络)。</p>
<p>- 神经网络架构搜索与超参数优化密切相关，是自动机器学习的一个分支。</p></div></div><div id="catalog"><h2 class="title2">目录<a href="javascript:" class="detail-edit">编辑</a></h2><div class="catalog_wrap" style=""><ul class="catalog_list col2"><li><span class="order">1</span><a href="javascript:" data-level="1" data-id="14995399475462674">强化学习</a></li><li><span class="order">2</span><a href="javascript:" data-level="1" data-id="14995399492239885">进化算法</a></li><li><span class="order">3</span><a href="javascript:" data-level="1" data-id="14995399492239886">爬山算法</a></li><li><span class="order">4</span><a href="javascript:" data-level="1" data-id="20060670850510344">可微分算法</a></li></ul><ul class="catalog_list col2"><li><span class="order">5</span><a href="javascript:" data-level="1" data-id="14995399492239887">多目标搜索</a></li><li><span class="order">6</span><a href="javascript:" data-level="1" data-id="references">参考文献</a></li></ul></div></div><div id="paragraphs"><div><div id="par_14995399475462674"><h2 class="title">1 强化学习<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>强化学习可以作为神经网络架构搜索的一种搜索策略。Zoph等人<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_3" class="kx_ref">[3]</a></sup> 针对CIFS-10数据集应用了基于强化学习的神经网络架构搜索，生成的网络体系结构在准确性方面可与最佳的人工设计的体系结构相媲美，测试错误率为3.65，比起使用了类似设计的人工设计模型，错误率低了0.09%，并且速度快了1.05倍。在Penn Treebank数据集上，该模型构建了一个优于LSTM的循环单元，在测试集上的困惑度达到了62.4，比之前领先的系统低了3.6。在PTB字符语言建模任务中，它取得了每个字符1.214位的效果。<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_3" class="kx_ref">[3]</a></sup> </p><p>直接在大型数据集上学习模型架构可能是一个漫长的过程。NASNet<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_4" class="kx_ref">[4]</a></sup><sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_5" class="kx_ref">[5]</a></sup> 通过将为小数据集设计的构造块转移到大数据集来解决这个问题。该设计被限制为使用两种类型的卷积单元来返回特征图，在将卷积的结果作为输入特征图时，返回的特征图主要有两个作用:返回相同范围(高度和宽度)的图的正常单元和返回的特征图高度和宽度减少两倍的缩减单元。对于缩减单元，应用于单元输入的初始操作作用了两步(以缩减高度和宽度)。<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_4" class="kx_ref">[4]</a></sup> 该设计包括了多个学习方面的元素，例如各个较高层将哪个较低层作为输入，在该层应用的变换以及在各层合并多个输出等。在过去的研究中，研究人员为CIFS-10数据集设计了最佳卷积层(或“单元”)，然后通过堆叠该单元的副本将其应用于ImageNet数据集，每个副本都有自己的参数。该方法的Top1准确率为82.7%，Top5准确率为96.2%。这超过了人类发明的最好的架构，减少了90亿次浮点运算——减少了28%。该系统在不同的计算水平上不断超过人工设计的方案。从图像分类中学习到的图像特征也可以迁移到其他计算机视觉问题上。例如，在目标检测任务中，集成了Faster-RCNN框架的学习单元在COCO数据集上的性能提高了4.0%。<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_4" class="kx_ref">[4]</a></sup> </p><p>在所谓的高效神经网络架构搜索(ENAS)中，控制器通过学习在大图中搜索最佳子图来发现架构。控制器用策略梯度法来进行训练：选择一个子图，使验证集的预期回报最大化。通过最小化规范交叉熵损失来训练对应子图的模型。多个子模型共享参数，ENAS比其他方法需要更少的GPU时间，比“标准”的神经网络架构搜索少1000倍。在CIFAR-10上，ENAS的设计达到了2.89%的测试误差，与NASNet相当。在宾州树库中，ENAS的设计达到了55.8的测试困惑度。<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_6" class="kx_ref">[6]</a></sup> </p></div></div><div id="par_14995399492239885"><h2 class="title">2 进化算法<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>几个小组在神经网络架构搜索中采用了进化算法。<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_7" class="kx_ref">[7]</a></sup><sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_8" class="kx_ref">[8]</a></sup><sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_9" class="kx_ref">[9]</a></sup> 在改进人工神经网络的过程中，突变是指诸如添加层、移除层或改变层类型(例如，从卷积到池化)的操作。在CIFAR-10上，进化算法和RL表现相当，但都优于随机搜索。<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_8" class="kx_ref">[8]</a></sup> </p></div></div><div id="par_14995399492239886"><h2 class="title">3 爬山算法<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>另一组使用了爬山程序，应用网络变形，然后进行短余弦退火优化运行。这种方法产生了有竞争力的结果，培训需要的资源的数量级与培训单一网络所需资源的数量级相同。例如，在CIFAR-10上，该方法在单个GPU设计并训练了12小时，得到了错误率低于5%的网络。<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_10" class="kx_ref">[10]</a></sup></p></div></div><div id="par_20060670850510344"><h2 class="title">4 可微分算法<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>最近的工作中，将网络架构的搜索看作对一个有向无环图(Directed Acyclic Graph, DAG)的搜索<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_11" class="kx_ref">[11]</a></sup>，主要原理是将原问题(对两个节点之间连接的运算操作进行选择，例如可以是卷积、池化或者是没有连接)松弛化，把离散搜索空间变成了连续搜索空间，从而可以使用梯度下降的方式来优化超参数，从而得到最优的架构。该方法在CIFAR-10上得到了2.76%的测试错误率，在PTB上得到了58.1%的困惑度，所花费时间与ENAS差不多。另外，Auto-Deeplab和FBNet等方法也使用了松弛化方法来进行可微分搜索<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_12" class="kx_ref">[12]</a></sup><sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_13" class="kx_ref">[13]</a></sup>。</p></div></div><div id="par_14995399492239887"><h2 class="title">5 多目标搜索<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>虽然大多数方法只专注于寻找具有最优预测性能的体系结构，但对于大多数实际应用，其他的优化目标也是很重要的，例如内存消耗、模型大小或推理时间(即获得预测结果所需的时间)。正因为如此，研究人员建立了多目标搜索。<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_14" class="kx_ref">[14]</a></sup><sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_15" class="kx_ref">[15]</a></sup> </p><p>LEMONADE<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_14" class="kx_ref">[14]</a></sup> 是一种进化算法，它采用拉马克进化理论思想来有效地优化多个目标。在每一代中，为了改善和当前ANNs有关的Pareto边界，子网络都会被生成。</p><p>神经网络架构师<sup><a href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/d10546.htm#quote_15" class="kx_ref">[15]</a></sup> 应该具有应用网络嵌入方法和性能预测的能力，来进行资源敏感的、基于强化学习的多目标优化和神经网络架构搜索。网络嵌入将现有网络编码成可训练的嵌入向量。基于嵌入向量，控制器网络生成目标网络的变换。多目标奖励函数考虑了网络准确性、计算资源和训练时间。奖励由多个性能模拟网络预测，这些网络是预先训练的或与控制器网络共同训练的。控制器网络通过策略梯度进行训练。经过修改后，得到由准确度网络和训练时间网络评估的候选网络。通过某种奖励机制组合这些结果，并将其输出传回至控制器网络。</p></div></div></div></div><div id="references"><h2 class="title" id="par_references">参考文献</h2><ul class="references"><li id="quote_1"><span class="references-num">[1]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Elsken, Thomas; Metzen, Jan Hendrik; Hutter, Frank: Neural Architecture Search: A Survey, Journal of Machine Learning Research, 2019.</span></p></li><li id="quote_2"><span class="references-num">[2]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Wistuba, Martin; Rawat, Ambrish; Pedapati, Tejaswini (2019-05-04). "A Survey on Neural Architecture Search". arXiv:1905.01392 [cs.LG]..</span></p></li><li id="quote_3"><span class="references-num">[3]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Zoph, Barret; Le, Quoc V. (2016-11-04). "Neural Architecture Search with Reinforcement Learning". arXiv:1611.01578 [cs.LG]..</span></p></li><li id="quote_4"><span class="references-num">[4]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Zoph, Barret; Vasudevan, Vijay; Shlens, Jonathon; Le, Quoc V. (2017-07-21). "Learning Transferable Architectures for Scalable Image Recognition". arXiv:1707.07012 [cs.CV]..</span></p></li><li id="quote_5"><span class="references-num">[5]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Zoph, Barret; Vasudevan, Vijay; Shlens, Jonathon; Le, Quoc V. (November 2, 2017). "AutoML for large scale image classification and object detection". Research Blog (in 英语). Retrieved 2018-02-20..</span></p></li><li id="quote_6"><span class="references-num">[6]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Hieu, Pham; Y., Guan, Melody; Barret, Zoph; V., Le, Quoc; Jeff, Dean (2018-02-09). "Efficient Neural Architecture Search via Parameter Sharing". arXiv:1802.03268 [cs.LG]..</span></p></li><li id="quote_7"><span class="references-num">[7]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Real, Esteban; Moore, Sherry; Selle, Andrew; Saxena, Saurabh; Suematsu, Yutaka Leon; Tan, Jie; Le, Quoc; Kurakin, Alex (2017-03-03). "Large-Scale Evolution of Image Classifiers". arXiv:1703.01041 [cs.NE]..</span></p></li><li id="quote_8"><span class="references-num">[8]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Real, Esteban; Aggarwal, Alok; Huang, Yanping; Le, Quoc V. (2018-02-05). "Regularized Evolution for Image Classifier Architecture Search". arXiv:1802.01548 [cs.NE]..</span></p></li><li id="quote_9"><span class="references-num">[9]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Stanley, Kenneth; Miikkulainen, Risto, "Evolving Neural Networks through Augmenting Topologies", in: Evolutionary Computation, 2002.</span></p></li><li id="quote_10"><span class="references-num">[10]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Thomas, Elsken; Jan-Hendrik, Metzen; Frank, Hutter (2017-11-13). "Simple And Efficient Architecture Search for Convolutional Neural Networks". arXiv:1711.04528 [stat.ML]..</span></p></li><li id="quote_11"><span class="references-num">[11]</span><p><a class="ref-back-btn">^</a><span data-url="https://web.archive.org/web/20221025114110/https://arxiv.org/abs/1806.09055" class="blue">Hanxiao Liu, Karen Simonyan, Yiming Yang, &amp;quot;DARTS: Differentiable Architecture Search&amp;quot;.</span>arxiv.org.</p></li><li id="quote_12"><span class="references-num">[12]</span><p><a class="ref-back-btn">^</a><span data-url="https://web.archive.org/web/20221025114110/http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Auto-DeepLab_Hierarchical_Neural_Architecture_Search_for_Semantic_Image_Segmentation_CVPR_2019_paper.html" class="blue">Chenxi Liu, Liang-Chieh Chen, Florian Schroff, Hartwig Adam, Wei Hua, Alan L. Yuille, Li Fei-Fei; &amp;quot;Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation&amp;quot;.</span>CVPR2019.</p></li><li id="quote_13"><span class="references-num">[13]</span><p><a class="ref-back-btn">^</a><span data-url="https://web.archive.org/web/20221025114110/http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_FBNet_Hardware-Aware_Efficient_ConvNet_Design_via_Differentiable_Neural_Architecture_Search_CVPR_2019_paper.html" class="blue">Bichen Wu, Xiaoliang Dai, Peizhao Zhang, Yanghan Wang, Fei Sun, Yiming Wu, Yuandong Tian, Peter Vajda, Yangqing Jia, Kurt Keutze; &amp;quot;FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search&amp;quot;.</span>CVPR2019.</p></li><li id="quote_14"><span class="references-num">[14]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Elsken, Thomas; Metzen, Jan Hendrik; Hutter, Frank (2018-04-24). "Efficient Multi-objective Neural Architecture Search via Lamarckian Evolution". arXiv:1804.09081 [stat.ML]..</span></p></li><li id="quote_15"><span class="references-num">[15]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Zhou, Yanqi; Diamos, Gregory. "Neural Architect: A Multi-objective Neural Architecture Search with Performance Prediction" (PDF). Baidu. Retrieved February 21, 2018..</span></p></li></ul></div><div class="read-num">阅读 <!-- -->147</div></div><div class="right-side" id="rightSide"><div class="side" id="lemma-side"><div class="side-title">版本记录</div><ul class="side-lst"><li><p class="side-lst-txt">暂无</p></li></ul><div class="user-card userCard"></div></div><div class="side"><div class="side-event"></div></div></div></div><div class="footer-box"><div id="footer"><div class="footer-logo-wrap"><div class="footer-logo"></div><div class="footer-logo-text">知识·传播·科普</div></div><div class="footer-info">本网站内容采用<a target="_blank" href="https://web.archive.org/web/20221025114110/https://creativecommons.org/licenses/by-sa/3.0/deed.zh?tdsourcetag=s_pctim_aiomsg">CC-BY-SA 3.0</a>授权</div><div class="footer-btn-wrap"><a target="_blank" href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/help/#user_protocol">用户协议</a><a target="_blank" href="https://web.archive.org/web/20221025114110/http://www.sogou.com/docs/terms.htm?v=1">免责声明</a><a target="_blank" href="https://web.archive.org/web/20221025114110/http://corp.sogou.com/private.html">隐私政策</a><a target="_blank" href="https://web.archive.org/web/20221025114110/https://baike.sogou.com/kexue/intro.htm">关于我们</a></div></div></div><script>window.lemmaInfo ={"lemmaId":"10546","versionId":"20060670816955906","title":"神经架构搜索","subtitle":"","abstracts":{"paragraphId":"14995399475462673","title":"简介","versionId":"20060670816955907","lemmaId":10546,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":76031308,"name":"iCe","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1579253091,"comment":null,"dependVersionId":0,"contentType":2,"content":"<p>神经网络架构搜索(NAS)<sup><a href=\"#quote_1\" class=\"kx_ref\">[1]</a></sup><sup><a href=\"#quote_2\" class=\"kx_ref\">[2]</a></sup> 是一种用于自动设计<b>人工神经网络</b>(ANN)的技术，其中人工神经网络是机器学习领域中广泛使用的模型。神经网络架构搜索已被用来设计与手工设计的体系结构性能相当或优于手工设计的体系结构的网络。<sup><a href=\"#quote_3\" class=\"kx_ref\">[3]</a></sup><sup><a href=\"#quote_4\" class=\"kx_ref\">[4]</a></sup> 神经网络架构搜索的方法可以根据搜索空间、搜索策略和使用的性能评估策略进行分类:<sup><a href=\"#quote_1\" class=\"kx_ref\">[1]</a></sup> </p>\n<p>-搜索空间定义了可以设计和优化的人工神经网络的类型。</p>\n<p>- 搜索策略定义了用于探索搜索空间的方法。</p>\n<p>- 性能评估策略从设计上评估可能的人工神经网络的性能(无需构建和训练神经网络)。</p>\n<p>- 神经网络架构搜索与超参数优化密切相关，是自动机器学习的一个分支。</p>","pics":null,"card":null,"references":[],"versionCount":0},"card":{"paragraphId":"20060670816955913","title":"基本信息","versionId":"20060670816955908","lemmaId":10546,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":76031308,"name":"iCe","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1579253091,"comment":null,"dependVersionId":0,"contentType":3,"content":"","pics":null,"card":{"cardItems":null},"references":[],"versionCount":0},"categories":[{"id":14,"name":"电子与通信技术","parents":[]}],"creator":{"uid":76031308,"name":"唐长成","pic":"https://web.archive.org/web/20221025114110/https://cache.soso.com/qlogo/g?b=oidb&k=hnXiab4vr0areKKo46k4wSQ&s=100&t=1600231953","introduction":null,"educations":[{"schoolName":"清华大学","major":"","degree":"硕士","universityId":1,"universityLogo":"https://web.archive.org/web/20221025114110/https://img01.sogoucdn.com/app/a/200943/2d91f0cc-6013-11e9-aa85-fc4dd4f70029","majorLevel1":null,"majorLevel2":null,"majorLevel3":null,"majorLevel1Id":0,"majorLevel2Id":0,"majorLevel3Id":0,"state":null,"lab":null,"researchField":null}],"jobs":null,"works":null,"educationBrief":"清华大学","jobBrief":"","role":0,"roleName":null,"title":"清华大学 · 硕士","professionalTitle":null,"phoneNo":null,"editable":true,"partnerId":50,"partnerIdCreateTime":1594286504,"partnerIdPoped":true},"createTime":1568626306,"editor":{"uid":76031308,"name":"唐长成","pic":"https://web.archive.org/web/20221025114110/https://cache.soso.com/qlogo/g?b=oidb&k=hnXiab4vr0areKKo46k4wSQ&s=100&t=1600231953","introduction":null,"educations":[{"schoolName":"清华大学","major":"","degree":"硕士","universityId":1,"universityLogo":"https://web.archive.org/web/20221025114110/https://img01.sogoucdn.com/app/a/200943/2d91f0cc-6013-11e9-aa85-fc4dd4f70029","majorLevel1":null,"majorLevel2":null,"majorLevel3":null,"majorLevel1Id":0,"majorLevel2Id":0,"majorLevel3Id":0,"state":null,"lab":null,"researchField":null}],"jobs":null,"works":null,"educationBrief":"清华大学","jobBrief":"","role":0,"roleName":null,"title":"清华大学 · 硕士","professionalTitle":null,"phoneNo":null,"editable":true,"partnerId":50,"partnerIdCreateTime":1594286504,"partnerIdPoped":true},"editTime":1579253091,"state":1,"versionCount":3,"upNum":1,"downNum":0,"pics":[],"catalogs":[{"level":1,"title":"强化学习","paragraphId":"14995399475462674","subCatalogs":null},{"level":1,"title":"进化算法","paragraphId":"14995399492239885","subCatalogs":null},{"level":1,"title":"爬山算法","paragraphId":"14995399492239886","subCatalogs":null},{"level":1,"title":"可微分算法","paragraphId":"20060670850510344","subCatalogs":null},{"level":1,"title":"多目标搜索","paragraphId":"14995399492239887","subCatalogs":null},{"level":1,"title":"参考文献","paragraphId":"-1","subCatalogs":null}],"paragraphs":[{"paragraphId":"14995399475462674","title":"强化学习","versionId":"20060670816955909","lemmaId":10546,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":76031308,"name":"iCe","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1579253091,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>强化学习可以作为神经网络架构搜索的一种搜索策略。Zoph等人<sup><a href=\"#quote_3\" class=\"kx_ref\">[3]</a></sup> 针对CIFS-10数据集应用了基于强化学习的神经网络架构搜索，生成的网络体系结构在准确性方面可与最佳的人工设计的体系结构相媲美，测试错误率为3.65，比起使用了类似设计的人工设计模型，错误率低了0.09%，并且速度快了1.05倍。在Penn Treebank数据集上，该模型构建了一个优于LSTM的循环单元，在测试集上的困惑度达到了62.4，比之前领先的系统低了3.6。在PTB字符语言建模任务中，它取得了每个字符1.214位的效果。<sup><a href=\"#quote_3\" class=\"kx_ref\">[3]</a></sup> </p><p>直接在大型数据集上学习模型架构可能是一个漫长的过程。NASNet<sup><a href=\"#quote_4\" class=\"kx_ref\">[4]</a></sup><sup><a href=\"#quote_5\" class=\"kx_ref\">[5]</a></sup> 通过将为小数据集设计的构造块转移到大数据集来解决这个问题。该设计被限制为使用两种类型的卷积单元来返回特征图，在将卷积的结果作为输入特征图时，返回的特征图主要有两个作用:返回相同范围(高度和宽度)的图的正常单元和返回的特征图高度和宽度减少两倍的缩减单元。对于缩减单元，应用于单元输入的初始操作作用了两步(以缩减高度和宽度)。<sup><a href=\"#quote_4\" class=\"kx_ref\">[4]</a></sup> 该设计包括了多个学习方面的元素，例如各个较高层将哪个较低层作为输入，在该层应用的变换以及在各层合并多个输出等。在过去的研究中，研究人员为CIFS-10数据集设计了最佳卷积层(或“单元”)，然后通过堆叠该单元的副本将其应用于ImageNet数据集，每个副本都有自己的参数。该方法的Top1准确率为82.7%，Top5准确率为96.2%。这超过了人类发明的最好的架构，减少了90亿次浮点运算——减少了28%。该系统在不同的计算水平上不断超过人工设计的方案。从图像分类中学习到的图像特征也可以迁移到其他计算机视觉问题上。例如，在目标检测任务中，集成了Faster-RCNN框架的学习单元在COCO数据集上的性能提高了4.0%。<sup><a href=\"#quote_4\" class=\"kx_ref\">[4]</a></sup> </p><p>在所谓的高效神经网络架构搜索(ENAS)中，控制器通过学习在大图中搜索最佳子图来发现架构。控制器用策略梯度法来进行训练：选择一个子图，使验证集的预期回报最大化。通过最小化规范交叉熵损失来训练对应子图的模型。多个子模型共享参数，ENAS比其他方法需要更少的GPU时间，比“标准”的神经网络架构搜索少1000倍。在CIFAR-10上，ENAS的设计达到了2.89%的测试误差，与NASNet相当。在宾州树库中，ENAS的设计达到了55.8的测试困惑度。<sup><a href=\"#quote_6\" class=\"kx_ref\">[6]</a></sup> </p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995399492239885","title":"进化算法","versionId":"14995399475462670","lemmaId":10546,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":76031308,"name":"唐长成","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233954,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>几个小组在神经网络架构搜索中采用了进化算法。<sup><a href=\"#quote_7\" class=\"kx_ref\">[7]</a></sup><sup><a href=\"#quote_8\" class=\"kx_ref\">[8]</a></sup><sup><a href=\"#quote_9\" class=\"kx_ref\">[9]</a></sup> 在改进人工神经网络的过程中，突变是指诸如添加层、移除层或改变层类型(例如，从卷积到池化)的操作。在CIFAR-10上，进化算法和RL表现相当，但都优于随机搜索。<sup><a href=\"#quote_8\" class=\"kx_ref\">[8]</a></sup> </p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995399492239886","title":"爬山算法","versionId":"20060670816955910","lemmaId":10546,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":76031308,"name":"iCe","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1579253091,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>另一组使用了爬山程序，应用网络变形，然后进行短余弦退火优化运行。这种方法产生了有竞争力的结果，培训需要的资源的数量级与培训单一网络所需资源的数量级相同。例如，在CIFAR-10上，该方法在单个GPU设计并训练了12小时，得到了错误率低于5%的网络。<sup><a href=\"#quote_10\" class=\"kx_ref\">[10]</a></sup></p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"20060670850510344","title":"可微分算法","versionId":"20060670816955911","lemmaId":10546,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":76031308,"name":"iCe","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1579253091,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>最近的工作中，将网络架构的搜索看作对一个有向无环图(Directed Acyclic Graph, DAG)的搜索<sup><a href=\"#quote_11\" class=\"kx_ref\">[11]</a></sup>，主要原理是将原问题(对两个节点之间连接的运算操作进行选择，例如可以是卷积、池化或者是没有连接)松弛化，把离散搜索空间变成了连续搜索空间，从而可以使用梯度下降的方式来优化超参数，从而得到最优的架构。该方法在CIFAR-10上得到了2.76%的测试错误率，在PTB上得到了58.1%的困惑度，所花费时间与ENAS差不多。另外，Auto-Deeplab和FBNet等方法也使用了松弛化方法来进行可微分搜索<sup><a href=\"#quote_12\" class=\"kx_ref\">[12]</a></sup><sup><a href=\"#quote_13\" class=\"kx_ref\">[13]</a></sup>。</p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995399492239887","title":"多目标搜索","versionId":"20060670816955912","lemmaId":10546,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":76031308,"name":"iCe","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1579253091,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>虽然大多数方法只专注于寻找具有最优预测性能的体系结构，但对于大多数实际应用，其他的优化目标也是很重要的，例如内存消耗、模型大小或推理时间(即获得预测结果所需的时间)。正因为如此，研究人员建立了多目标搜索。<sup><a href=\"#quote_14\" class=\"kx_ref\">[14]</a></sup><sup><a href=\"#quote_15\" class=\"kx_ref\">[15]</a></sup> </p><p>LEMONADE<sup><a href=\"#quote_14\" class=\"kx_ref\">[14]</a></sup> 是一种进化算法，它采用拉马克进化理论思想来有效地优化多个目标。在每一代中，为了改善和当前ANNs有关的Pareto边界，子网络都会被生成。</p><p>神经网络架构师<sup><a href=\"#quote_15\" class=\"kx_ref\">[15]</a></sup> 应该具有应用网络嵌入方法和性能预测的能力，来进行资源敏感的、基于强化学习的多目标优化和神经网络架构搜索。网络嵌入将现有网络编码成可训练的嵌入向量。基于嵌入向量，控制器网络生成目标网络的变换。多目标奖励函数考虑了网络准确性、计算资源和训练时间。奖励由多个性能模拟网络预测，这些网络是预先训练的或与控制器网络共同训练的。控制器网络通过策略梯度进行训练。经过修改后，得到由准确度网络和训练时间网络评估的候选网络。通过某种奖励机制组合这些结果，并将其输出传回至控制器网络。</p>","pics":null,"card":null,"references":[],"versionCount":0}],"references":[{"id":1,"type":"book","title":"Elsken, Thomas; Metzen, Jan Hendrik; Hutter, Frank: Neural Architecture Search: A Survey, Journal of Machine Learning Research, 2019","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":2,"type":"book","title":"Wistuba, Martin; Rawat, Ambrish; Pedapati, Tejaswini (2019-05-04). \"A Survey on Neural Architecture Search\". arXiv:1905.01392 [cs.LG].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":3,"type":"book","title":"Zoph, Barret; Le, Quoc V. (2016-11-04). \"Neural Architecture Search with Reinforcement Learning\". arXiv:1611.01578 [cs.LG].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":4,"type":"book","title":"Zoph, Barret; Vasudevan, Vijay; Shlens, Jonathon; Le, Quoc V. (2017-07-21). \"Learning Transferable Architectures for Scalable Image Recognition\". arXiv:1707.07012 [cs.CV].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":5,"type":"book","title":"Zoph, Barret; Vasudevan, Vijay; Shlens, Jonathon; Le, Quoc V. (November 2, 2017). \"AutoML for large scale image classification and object detection\". Research Blog (in 英语). Retrieved 2018-02-20.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":6,"type":"book","title":"Hieu, Pham; Y., Guan, Melody; Barret, Zoph; V., Le, Quoc; Jeff, Dean (2018-02-09). \"Efficient Neural Architecture Search via Parameter Sharing\". arXiv:1802.03268 [cs.LG].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":7,"type":"book","title":"Real, Esteban; Moore, Sherry; Selle, Andrew; Saxena, Saurabh; Suematsu, Yutaka Leon; Tan, Jie; Le, Quoc; Kurakin, Alex (2017-03-03). \"Large-Scale Evolution of Image Classifiers\". arXiv:1703.01041 [cs.NE].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":8,"type":"book","title":"Real, Esteban; Aggarwal, Alok; Huang, Yanping; Le, Quoc V. (2018-02-05). \"Regularized Evolution for Image Classifier Architecture Search\". arXiv:1802.01548 [cs.NE].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":9,"type":"book","title":"Stanley, Kenneth; Miikkulainen, Risto, \"Evolving Neural Networks through Augmenting Topologies\", in: Evolutionary Computation, 2002","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":10,"type":"book","title":"Thomas, Elsken; Jan-Hendrik, Metzen; Frank, Hutter (2017-11-13). \"Simple And Efficient Architecture Search for Convolutional Neural Networks\". arXiv:1711.04528 [stat.ML].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":11,"type":"web","title":"Hanxiao Liu, Karen Simonyan, Yiming Yang, &quot;DARTS: Differentiable Architecture Search&quot;","site":"arxiv.org","url":"https://web.archive.org/web/20221025114110/https://arxiv.org/abs/1806.09055","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":12,"type":"web","title":"Chenxi Liu, Liang-Chieh Chen, Florian Schroff, Hartwig Adam, Wei Hua, Alan L. Yuille, Li Fei-Fei; &quot;Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation&quot;","site":"CVPR2019","url":"https://web.archive.org/web/20221025114110/http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Auto-DeepLab_Hierarchical_Neural_Architecture_Search_for_Semantic_Image_Segmentation_CVPR_2019_paper.html","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":13,"type":"web","title":"Bichen Wu, Xiaoliang Dai, Peizhao Zhang, Yanghan Wang, Fei Sun, Yiming Wu, Yuandong Tian, Peter Vajda, Yangqing Jia, Kurt Keutze; &quot;FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search&quot;","site":"CVPR2019","url":"https://web.archive.org/web/20221025114110/http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_FBNet_Hardware-Aware_Efficient_ConvNet_Design_via_Differentiable_Neural_Architecture_Search_CVPR_2019_paper.html","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":14,"type":"book","title":"Elsken, Thomas; Metzen, Jan Hendrik; Hutter, Frank (2018-04-24). \"Efficient Multi-objective Neural Architecture Search via Lamarckian Evolution\". arXiv:1804.09081 [stat.ML].","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":15,"type":"book","title":"Zhou, Yanqi; Diamos, Gregory. \"Neural Architect: A Multi-objective Neural Architecture Search with Performance Prediction\" (PDF). Baidu. Retrieved February 21, 2018.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false}],"recommendReferences":null,"auditState":2,"lemmaLevel":1,"origin":0,"originEnTitle":null,"originZhTitle":null,"pv":147,"auditType":0,"synonyms":null,"showEditTime":"2020.01.17 17:24","auditors":[{"uid":75234227,"name":"7","pic":"https://web.archive.org/web/20221025114110/https://cache.soso.com/qlogo/g?b=oidb&k=plvPjjqaNicMYKMwhI6yKUA&s=100&t=1555919297","introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":"","jobBrief":"","role":0,"roleName":null,"title":"","professionalTitle":null,"phoneNo":null,"editable":true,"partnerId":177,"partnerIdCreateTime":1595844898,"partnerIdPoped":true}],"hasZhishiNav":false,"auditInfos":{"0":[{"versionId":"0","auditTime":1579399635,"auditorId":75234227,"auditUser":{"uid":75234227,"name":"7","pic":"https://web.archive.org/web/20221025114110/https://cache.soso.com/qlogo/g?b=oidb&k=plvPjjqaNicMYKMwhI6yKUA&s=100&t=1555919297","introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":"","jobBrief":"","role":0,"roleName":null,"title":"","professionalTitle":null,"phoneNo":null,"editable":true,"partnerId":177,"partnerIdCreateTime":1595844898,"partnerIdPoped":true},"auditReason":"通过","auditSuggest":null,"auditResult":2,"auditAnnotations":null}]},"isHistory":false};</script><script crossorigin="anonymous" src="./546.神经架构搜索 - 搜狗科学百科_files/aegis.min.js.download"></script><script crossorigin="anonymous" src="./546.神经架构搜索 - 搜狗科学百科_files/main_2020092401.js.download"></script><script crossorigin="anonymous" src="./546.神经架构搜索 - 搜狗科学百科_files/react.production.min.js.download"></script><script crossorigin="anonymous" src="./546.神经架构搜索 - 搜狗科学百科_files/react-dom.production.min.js.download"></script><script crossorigin="anonymous" src="./546.神经架构搜索 - 搜狗科学百科_files/jquery-1.11.1.min.js.download"></script><script crossorigin="anonymous" src="./546.神经架构搜索 - 搜狗科学百科_files/main_2022062701.js.download"></script><script crossorigin="anonymous" src="./546.神经架构搜索 - 搜狗科学百科_files/main_66bbe21.js.download"></script><script crossorigin="anonymous" src="./546.神经架构搜索 - 搜狗科学百科_files/react.production.min.js.download"></script><script crossorigin="anonymous" src="./546.神经架构搜索 - 搜狗科学百科_files/react-dom.production.min.js.download"></script><script crossorigin="anonymous" src="./546.神经架构搜索 - 搜狗科学百科_files/main_edf0f08.js.download"></script>
</body></html>