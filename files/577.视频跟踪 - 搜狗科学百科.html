<!DOCTYPE html>
<!-- saved from url=(0083)https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/d10577.htm -->
<html class="" data-reactroot=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script src="./577.视频跟踪 - 搜狗科学百科_files/analytics.js.download" type="text/javascript"></script>
<script type="text/javascript">window.addEventListener('DOMContentLoaded',function(){var v=archive_analytics.values;v.service='wb';v.server_name='wwwb-app223.us.archive.org';v.server_ms=176;archive_analytics.send_pageview({});});</script>
<script type="text/javascript" src="./577.视频跟踪 - 搜狗科学百科_files/bundle-playback.js.download" charset="utf-8"></script>
<script type="text/javascript" src="./577.视频跟踪 - 搜狗科学百科_files/wombat.js.download" charset="utf-8"></script>
<script type="text/javascript">
  __wm.init("https://web.archive.org/web");
  __wm.wombat("https://baike.sogou.com/kexue/d10577.htm","20221025114448","https://web.archive.org/","web","/_static/",
	      "1666698288");
</script>
<link rel="stylesheet" type="text/css" href="./577.视频跟踪 - 搜狗科学百科_files/banner-styles.css">
<link rel="stylesheet" type="text/css" href="./577.视频跟踪 - 搜狗科学百科_files/iconochive.css">
<!-- End Wayback Rewrite JS Include -->
<meta name="save" content="history"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="baidu-site-verification" content="VWGb6TyYx8"><meta content="视频跟踪 - 搜狗科学百科" name="keywords"><meta content="搜狗科学百科是一部有着平等、协作、分享、自由理念的网络科学全书，为每一个互联网用户创造一个涵盖所有领域知识、服务的中文知识性平台。" name="description"><meta http-equiv="x-dns-prefetch-control" content="on"><meta name="server" baike="235" ip="210" env="online"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114448/https://cache.soso.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114448/https://hhy.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114448/https://pic.baike.soso.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114448/https://ugc.qpic.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114448/https://xui.ptlogin2.qq.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114448/https://q1.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114448/https://q2.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114448/https://q3.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114448/https://q4.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114448/https://q.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114448/https://img01.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114448/https://img02.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114448/https://img03.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025114448/https://img04.sogoucdn.com/"><link rel="Shortcut Icon" href="https://web.archive.org/web/20221025114448im_/https://www.sogou.com/images/logo/new/favicon.ico?v=4"><link rel="Bookmark" href="https://www.sogou.com/images/logo/new/favicon.ico?v=4"><link href="./577.视频跟踪 - 搜狗科学百科_files/base_b849887.css" rel="stylesheet"><link href="./577.视频跟踪 - 搜狗科学百科_files/detail_378aed5.css" rel="stylesheet"><link href="./577.视频跟踪 - 搜狗科学百科_files/inviteAudit_7894507.css" rel="stylesheet"><link rel="stylesheet" href="./577.视频跟踪 - 搜狗科学百科_files/highlight.min.css"><title>视频跟踪 - 搜狗科学百科</title><style>.onekey-close {
	position: absolute;
	top: 16px;
	right: 16px;
	width: 24px;
	height: 24px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	text-indent: -999em;
	background-size: 84px;
	background-position: -63px 0;
}

.onekey-login {
	position: absolute;
	top: 16.4%;
	left: 0;
	right: 0;
	width: 100%;
}

/* .onekey-login-img {
    width: 75px;
    height: 75px;
    background: url("https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/images/sprite_wap_baike.png") no-repeat;
    background-size: 100px 91px;
    background-position: 0 0;
    background-repeat: no-repeat;
    margin: 0 auto;
} */

.onekey-login-title {
	text-align: center;
	padding-bottom: 3px;
	font-size: 21px;
	font-weight: bold;
	line-height: 30px;
	color: #000;
}

.onekey-login-txt {
	text-align: center;
	font-family: PingFangSC;
	font-size: 14px;
	line-height: 20px;
	color: #8f8f8f;
}

.onekey-login-qq,
.onekey-login-wx,
.onekey-login-phone {
	display: block;
	width: 245px;
	height: 54px;
	border-radius: 45px;
	text-align: center;

	margin: 0 auto;
	font-size: 17px;
	line-height: 24px;
	color: #000;
	/* padding: 16px 77px; */
	border-radius: 12px;
	border: solid 1px #e0e0e0;
}
.onekey-qq-content,
.onekey-vx-content,
.onekey-phone-content {
	display: inline-block;
	margin-top: 16px;
}
.onekey-qq-content {
	padding: 0 5px;
}

.onekey-login-qq {
	margin-top: 48px;
	margin-bottom: 24px;
}

.onekey-login-qq:before {
	display: inline-block;
	content: "";
	width: 20px;
	height: 20px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 80px;
	background-position: -20px 0;
	vertical-align: top;
	margin: 17px 8px 0 0;
}

.onekey-login-wx {
	margin-bottom: 24px;
}

.onekey-login-wx:before {
	display: inline-block;
	content: "";
	width: 21px;
	height: 21px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 84px;
	background-position: 0 0;
	vertical-align: top;
	margin: 17px 10px 0 0;
}

.onekey-login-phone {
}

.onekey-login-phone:before {
	display: inline-block;
	content: "";
	width: 21px;
	height: 21px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 84px;
	background-position: -42px 0;
	vertical-align: top;
	margin: 17px 10px 0 0;
}

.onekey-fixed {
	z-index: 100;
	position: fixed;
	top: 0;
	bottom: 0;
	left: 0;
	right: 0;
	background: #fff;
	width: 100%;
	height: 100%;
}

.onekey-fixed.forbid {
	z-index: 100;
	position: fixed;
	top: auto;
	bottom: 68px;
	left: 9%;
	right: 0;
	background: rgba(0, 0, 0, 0.7);
	width: 82%;
	height: 43px;
	border-radius: 25px;
	color: #ffffff;
}
.onekey-login-title.forbid {
	text-align: center;
	padding-bottom: 3px;
	font-size: 14px;
	font-weight: normal;
	line-height: 30px;
	color: white;
}
</style><style>#login_mask {
  background: #000;
  opacity: 0.5;
  filter: alpha(opacity=50);
  position: fixed;
  /*fixed好像在哪个IE上有BUG，先用用*/
  left: 0;
  top: 0;
  z-index: 999;
  height: 100%;
}

#login_iframe_container {
  position: fixed;
  width: 550px;
  height: 360px;
  z-index: 1020;
  background-color: #ffffff;
}

@media screen and (max-width: 828px) {
  #login_iframe_container {
    top: 50% !important;
    left: 50% !important;
    transform: translate(-50%, -50%);
  }
}

#login_iframe_container.new-login {
  width: 550px;
  height: 360px;
  background-image: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/background_2a4a8a6.png);
}

#login_iframe_container.new-login.no-bg {
  background: #fff;
}

#login_iframe_container.new-login .login-title {
  width: 100%;
  height: 42px;
  line-height: 42px;
  text-align: center;
  font-size: 30px;
  letter-spacing: 0.19px;
  color: #ffffff;
  margin-top: 62px;
}
#login_iframe_container.new-login .forbid-title {
  width: 100%;
  height: 42px;
  line-height: 42px;
  text-align: center;
  font-size: 24px;
  letter-spacing: 0.19px;
  color: #333333;
  margin-top: 150px;
}

#login_iframe_container.new-login.no-bg .login-title {
  color: #333333;
}

#login_iframe_container.new-login .login-subtitle {
  width: 100%;
  height: 18px;
  line-height: 18px;
  font-size: 13px;
  letter-spacing: 0.08px;
  color: #ffffff;
  text-align: center;
  margin-top: 9px;
  margin-bottom: 43px;
}

#login_iframe_container.new-login.no-bg .login-subtitle {
  color: #999999;
}

#login_iframe_container.new-login .login-subtitle::before {
  content: '';
  display: inline-block;
  width: 10px;
  height: 1px;
  background-color: #ffffff;
  position: relative;
  top: -4px;
  left: -5px;
}

#login_iframe_container.new-login .login-subtitle::after {
  content: '';
  display: inline-block;
  width: 10px;
  height: 1px;
  background-color: #ffffff;
  position: relative;
  top: -4px;
  left: 5px;
}

#login_iframe_container.new-login.no-bg .login-subtitle::before {
  background-color: #999999;
}

#login_iframe_container.new-login.no-bg .login-subtitle::after {
  background-color: #999999;
}

#login_iframe_container.new-login .close-btn {
  position: absolute;
  top: 20px;
  right: 20px;
  width: 12px;
  height: 12px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -59px -10px;
  background-size: 81px 91px;
  cursor: pointer;
}

#login_iframe_container.new-login .login-btn {
  width: 220px;
  height: 47px;
  border-radius: 24px;
  border: solid 1px #dddddd;
  background-color: #ffffff;
  margin: 0 auto;
  margin-top: 28px;
  position: relative;
  display: block;
}

#login_iframe_container.new-login .login-btn .login-icon {
  position: absolute;
}

#login_iframe_container.new-login .login-btn .login-text {
  width: 61px;
  height: 47px;
  line-height: 47px;
  vertical-align: middle;
  font-size: 15px;
  letter-spacing: 0.1px;
  color: #666666;
  position: absolute;
  right: 62px;
}

#login_iframe_container.new-login .login-btn.qq-btn .login-icon {
  width: 22px;
  height: 27px;
  top: 10px;
  left: 67px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -10px -54px;
  background-size: 81px 91px;
}

#login_iframe_container.new-login .login-btn.qq-btn .login-text {
  right: 59px;
}

#login_iframe_container.new-login .login-btn.wechat-btn .login-icon {
  width: 29px;
  height: 24px;
  top: 12px;
  left: 62px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -10px -10px;
  background-size: 81px 91px;
}</style><style>/* -- container -- */
.rodal,
.rodal-mask {
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: 100;
}

.rodal {
    position: fixed;
}

/* -- mask -- */
.rodal-mask {
    position: fixed;
    background: rgba(0, 0, 0, .5);
}

/* -- dialog -- */
.rodal-dialog {
    position: absolute;
    z-index: 101;
    background: #fff;
    border-radius: 3px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, .2);
}

.rodal-center {
    top: 50%;
    transform: translateY(-50%);
    left: 0;
    right: 0;
    margin: 0 auto;
}

.rodal-bottom {
    left: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

.rodal-top {
    left: 0;
    right: 0;
    top: 0;
    margin: auto;
}

.rodal-left {
    top: 0;
    left: 0;
    bottom: 0;
    margin: auto;
}

.rodal-right {
    top: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

/* -- close button -- */
.rodal-close {
    position: absolute;
    cursor: pointer;
    top: 16px;
    right: 16px;
    width: 16px;
    height: 16px;
}

.rodal-close:before,
.rodal-close:after {
    position: absolute;
    content: '';
    height: 2px;
    width: 100%;
    top: 50%;
    left: 0;
    margin-top: -1px;
    background: #999;
    border-radius: 100%;
    -webkit-transition: background .2s;
    transition: background .2s;
}

.rodal-close:before {
    -webkit-transform: rotate(45deg);
    transform: rotate(45deg);
}

.rodal-close:after {
    -webkit-transform: rotate(-45deg);
    transform: rotate(-45deg);
}

.rodal-close:hover:before,
.rodal-close:hover:after {
    background: #333;
}

/* -- fade -- */
/* @-webkit-keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

@keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

.rodal-fade-enter {
    -webkit-animation: rodal-fade-enter both ease-in;
    animation: rodal-fade-enter both ease-in;
} */

@-webkit-keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

@keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

.rodal-fade-leave {
    -webkit-animation: rodal-fade-leave both ease-out;
    animation: rodal-fade-leave both ease-out;
}

/* -- zoom -- */
@-webkit-keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-enter {
    -webkit-animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-leave {
    -webkit-animation: rodal-zoom-leave both;
    animation: rodal-zoom-leave both;
}

/* -- slideDown -- */
@-webkit-keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-enter {
    -webkit-animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-leave {
    -webkit-animation: rodal-slideDown-leave both;
    animation: rodal-slideDown-leave both;
}

/* -- slideLeft -- */
@-webkit-keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-enter {
    -webkit-animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-leave {
    -webkit-animation: rodal-slideLeft-leave both;
    animation: rodal-slideLeft-leave both;
}

/* -- slideRight -- */
@-webkit-keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-enter {
    -webkit-animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-leave {
    -webkit-animation: rodal-slideRight-leave both;
    animation: rodal-slideRight-leave both;
}

/* -- slideUp -- */
@-webkit-keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-enter {
    -webkit-animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
    animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
}

@-webkit-keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-leave {
    -webkit-animation: rodal-slideUp-leave both;
    animation: rodal-slideUp-leave both;
}

/* -- flip -- */
@-webkit-keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

@keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

.rodal-flip-enter {
    -webkit-animation: rodal-flip-enter both ease-in;
    animation: rodal-flip-enter both ease-in;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

@-webkit-keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

@keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

.rodal-flip-leave {
    -webkit-animation: rodal-flip-leave both;
    animation: rodal-flip-leave both;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

/* -- rotate -- */
@-webkit-keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-enter {
    -webkit-animation: rodal-rotate-enter both;
    animation: rodal-rotate-enter both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

@-webkit-keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-leave {
    -webkit-animation: rodal-rotate-leave both;
    animation: rodal-rotate-leave both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

/* -- door -- */
@-webkit-keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

@keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

.rodal-door-enter {
    -webkit-animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

@keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

.rodal-door-leave {
    -webkit-animation: rodal-door-leave both;
    animation: rodal-door-leave both;
}</style><style>/* -- container -- */
.rodal,
.rodal-mask {
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: 100;
}

.rodal {
    position: fixed;
}

/* -- mask -- */
.rodal-mask {
    position: fixed;
    background: rgba(0, 0, 0, .5);
}

/* -- dialog -- */
.rodal-dialog {
    position: absolute;
    z-index: 101;
    background: #fff;
    border-radius: 3px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, .2);
}

.rodal-center {
    top: 50%;
    transform: translateY(-50%);
    left: 0;
    right: 0;
    margin: 0 auto;
}

.rodal-bottom {
    left: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

.rodal-top {
    left: 0;
    right: 0;
    top: 0;
    margin: auto;
}

.rodal-left {
    top: 0;
    left: 0;
    bottom: 0;
    margin: auto;
}

.rodal-right {
    top: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

/* -- close button -- */
.rodal-close {
    position: absolute;
    cursor: pointer;
    top: 16px;
    right: 16px;
    width: 16px;
    height: 16px;
}

.rodal-close:before,
.rodal-close:after {
    position: absolute;
    content: '';
    height: 2px;
    width: 100%;
    top: 50%;
    left: 0;
    margin-top: -1px;
    background: #999;
    border-radius: 100%;
    -webkit-transition: background .2s;
    transition: background .2s;
}

.rodal-close:before {
    -webkit-transform: rotate(45deg);
    transform: rotate(45deg);
}

.rodal-close:after {
    -webkit-transform: rotate(-45deg);
    transform: rotate(-45deg);
}

.rodal-close:hover:before,
.rodal-close:hover:after {
    background: #333;
}

/* -- fade -- */
/* @-webkit-keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

@keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

.rodal-fade-enter {
    -webkit-animation: rodal-fade-enter both ease-in;
    animation: rodal-fade-enter both ease-in;
} */

@-webkit-keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

@keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

.rodal-fade-leave {
    -webkit-animation: rodal-fade-leave both ease-out;
    animation: rodal-fade-leave both ease-out;
}

/* -- zoom -- */
@-webkit-keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-enter {
    -webkit-animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-leave {
    -webkit-animation: rodal-zoom-leave both;
    animation: rodal-zoom-leave both;
}

/* -- slideDown -- */
@-webkit-keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-enter {
    -webkit-animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-leave {
    -webkit-animation: rodal-slideDown-leave both;
    animation: rodal-slideDown-leave both;
}

/* -- slideLeft -- */
@-webkit-keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-enter {
    -webkit-animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-leave {
    -webkit-animation: rodal-slideLeft-leave both;
    animation: rodal-slideLeft-leave both;
}

/* -- slideRight -- */
@-webkit-keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-enter {
    -webkit-animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-leave {
    -webkit-animation: rodal-slideRight-leave both;
    animation: rodal-slideRight-leave both;
}

/* -- slideUp -- */
@-webkit-keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-enter {
    -webkit-animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
    animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
}

@-webkit-keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-leave {
    -webkit-animation: rodal-slideUp-leave both;
    animation: rodal-slideUp-leave both;
}

/* -- flip -- */
@-webkit-keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

@keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

.rodal-flip-enter {
    -webkit-animation: rodal-flip-enter both ease-in;
    animation: rodal-flip-enter both ease-in;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

@-webkit-keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

@keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

.rodal-flip-leave {
    -webkit-animation: rodal-flip-leave both;
    animation: rodal-flip-leave both;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

/* -- rotate -- */
@-webkit-keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-enter {
    -webkit-animation: rodal-rotate-enter both;
    animation: rodal-rotate-enter both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

@-webkit-keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-leave {
    -webkit-animation: rodal-rotate-leave both;
    animation: rodal-rotate-leave both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

/* -- door -- */
@-webkit-keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

@keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

.rodal-door-enter {
    -webkit-animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

@keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

.rodal-door-leave {
    -webkit-animation: rodal-door-leave both;
    animation: rodal-door-leave both;
}</style>
<!--百度统计-->
<script>
   var _hmt = _hmt || [];
   (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?3c7614be3026469d5a60f41ab30b5082";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
      })();
</script>
</head>
<body class=""><!-- BEGIN WAYBACK TOOLBAR INSERT -->
<style type="text/css">
body {
  margin-top:0 !important;
  padding-top:0 !important;
  /*min-width:800px !important;*/
}
</style>
<script>__wm.rw(0);</script>
<div id="wm-ipp-base" lang="en" style="display: block; direction: ltr;">
</div><div id="wm-ipp-print">The Wayback Machine - https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/d10577.htm</div>
<script type="text/javascript">//<![CDATA[
__wm.bt(675,27,25,2,"web","https://baike.sogou.com/kexue/d10577.htm","20221025114448",1996,"/_static/",["/_static/css/banner-styles.css?v=S1zqJCYt","/_static/css/iconochive.css?v=qtvMKcIJ"], false);
  __wm.rw(1);
//]]></script>
<!-- END WAYBACK TOOLBAR INSERT --><script>window._gtag=window._gtag||{};window._gtag.shouldGrayed = false;if ('f6e0f74f8286447f85fb41981793405d') window._gtag.traceId = 'f6e0f74f8286447f85fb41981793405d';if ({"illegality":true}) window.userInfo = {"illegality":true};</script><div class="topnavbox"><ul class="topnav"><li><a href="https://web.archive.org/web/20221025114448/https://www.sogou.com/web?query=">网页</a></li><li><a href="https://web.archive.org/web/20221025114448/https://weixin.sogou.com/weixin?p=75351201">微信</a></li><li><a href="https://web.archive.org/web/20221025114448/https://zhihu.sogou.com/zhihu?p=75351218">知乎</a></li><li><a href="https://web.archive.org/web/20221025114448/https://pic.sogou.com/pics?query=">图片</a></li><li><a href="https://web.archive.org/web/20221025114448/https://v.sogou.com/v?query=">视频</a></li><li><a href="https://web.archive.org/web/20221025114448/https://mingyi.sogou.com/">医疗</a></li><li class="cur"><strong>科学</strong></li><li><a href="https://web.archive.org/web/20221025114448/https://hanyu.sogou.com/">汉语</a></li><li><a href="https://web.archive.org/web/20221025114448/https://wenwen.sogou.com/">问问</a></li><li><a href="https://web.archive.org/web/20221025114448/https://www.sogou.com/docs/more.htm">更多<span class="topraquo">»</span></a></li></ul></div><div id="header"><div class="header-wrap"><a class="header-logo" href="https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue"></a><div class="header-search"><div class="querybox" id="suggBox"><form><input id="searchInput" class="query" type="text" placeholder="搜科学领域专业百科词条" name="query" autocomplete="off" value=""><a href="javascript:;" class="query-search"></a></form></div></div><div class="header-rgt"><span class="btn-header-rgt btn-edit" id="editLemma">创建</span><div class="header-user no-login"></div></div></div></div><div class="fixed-placeholder" style="visibility:none"></div><div id="container" class=""><div class="content lemma-level1"><div class="detail-title" id="abstract-title"><h1>视频跟踪</h1><a href="https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/d10577.htm#!" class="detail-edit">编辑</a></div><div class="section_content" data-id="14995413115339012"><div><p><b>视频跟踪</b>是使用摄像机随时间定位移动物体(或多个物体)的过程。它有多种用途，包括有：人机交互、安保和监控、视频通信和压缩、增强现实、交通控制、医学成像<sup><a href="https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/d10577.htm#quote_1" class="kx_ref">[1]</a></sup>和视频编辑<sup><a href="https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/d10577.htm#quote_2" class="kx_ref">[2]</a></sup><sup><a href="https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/d10577.htm#quote_3" class="kx_ref">[3]</a></sup>。由于视频中包含大量数据，视频跟踪可能会是一个相当耗时的过程。更复杂的是可能需要使用目标识别技术以实现跟踪，这本身就是一个具有挑战性的问题。 </p></div></div><div id="catalog"><h2 class="title2">目录<a href="javascript:" class="detail-edit">编辑</a></h2><div class="catalog_wrap" style=""><ul class="catalog_list col1"><li><span class="order">1</span><a href="javascript:" data-level="1" data-id="14995413115339013">目标</a></li><li><span class="order">2</span><a href="javascript:" data-level="1" data-id="14995413132116236">算法</a></li><li><span class="order">3</span><a href="javascript:" data-level="1" data-id="references">参考文献</a></li></ul></div></div><div id="paragraphs"><div><div id="par_14995413115339013"><h2 class="title">1 目标<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p></p><p></p><div class="text_img ed_imgfloat_right">
            <a class="ed_image_link lazyLoad" data-src="https://img04.sogoucdn.com/app/a/200698/sogou_science_13165" data-bigsrc="" title="点击查看大图" href="javascript:" data-observer="true" data-loaded="true" style="background-image: url(&quot;https://web.archive.org/web/20221025114448/https://img04.sogoucdn.com/app/a/200698/sogou_science_13165&quot;);"></a>
            <div class="text_img_title">机器人手通过视觉反馈跟踪接球的视觉伺服示例，该视觉反馈由高速图像处理系统处理。[1][2]</div>   
        </div> <p></p><p></p> 
<p>视频跟踪的目标是将连续视频帧中的目标物体相关联。当物体相对于帧速率快速移动时，这种关联可能会特别困难。另一种情况是当被跟踪物体的方向随时间改变时，问题的复杂性会增加。对于这种情况，视频跟踪系统通常采用运动模型，以描述目标图像随着物体的不同可能运动会如何变化。 </p>
<p>简单运动模型有: </p> 
<ul>
 <li>当跟踪平面物体时，运动模型是物体图像(例如初始帧)的2D变换(仿射变换或单应性变换)。</li> 
 <li>当目标是刚性3D对象时，运动模型根据其3D位置和方向定义其方位。</li> 
 <li>对于视频压缩，关键帧被分成宏块。运动模型是关键帧的一种分解，其中每个宏块由运动参数给出的运动矢量转换得到。</li> 
 <li>可变形物体的图像可以用网格覆盖，物体的运动由网格节点的位置来定义。</li>
</ul></div></div><div id="par_14995413132116236"><h2 class="title">2 算法<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>为了实现视频跟踪，算法分析连续的视频帧，并输出不同帧之间物体的移动。目前存在各种各样的算法，各有优缺点。选择使用哪种算法时，考虑预期用途很重要。视觉跟踪系统有两个主要组成部分:目标表示和定位以及过滤和数据关联。 </p>
<p><i>目标表示和定位</i>主要是一个自下而上的过程。其提供了多种识别运动物体的工具。能否成功定位和跟踪目标取决于算法。例如，使用斑点跟踪对于识别人类运动是适用的，因为人的轮廓是动态变化的。<sup><a href="https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/d10577.htm#quote_6" class="kx_ref">[6]</a></sup> 通常来说这些算法的计算复杂度很低。以下是一些常见的<i>目标表示和定位</i>算法: </p> 
<ul>
 <li><b>基于内核跟踪</b>(均值漂移跟踪<sup><a href="https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/d10577.htm#quote_7" class="kx_ref">[7]</a></sup>): &nbsp;基于相似性度量(巴特查亚系数)最大化的迭代定位过程。</li> 
 <li><b>轮廓跟踪</b>:物体边界检测(如活动轮廓或凝聚算法)。轮廓跟踪方法通过迭代将初始轮廓从前一帧转化到到当前帧中的新位置。这种方法通过使用梯度下降以最小化轮廓能量来直接推理轮廓。</li>
</ul> 
<p><i>过滤和数据关联</i>主要是一个自上而下的过程，其整合场景或物体的先验信息、处理物体运动以及评估不同的假设。这些方法适用于跟踪具有复杂物体交互的复杂物体，例如跟踪于障碍物后面移动的物体。<sup><a href="https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/d10577.htm#quote_8" class="kx_ref">[8]</a></sup> 此外，如果视频跟踪器(也称为TV跟踪器或目标跟踪器)非固联安装，而是安装在移动的平台上，人们通常会使用惯性测量系统来预稳定视频跟踪器，以减少相机系统所需的动态和带宽，这种情况下算法复杂性会增加。<sup><a href="https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/d10577.htm#quote_9" class="kx_ref">[9]</a></sup>过滤和数据关联算法的计算复杂度通常要高得多。以下是一些常见的过滤算法: </p> 
<ul>
 <li>卡尔曼滤波:高斯噪声下线性函数的最优递归贝叶斯滤波。其使用一系列随时间观察到的测量值，包含噪声(随机变化)和其他不准确性，并输出未知变量的估计值，这些估计值往往比仅基于单个测量值的估计值更精确。<sup><a href="https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/d10577.htm#quote_10" class="kx_ref">[10]</a></sup></li> 
 <li>粒子滤波器:用于对非线性和非高斯过程的基本状态空间分布进行采样。<sup><a href="https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/d10577.htm#quote_11" class="kx_ref">[11]</a></sup><sup><a href="https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/d10577.htm#quote_12" class="kx_ref">[12]</a></sup><sup><a href="https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/d10577.htm#quote_13" class="kx_ref">[13]</a></sup></li>
</ul></div></div></div></div><div id="references"><h2 class="title" id="par_references">参考文献</h2><ul class="references"><li id="quote_1"><span class="references-num">[1]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Peter Mountney, Danail Stoyanov &amp; Guang-Zhong Yang (2010). "Three-Dimensional Tissue Deformation Recovery and Tracking: Introducing techniques based on laparoscopic or endoscopic images." IEEE Signal Processing Magazine. 2010 July. Volume: 27". IEEE Signal Processing Magazine. 27 (4): 14–24. doi:10.1109/MSP.2010.936728..</span></p></li><li id="quote_2"><span class="references-num">[2]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Lyudmila Mihaylova, Paul Brasnett, Nishan Canagarajan and David Bull (2007). Object Tracking by Particle Filtering Techniques in Video Sequences; In: Advances and Challenges in Multisensor Data and Information. NATO Security Through Science Series, 8. Netherlands: IOS Press. pp. 260–268. CiteSeerX 10.1.1.60.8510. ISBN 978-1-58603-727-7.CS1 maint: Multiple names: authors list (link).</span></p></li><li id="quote_3"><span class="references-num">[3]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Kato, Hirokazu &amp; Mark Billinghurst (1999). "Marker Tracking and HMD Calibration for a Video-based Augmented Reality Conferencing System" (PDF). IWAR '99 Proceedings of the 2nd IEEE and ACM International Workshop on Augmented Reality. IEEE Computer Society, Washington, DC, USA..</span></p></li><li id="quote_4"><span class="references-num">[4]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"High-speed Catching System (exhibited in National Museum of Emerging Science and Innovation since 2005)". Ishikawa Watanabe Laboratory, University of Tokyo. Retrieved 12 February 2015..</span></p></li><li id="quote_5"><span class="references-num">[5]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Basic Concept and Technical Terms". Ishikawa Watanabe Laboratory, University of Tokyo. Retrieved 12 February 2015..</span></p></li><li id="quote_6"><span class="references-num">[6]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">S. Kang; J. Paik; A. Koschan; B. Abidi &amp; M. A. Abidi (2003). "Real-time video tracking using PTZ cameras". Proc. SPIE. 5132: 103–111. CiteSeerX 10.1.1.101.4242. doi:10.1117/12.514945..</span></p></li><li id="quote_7"><span class="references-num">[7]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Comaniciu, D.; Ramesh, V.; Meer, P., "Real-time tracking of non-rigid objects using mean shift," Computer Vision and Pattern Recognition, 2000. Proceedings. IEEE Conference on , vol.2, no., pp.142,149 vol.2, 2000.</span></p></li><li id="quote_8"><span class="references-num">[8]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Black, James, Tim Ellis, and Paul Rosin (2003). "A Novel Method for Video Tracking Performance Evaluation". Joint IEEE Int. Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance: 125–132. CiteSeerX 10.1.1.10.3365.CS1 maint: Multiple names: authors list (link).</span></p></li><li id="quote_9"><span class="references-num">[9]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Gyro Stabilized Target Tracker for Off-shore Installation.</span></p></li><li id="quote_10"><span class="references-num">[10]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">M. Arulampalam; S. Maskell; N. Gordon &amp; T. Clapp (2002). "A Tutorial on Particle Filters for Online Nonlinear/Non-Gaussian Bayesian Tracking". IEEE Transactions on Signal Processing. 50 (2): 174. CiteSeerX 10.1.1.117.1144. doi:10.1109/78.978374..</span></p></li><li id="quote_11"><span class="references-num">[11]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Emilio Maggio; Andrea Cavallaro (2010). Video Tracking: Theory and Practice. 1. Video Tracking provides a comprehensive treatment of the fundamental aspects of algorithm and application development for the task of estimating, over time..</span></p></li><li id="quote_12"><span class="references-num">[12]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Karthik Chandrasekaran (2010). Parametric &amp; Non-parametric Background Subtraction Model with Object Tracking for VENUS. 1. Background subtraction is the process by which we segment moving regions in image sequences..</span></p></li><li id="quote_13"><span class="references-num">[13]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">J. Martinez-del-Rincon, D. Makris, C. Orrite-Urunuela and J.-C. Nebel (2010). "Tracking Human Position and Lower Body Parts Using Kalman and Particle Filters Constrained by Human Biomechanics". IEEE Transactions on Systems Man and Cybernetics – Part B', 40(4)..</span></p></li></ul></div><div class="read-num">阅读 <!-- -->569</div></div><div class="right-side" id="rightSide"><div class="side" id="lemma-side"><div class="side-title">版本记录</div><ul class="side-lst"><li><p class="side-lst-txt">暂无</p></li></ul><div class="user-card userCard"></div></div><div class="side"><div class="side-event"></div></div></div></div><div class="footer-box"><div id="footer"><div class="footer-logo-wrap"><div class="footer-logo"></div><div class="footer-logo-text">知识·传播·科普</div></div><div class="footer-info">本网站内容采用<a target="_blank" href="https://web.archive.org/web/20221025114448/https://creativecommons.org/licenses/by-sa/3.0/deed.zh?tdsourcetag=s_pctim_aiomsg">CC-BY-SA 3.0</a>授权</div><div class="footer-btn-wrap"><a target="_blank" href="https://web.archive.org/web/20221025114448/https://baike.sogou.com/help/#user_protocol">用户协议</a><a target="_blank" href="https://web.archive.org/web/20221025114448/http://www.sogou.com/docs/terms.htm?v=1">免责声明</a><a target="_blank" href="https://web.archive.org/web/20221025114448/http://corp.sogou.com/private.html">隐私政策</a><a target="_blank" href="https://web.archive.org/web/20221025114448/https://baike.sogou.com/kexue/intro.htm">关于我们</a></div></div></div><script>window.lemmaInfo ={"lemmaId":"10577","versionId":"14995413115339008","title":"视频跟踪","subtitle":"","abstracts":{"paragraphId":"14995413115339012","title":"简介","versionId":"14995413115339009","lemmaId":10577,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":31221062,"name":"张志煌","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233962,"comment":null,"dependVersionId":0,"contentType":2,"content":"<p><b>视频跟踪</b>是使用摄像机随时间定位移动物体(或多个物体)的过程。它有多种用途，包括有：人机交互、安保和监控、视频通信和压缩、增强现实、交通控制、医学成像<sup><a href=\"#quote_1\" class=\"kx_ref\">[1]</a></sup>和视频编辑<sup><a href=\"#quote_2\" class=\"kx_ref\">[2]</a></sup><sup><a href=\"#quote_3\" class=\"kx_ref\">[3]</a></sup>。由于视频中包含大量数据，视频跟踪可能会是一个相当耗时的过程。更复杂的是可能需要使用目标识别技术以实现跟踪，这本身就是一个具有挑战性的问题。 </p>","pics":null,"card":null,"references":[],"versionCount":0},"card":{"paragraphId":"0","title":null,"versionId":"0","lemmaId":0,"createType":0,"creator":null,"createTime":0,"versionEditor":null,"editTime":0,"comment":null,"dependVersionId":0,"contentType":0,"content":null,"pics":null,"card":null,"references":null,"versionCount":0},"categories":[{"id":6,"name":"机械工程","parents":[]}],"creator":{"uid":31221062,"name":"张志煌","pic":"https://web.archive.org/web/20221025114448/https://cache.soso.com/qlogo/g?b=oidb&k=yI5YsiaWJ2vMgkUriabwpoPQ&s=100&t=1555539303","introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":"","jobBrief":"","role":0,"roleName":null,"title":"","professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":151,"partnerIdCreateTime":1595844883,"partnerIdPoped":false},"createTime":1568626425,"editor":{"uid":31221062,"name":"张志煌","pic":"https://web.archive.org/web/20221025114448/https://cache.soso.com/qlogo/g?b=oidb&k=yI5YsiaWJ2vMgkUriabwpoPQ&s=100&t=1555539303","introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":"","jobBrief":"","role":0,"roleName":null,"title":"","professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":151,"partnerIdCreateTime":1595844883,"partnerIdPoped":false},"editTime":1576233962,"state":1,"versionCount":1,"upNum":6,"downNum":0,"pics":[{"originalUrl":"https://web.archive.org/web/20221025114448/https://img04.sogoucdn.com/app/a/200698/sogou_science_13165?w=300&h=169&titlename=%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E9%80%9A%E8%BF%87%E8%A7%86%E8%A7%89%E5%8F%8D%E9%A6%88%E8%B7%9F%E8%B8%AA%E6%8E%A5%E7%90%83%E7%9A%84%E8%A7%86%E8%A7%89%E4%BC%BA%E6%9C%8D%E7%A4%BA%E4%BE%8B%EF%BC%8C%E8%AF%A5%E8%A7%86%E8%A7%89%E5%8F%8D%E9%A6%88%E7%94%B1%E9%AB%98%E9%80%9F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%B3%BB%E7%BB%9F%E5%A4%84%E7%90%86%E3%80%82%5B1%5D%5B2%5D","url":"https://web.archive.org/web/20221025114448/https://img04.sogoucdn.com/app/a/200698/sogou_science_13165","rw":300,"rh":169,"title":"机器人手通过视觉反馈跟踪接球的视觉伺服示例，该视觉反馈由高速图像处理系统处理。[1][2]","alt":null,"width":0,"height":0}],"catalogs":[{"level":1,"title":"目标","paragraphId":"14995413115339013","subCatalogs":null},{"level":1,"title":"算法","paragraphId":"14995413132116236","subCatalogs":null},{"level":1,"title":"参考文献","paragraphId":"-1","subCatalogs":null}],"paragraphs":[{"paragraphId":"14995413115339013","title":"目标","versionId":"14995413115339010","lemmaId":10577,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":31221062,"name":"张志煌","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233962,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p></p><p><img class=\"videoimg kx_img ed_imgfloat_right\" img_height=\"169\" img_width=\"300\" titlename=\"机器人手通过视觉反馈跟踪接球的视觉伺服示例，该视觉反馈由高速图像处理系统处理。[1][2]\" data-src=\"https://img04.sogoucdn.com/app/a/200698/sogou_science_13165\"> </p><p></p> \n<p>视频跟踪的目标是将连续视频帧中的目标物体相关联。当物体相对于帧速率快速移动时，这种关联可能会特别困难。另一种情况是当被跟踪物体的方向随时间改变时，问题的复杂性会增加。对于这种情况，视频跟踪系统通常采用运动模型，以描述目标图像随着物体的不同可能运动会如何变化。 </p>\n<p>简单运动模型有: </p> \n<ul>\n <li>当跟踪平面物体时，运动模型是物体图像(例如初始帧)的2D变换(仿射变换或单应性变换)。</li> \n <li>当目标是刚性3D对象时，运动模型根据其3D位置和方向定义其方位。</li> \n <li>对于视频压缩，关键帧被分成宏块。运动模型是关键帧的一种分解，其中每个宏块由运动参数给出的运动矢量转换得到。</li> \n <li>可变形物体的图像可以用网格覆盖，物体的运动由网格节点的位置来定义。</li>\n</ul>","pics":[{"originalUrl":"https://web.archive.org/web/20221025114448/https://img04.sogoucdn.com/app/a/200698/sogou_science_13165?w=300&h=169&titlename=%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E9%80%9A%E8%BF%87%E8%A7%86%E8%A7%89%E5%8F%8D%E9%A6%88%E8%B7%9F%E8%B8%AA%E6%8E%A5%E7%90%83%E7%9A%84%E8%A7%86%E8%A7%89%E4%BC%BA%E6%9C%8D%E7%A4%BA%E4%BE%8B%EF%BC%8C%E8%AF%A5%E8%A7%86%E8%A7%89%E5%8F%8D%E9%A6%88%E7%94%B1%E9%AB%98%E9%80%9F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%B3%BB%E7%BB%9F%E5%A4%84%E7%90%86%E3%80%82%5B1%5D%5B2%5D","url":"https://web.archive.org/web/20221025114448/https://img04.sogoucdn.com/app/a/200698/sogou_science_13165","rw":300,"rh":169,"title":"机器人手通过视觉反馈跟踪接球的视觉伺服示例，该视觉反馈由高速图像处理系统处理。[1][2]","alt":null,"width":0,"height":0}],"card":null,"references":[],"versionCount":0},{"paragraphId":"14995413132116236","title":"算法","versionId":"14995413115339011","lemmaId":10577,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":31221062,"name":"张志煌","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233962,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>为了实现视频跟踪，算法分析连续的视频帧，并输出不同帧之间物体的移动。目前存在各种各样的算法，各有优缺点。选择使用哪种算法时，考虑预期用途很重要。视觉跟踪系统有两个主要组成部分:目标表示和定位以及过滤和数据关联。 </p>\n<p><i>目标表示和定位</i>主要是一个自下而上的过程。其提供了多种识别运动物体的工具。能否成功定位和跟踪目标取决于算法。例如，使用斑点跟踪对于识别人类运动是适用的，因为人的轮廓是动态变化的。<sup><a href=\"#quote_6\" class=\"kx_ref\">[6]</a></sup> 通常来说这些算法的计算复杂度很低。以下是一些常见的<i>目标表示和定位</i>算法: </p> \n<ul>\n <li><b>基于内核跟踪</b>(均值漂移跟踪<sup><a href=\"#quote_7\" class=\"kx_ref\">[7]</a></sup>):  基于相似性度量(巴特查亚系数)最大化的迭代定位过程。</li> \n <li><b>轮廓跟踪</b>:物体边界检测(如活动轮廓或凝聚算法)。轮廓跟踪方法通过迭代将初始轮廓从前一帧转化到到当前帧中的新位置。这种方法通过使用梯度下降以最小化轮廓能量来直接推理轮廓。</li>\n</ul> \n<p><i>过滤和数据关联</i>主要是一个自上而下的过程，其整合场景或物体的先验信息、处理物体运动以及评估不同的假设。这些方法适用于跟踪具有复杂物体交互的复杂物体，例如跟踪于障碍物后面移动的物体。<sup><a href=\"#quote_8\" class=\"kx_ref\">[8]</a></sup> 此外，如果视频跟踪器(也称为TV跟踪器或目标跟踪器)非固联安装，而是安装在移动的平台上，人们通常会使用惯性测量系统来预稳定视频跟踪器，以减少相机系统所需的动态和带宽，这种情况下算法复杂性会增加。<sup><a href=\"#quote_9\" class=\"kx_ref\">[9]</a></sup>过滤和数据关联算法的计算复杂度通常要高得多。以下是一些常见的过滤算法: </p> \n<ul>\n <li>卡尔曼滤波:高斯噪声下线性函数的最优递归贝叶斯滤波。其使用一系列随时间观察到的测量值，包含噪声(随机变化)和其他不准确性，并输出未知变量的估计值，这些估计值往往比仅基于单个测量值的估计值更精确。<sup><a href=\"#quote_10\" class=\"kx_ref\">[10]</a></sup></li> \n <li>粒子滤波器:用于对非线性和非高斯过程的基本状态空间分布进行采样。<sup><a href=\"#quote_11\" class=\"kx_ref\">[11]</a></sup><sup><a href=\"#quote_12\" class=\"kx_ref\">[12]</a></sup><sup><a href=\"#quote_13\" class=\"kx_ref\">[13]</a></sup></li>\n</ul>","pics":null,"card":null,"references":[],"versionCount":0}],"references":[{"id":1,"type":"book","title":"Peter Mountney, Danail Stoyanov & Guang-Zhong Yang (2010). \"Three-Dimensional Tissue Deformation Recovery and Tracking: Introducing techniques based on laparoscopic or endoscopic images.\" IEEE Signal Processing Magazine. 2010 July. Volume: 27\". IEEE Signal Processing Magazine. 27 (4): 14–24. doi:10.1109/MSP.2010.936728.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":2,"type":"book","title":"Lyudmila Mihaylova, Paul Brasnett, Nishan Canagarajan and David Bull (2007). Object Tracking by Particle Filtering Techniques in Video Sequences; In: Advances and Challenges in Multisensor Data and Information. NATO Security Through Science Series, 8. Netherlands: IOS Press. pp. 260–268. CiteSeerX 10.1.1.60.8510. ISBN 978-1-58603-727-7.CS1 maint: Multiple names: authors list (link)","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":3,"type":"book","title":"Kato, Hirokazu & Mark Billinghurst (1999). \"Marker Tracking and HMD Calibration for a Video-based Augmented Reality Conferencing System\" (PDF). IWAR '99 Proceedings of the 2nd IEEE and ACM International Workshop on Augmented Reality. IEEE Computer Society, Washington, DC, USA.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":4,"type":"book","title":"\"High-speed Catching System (exhibited in National Museum of Emerging Science and Innovation since 2005)\". Ishikawa Watanabe Laboratory, University of Tokyo. Retrieved 12 February 2015.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":5,"type":"book","title":"\"Basic Concept and Technical Terms\". Ishikawa Watanabe Laboratory, University of Tokyo. Retrieved 12 February 2015.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":6,"type":"book","title":"S. Kang; J. Paik; A. Koschan; B. Abidi & M. A. Abidi (2003). \"Real-time video tracking using PTZ cameras\". Proc. SPIE. 5132: 103–111. CiteSeerX 10.1.1.101.4242. doi:10.1117/12.514945.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":7,"type":"book","title":"Comaniciu, D.; Ramesh, V.; Meer, P., \"Real-time tracking of non-rigid objects using mean shift,\" Computer Vision and Pattern Recognition, 2000. Proceedings. IEEE Conference on , vol.2, no., pp.142,149 vol.2, 2000","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":8,"type":"book","title":"Black, James, Tim Ellis, and Paul Rosin (2003). \"A Novel Method for Video Tracking Performance Evaluation\". Joint IEEE Int. Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance: 125–132. CiteSeerX 10.1.1.10.3365.CS1 maint: Multiple names: authors list (link)","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":9,"type":"book","title":"Gyro Stabilized Target Tracker for Off-shore Installation","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":10,"type":"book","title":"M. Arulampalam; S. Maskell; N. Gordon & T. Clapp (2002). \"A Tutorial on Particle Filters for Online Nonlinear/Non-Gaussian Bayesian Tracking\". IEEE Transactions on Signal Processing. 50 (2): 174. CiteSeerX 10.1.1.117.1144. doi:10.1109/78.978374.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":11,"type":"book","title":"Emilio Maggio; Andrea Cavallaro (2010). Video Tracking: Theory and Practice. 1. Video Tracking provides a comprehensive treatment of the fundamental aspects of algorithm and application development for the task of estimating, over time.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":12,"type":"book","title":"Karthik Chandrasekaran (2010). Parametric & Non-parametric Background Subtraction Model with Object Tracking for VENUS. 1. Background subtraction is the process by which we segment moving regions in image sequences.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":13,"type":"book","title":"J. Martinez-del-Rincon, D. Makris, C. Orrite-Urunuela and J.-C. Nebel (2010). \"Tracking Human Position and Lower Body Parts Using Kalman and Particle Filters Constrained by Human Biomechanics\". IEEE Transactions on Systems Man and Cybernetics – Part B', 40(4).","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false}],"recommendReferences":null,"auditState":2,"lemmaLevel":1,"origin":0,"originEnTitle":null,"originZhTitle":null,"pv":569,"auditType":0,"synonyms":null,"showEditTime":"2019.12.13 18:46","auditors":[{"uid":0,"name":"Ki.κe","pic":"https://web.archive.org/web/20221025114448/https://wx.qlogo.cn/mmopen/vi_32/y67kfr32Doib4wg71Jiau7jVWvharic3nRKgdRRQSl6koeQJCo0GQs2Krw0vwdFRsOWnHIQOwAZsSg5lIkIrFCOcQ/132","introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":"","jobBrief":"","role":0,"roleName":null,"title":"","professionalTitle":null,"phoneNo":null,"editable":true,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false}],"hasZhishiNav":false,"auditInfos":{},"isHistory":false};</script><script crossorigin="anonymous" src="./577.视频跟踪 - 搜狗科学百科_files/aegis.min.js.download"></script><script crossorigin="anonymous" src="./577.视频跟踪 - 搜狗科学百科_files/main_2020092401.js.download"></script><script crossorigin="anonymous" src="./577.视频跟踪 - 搜狗科学百科_files/react.production.min.js.download"></script><script crossorigin="anonymous" src="./577.视频跟踪 - 搜狗科学百科_files/react-dom.production.min.js.download"></script><script crossorigin="anonymous" src="./577.视频跟踪 - 搜狗科学百科_files/jquery-1.11.1.min.js.download"></script><script crossorigin="anonymous" src="./577.视频跟踪 - 搜狗科学百科_files/main_2022062701.js.download"></script><script crossorigin="anonymous" src="./577.视频跟踪 - 搜狗科学百科_files/main_66bbe21.js.download"></script><script crossorigin="anonymous" src="./577.视频跟踪 - 搜狗科学百科_files/react.production.min.js.download"></script><script crossorigin="anonymous" src="./577.视频跟踪 - 搜狗科学百科_files/react-dom.production.min.js.download"></script><script crossorigin="anonymous" src="./577.视频跟踪 - 搜狗科学百科_files/main_edf0f08.js.download"></script>
</body></html>