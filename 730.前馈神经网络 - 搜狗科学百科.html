<!DOCTYPE html>
<!-- saved from url=(0083)https://web.archive.org/web/20221025120000/https://baike.sogou.com/kexue/d10730.htm -->
<html class="" data-reactroot=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script src="./730.前馈神经网络 - 搜狗科学百科_files/analytics.js.download" type="text/javascript"></script>
<script type="text/javascript">window.addEventListener('DOMContentLoaded',function(){var v=archive_analytics.values;v.service='wb';v.server_name='wwwb-app227.us.archive.org';v.server_ms=314;archive_analytics.send_pageview({});});</script>
<script type="text/javascript" src="./730.前馈神经网络 - 搜狗科学百科_files/bundle-playback.js.download" charset="utf-8"></script>
<script type="text/javascript" src="./730.前馈神经网络 - 搜狗科学百科_files/wombat.js.download" charset="utf-8"></script>
<script type="text/javascript">
  __wm.init("https://web.archive.org/web");
  __wm.wombat("https://baike.sogou.com/kexue/d10730.htm","20221025120000","https://web.archive.org/","web","/_static/",
	      "1666699200");
</script>
<link rel="stylesheet" type="text/css" href="./730.前馈神经网络 - 搜狗科学百科_files/banner-styles.css">
<link rel="stylesheet" type="text/css" href="./730.前馈神经网络 - 搜狗科学百科_files/iconochive.css">
<!-- End Wayback Rewrite JS Include -->
<meta name="save" content="history"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="baidu-site-verification" content="VWGb6TyYx8"><meta content="前馈神经网络 - 搜狗科学百科" name="keywords"><meta content="搜狗科学百科是一部有着平等、协作、分享、自由理念的网络科学全书，为每一个互联网用户创造一个涵盖所有领域知识、服务的中文知识性平台。" name="description"><meta http-equiv="x-dns-prefetch-control" content="on"><meta name="server" baike="235" ip="210" env="online"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025120000/https://cache.soso.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025120000/https://hhy.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025120000/https://pic.baike.soso.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025120000/https://ugc.qpic.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025120000/https://xui.ptlogin2.qq.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025120000/https://q1.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025120000/https://q2.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025120000/https://q3.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025120000/https://q4.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025120000/https://q.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025120000/https://img01.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025120000/https://img02.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025120000/https://img03.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025120000/https://img04.sogoucdn.com/"><link rel="Shortcut Icon" href="https://web.archive.org/web/20221025120000im_/https://www.sogou.com/images/logo/new/favicon.ico?v=4"><link rel="Bookmark" href="https://www.sogou.com/images/logo/new/favicon.ico?v=4"><link href="./730.前馈神经网络 - 搜狗科学百科_files/base_b849887.css" rel="stylesheet"><link href="./730.前馈神经网络 - 搜狗科学百科_files/detail_378aed5.css" rel="stylesheet"><link href="./730.前馈神经网络 - 搜狗科学百科_files/inviteAudit_7894507.css" rel="stylesheet"><link rel="stylesheet" href="./730.前馈神经网络 - 搜狗科学百科_files/highlight.min.css"><title>前馈神经网络 - 搜狗科学百科</title><style>.onekey-close {
	position: absolute;
	top: 16px;
	right: 16px;
	width: 24px;
	height: 24px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	text-indent: -999em;
	background-size: 84px;
	background-position: -63px 0;
}

.onekey-login {
	position: absolute;
	top: 16.4%;
	left: 0;
	right: 0;
	width: 100%;
}

/* .onekey-login-img {
    width: 75px;
    height: 75px;
    background: url("https://web.archive.org/web/20221025120000/https://baike.sogou.com/kexue/images/sprite_wap_baike.png") no-repeat;
    background-size: 100px 91px;
    background-position: 0 0;
    background-repeat: no-repeat;
    margin: 0 auto;
} */

.onekey-login-title {
	text-align: center;
	padding-bottom: 3px;
	font-size: 21px;
	font-weight: bold;
	line-height: 30px;
	color: #000;
}

.onekey-login-txt {
	text-align: center;
	font-family: PingFangSC;
	font-size: 14px;
	line-height: 20px;
	color: #8f8f8f;
}

.onekey-login-qq,
.onekey-login-wx,
.onekey-login-phone {
	display: block;
	width: 245px;
	height: 54px;
	border-radius: 45px;
	text-align: center;

	margin: 0 auto;
	font-size: 17px;
	line-height: 24px;
	color: #000;
	/* padding: 16px 77px; */
	border-radius: 12px;
	border: solid 1px #e0e0e0;
}
.onekey-qq-content,
.onekey-vx-content,
.onekey-phone-content {
	display: inline-block;
	margin-top: 16px;
}
.onekey-qq-content {
	padding: 0 5px;
}

.onekey-login-qq {
	margin-top: 48px;
	margin-bottom: 24px;
}

.onekey-login-qq:before {
	display: inline-block;
	content: "";
	width: 20px;
	height: 20px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 80px;
	background-position: -20px 0;
	vertical-align: top;
	margin: 17px 8px 0 0;
}

.onekey-login-wx {
	margin-bottom: 24px;
}

.onekey-login-wx:before {
	display: inline-block;
	content: "";
	width: 21px;
	height: 21px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 84px;
	background-position: 0 0;
	vertical-align: top;
	margin: 17px 10px 0 0;
}

.onekey-login-phone {
}

.onekey-login-phone:before {
	display: inline-block;
	content: "";
	width: 21px;
	height: 21px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 84px;
	background-position: -42px 0;
	vertical-align: top;
	margin: 17px 10px 0 0;
}

.onekey-fixed {
	z-index: 100;
	position: fixed;
	top: 0;
	bottom: 0;
	left: 0;
	right: 0;
	background: #fff;
	width: 100%;
	height: 100%;
}

.onekey-fixed.forbid {
	z-index: 100;
	position: fixed;
	top: auto;
	bottom: 68px;
	left: 9%;
	right: 0;
	background: rgba(0, 0, 0, 0.7);
	width: 82%;
	height: 43px;
	border-radius: 25px;
	color: #ffffff;
}
.onekey-login-title.forbid {
	text-align: center;
	padding-bottom: 3px;
	font-size: 14px;
	font-weight: normal;
	line-height: 30px;
	color: white;
}
</style><style>#login_mask {
  background: #000;
  opacity: 0.5;
  filter: alpha(opacity=50);
  position: fixed;
  /*fixed好像在哪个IE上有BUG，先用用*/
  left: 0;
  top: 0;
  z-index: 999;
  height: 100%;
}

#login_iframe_container {
  position: fixed;
  width: 550px;
  height: 360px;
  z-index: 1020;
  background-color: #ffffff;
}

@media screen and (max-width: 828px) {
  #login_iframe_container {
    top: 50% !important;
    left: 50% !important;
    transform: translate(-50%, -50%);
  }
}

#login_iframe_container.new-login {
  width: 550px;
  height: 360px;
  background-image: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/background_2a4a8a6.png);
}

#login_iframe_container.new-login.no-bg {
  background: #fff;
}

#login_iframe_container.new-login .login-title {
  width: 100%;
  height: 42px;
  line-height: 42px;
  text-align: center;
  font-size: 30px;
  letter-spacing: 0.19px;
  color: #ffffff;
  margin-top: 62px;
}
#login_iframe_container.new-login .forbid-title {
  width: 100%;
  height: 42px;
  line-height: 42px;
  text-align: center;
  font-size: 24px;
  letter-spacing: 0.19px;
  color: #333333;
  margin-top: 150px;
}

#login_iframe_container.new-login.no-bg .login-title {
  color: #333333;
}

#login_iframe_container.new-login .login-subtitle {
  width: 100%;
  height: 18px;
  line-height: 18px;
  font-size: 13px;
  letter-spacing: 0.08px;
  color: #ffffff;
  text-align: center;
  margin-top: 9px;
  margin-bottom: 43px;
}

#login_iframe_container.new-login.no-bg .login-subtitle {
  color: #999999;
}

#login_iframe_container.new-login .login-subtitle::before {
  content: '';
  display: inline-block;
  width: 10px;
  height: 1px;
  background-color: #ffffff;
  position: relative;
  top: -4px;
  left: -5px;
}

#login_iframe_container.new-login .login-subtitle::after {
  content: '';
  display: inline-block;
  width: 10px;
  height: 1px;
  background-color: #ffffff;
  position: relative;
  top: -4px;
  left: 5px;
}

#login_iframe_container.new-login.no-bg .login-subtitle::before {
  background-color: #999999;
}

#login_iframe_container.new-login.no-bg .login-subtitle::after {
  background-color: #999999;
}

#login_iframe_container.new-login .close-btn {
  position: absolute;
  top: 20px;
  right: 20px;
  width: 12px;
  height: 12px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -59px -10px;
  background-size: 81px 91px;
  cursor: pointer;
}

#login_iframe_container.new-login .login-btn {
  width: 220px;
  height: 47px;
  border-radius: 24px;
  border: solid 1px #dddddd;
  background-color: #ffffff;
  margin: 0 auto;
  margin-top: 28px;
  position: relative;
  display: block;
}

#login_iframe_container.new-login .login-btn .login-icon {
  position: absolute;
}

#login_iframe_container.new-login .login-btn .login-text {
  width: 61px;
  height: 47px;
  line-height: 47px;
  vertical-align: middle;
  font-size: 15px;
  letter-spacing: 0.1px;
  color: #666666;
  position: absolute;
  right: 62px;
}

#login_iframe_container.new-login .login-btn.qq-btn .login-icon {
  width: 22px;
  height: 27px;
  top: 10px;
  left: 67px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -10px -54px;
  background-size: 81px 91px;
}

#login_iframe_container.new-login .login-btn.qq-btn .login-text {
  right: 59px;
}

#login_iframe_container.new-login .login-btn.wechat-btn .login-icon {
  width: 29px;
  height: 24px;
  top: 12px;
  left: 62px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -10px -10px;
  background-size: 81px 91px;
}</style><style>/* -- container -- */
.rodal,
.rodal-mask {
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: 100;
}

.rodal {
    position: fixed;
}

/* -- mask -- */
.rodal-mask {
    position: fixed;
    background: rgba(0, 0, 0, .5);
}

/* -- dialog -- */
.rodal-dialog {
    position: absolute;
    z-index: 101;
    background: #fff;
    border-radius: 3px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, .2);
}

.rodal-center {
    top: 50%;
    transform: translateY(-50%);
    left: 0;
    right: 0;
    margin: 0 auto;
}

.rodal-bottom {
    left: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

.rodal-top {
    left: 0;
    right: 0;
    top: 0;
    margin: auto;
}

.rodal-left {
    top: 0;
    left: 0;
    bottom: 0;
    margin: auto;
}

.rodal-right {
    top: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

/* -- close button -- */
.rodal-close {
    position: absolute;
    cursor: pointer;
    top: 16px;
    right: 16px;
    width: 16px;
    height: 16px;
}

.rodal-close:before,
.rodal-close:after {
    position: absolute;
    content: '';
    height: 2px;
    width: 100%;
    top: 50%;
    left: 0;
    margin-top: -1px;
    background: #999;
    border-radius: 100%;
    -webkit-transition: background .2s;
    transition: background .2s;
}

.rodal-close:before {
    -webkit-transform: rotate(45deg);
    transform: rotate(45deg);
}

.rodal-close:after {
    -webkit-transform: rotate(-45deg);
    transform: rotate(-45deg);
}

.rodal-close:hover:before,
.rodal-close:hover:after {
    background: #333;
}

/* -- fade -- */
/* @-webkit-keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

@keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

.rodal-fade-enter {
    -webkit-animation: rodal-fade-enter both ease-in;
    animation: rodal-fade-enter both ease-in;
} */

@-webkit-keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

@keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

.rodal-fade-leave {
    -webkit-animation: rodal-fade-leave both ease-out;
    animation: rodal-fade-leave both ease-out;
}

/* -- zoom -- */
@-webkit-keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-enter {
    -webkit-animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-leave {
    -webkit-animation: rodal-zoom-leave both;
    animation: rodal-zoom-leave both;
}

/* -- slideDown -- */
@-webkit-keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-enter {
    -webkit-animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-leave {
    -webkit-animation: rodal-slideDown-leave both;
    animation: rodal-slideDown-leave both;
}

/* -- slideLeft -- */
@-webkit-keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-enter {
    -webkit-animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-leave {
    -webkit-animation: rodal-slideLeft-leave both;
    animation: rodal-slideLeft-leave both;
}

/* -- slideRight -- */
@-webkit-keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-enter {
    -webkit-animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-leave {
    -webkit-animation: rodal-slideRight-leave both;
    animation: rodal-slideRight-leave both;
}

/* -- slideUp -- */
@-webkit-keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-enter {
    -webkit-animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
    animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
}

@-webkit-keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-leave {
    -webkit-animation: rodal-slideUp-leave both;
    animation: rodal-slideUp-leave both;
}

/* -- flip -- */
@-webkit-keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

@keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

.rodal-flip-enter {
    -webkit-animation: rodal-flip-enter both ease-in;
    animation: rodal-flip-enter both ease-in;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

@-webkit-keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

@keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

.rodal-flip-leave {
    -webkit-animation: rodal-flip-leave both;
    animation: rodal-flip-leave both;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

/* -- rotate -- */
@-webkit-keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-enter {
    -webkit-animation: rodal-rotate-enter both;
    animation: rodal-rotate-enter both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

@-webkit-keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-leave {
    -webkit-animation: rodal-rotate-leave both;
    animation: rodal-rotate-leave both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

/* -- door -- */
@-webkit-keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

@keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

.rodal-door-enter {
    -webkit-animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

@keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

.rodal-door-leave {
    -webkit-animation: rodal-door-leave both;
    animation: rodal-door-leave both;
}</style><style>/* -- container -- */
.rodal,
.rodal-mask {
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: 100;
}

.rodal {
    position: fixed;
}

/* -- mask -- */
.rodal-mask {
    position: fixed;
    background: rgba(0, 0, 0, .5);
}

/* -- dialog -- */
.rodal-dialog {
    position: absolute;
    z-index: 101;
    background: #fff;
    border-radius: 3px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, .2);
}

.rodal-center {
    top: 50%;
    transform: translateY(-50%);
    left: 0;
    right: 0;
    margin: 0 auto;
}

.rodal-bottom {
    left: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

.rodal-top {
    left: 0;
    right: 0;
    top: 0;
    margin: auto;
}

.rodal-left {
    top: 0;
    left: 0;
    bottom: 0;
    margin: auto;
}

.rodal-right {
    top: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

/* -- close button -- */
.rodal-close {
    position: absolute;
    cursor: pointer;
    top: 16px;
    right: 16px;
    width: 16px;
    height: 16px;
}

.rodal-close:before,
.rodal-close:after {
    position: absolute;
    content: '';
    height: 2px;
    width: 100%;
    top: 50%;
    left: 0;
    margin-top: -1px;
    background: #999;
    border-radius: 100%;
    -webkit-transition: background .2s;
    transition: background .2s;
}

.rodal-close:before {
    -webkit-transform: rotate(45deg);
    transform: rotate(45deg);
}

.rodal-close:after {
    -webkit-transform: rotate(-45deg);
    transform: rotate(-45deg);
}

.rodal-close:hover:before,
.rodal-close:hover:after {
    background: #333;
}

/* -- fade -- */
/* @-webkit-keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

@keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

.rodal-fade-enter {
    -webkit-animation: rodal-fade-enter both ease-in;
    animation: rodal-fade-enter both ease-in;
} */

@-webkit-keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

@keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

.rodal-fade-leave {
    -webkit-animation: rodal-fade-leave both ease-out;
    animation: rodal-fade-leave both ease-out;
}

/* -- zoom -- */
@-webkit-keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-enter {
    -webkit-animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-leave {
    -webkit-animation: rodal-zoom-leave both;
    animation: rodal-zoom-leave both;
}

/* -- slideDown -- */
@-webkit-keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-enter {
    -webkit-animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-leave {
    -webkit-animation: rodal-slideDown-leave both;
    animation: rodal-slideDown-leave both;
}

/* -- slideLeft -- */
@-webkit-keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-enter {
    -webkit-animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-leave {
    -webkit-animation: rodal-slideLeft-leave both;
    animation: rodal-slideLeft-leave both;
}

/* -- slideRight -- */
@-webkit-keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-enter {
    -webkit-animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-leave {
    -webkit-animation: rodal-slideRight-leave both;
    animation: rodal-slideRight-leave both;
}

/* -- slideUp -- */
@-webkit-keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-enter {
    -webkit-animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
    animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
}

@-webkit-keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-leave {
    -webkit-animation: rodal-slideUp-leave both;
    animation: rodal-slideUp-leave both;
}

/* -- flip -- */
@-webkit-keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

@keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

.rodal-flip-enter {
    -webkit-animation: rodal-flip-enter both ease-in;
    animation: rodal-flip-enter both ease-in;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

@-webkit-keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

@keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

.rodal-flip-leave {
    -webkit-animation: rodal-flip-leave both;
    animation: rodal-flip-leave both;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

/* -- rotate -- */
@-webkit-keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-enter {
    -webkit-animation: rodal-rotate-enter both;
    animation: rodal-rotate-enter both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

@-webkit-keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-leave {
    -webkit-animation: rodal-rotate-leave both;
    animation: rodal-rotate-leave both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

/* -- door -- */
@-webkit-keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

@keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

.rodal-door-enter {
    -webkit-animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

@keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

.rodal-door-leave {
    -webkit-animation: rodal-door-leave both;
    animation: rodal-door-leave both;
}</style></head><body class=""><!-- BEGIN WAYBACK TOOLBAR INSERT -->
<style type="text/css">
body {
  margin-top:0 !important;
  padding-top:0 !important;
  /*min-width:800px !important;*/
}
</style>
<script>__wm.rw(0);</script>
<div id="wm-ipp-base" lang="en" style="display: block; direction: ltr;">
</div><div id="wm-ipp-print">The Wayback Machine - https://web.archive.org/web/20221025120000/https://baike.sogou.com/kexue/d10730.htm</div>
<script type="text/javascript">//<![CDATA[
__wm.bt(675,27,25,2,"web","https://baike.sogou.com/kexue/d10730.htm","20221025120000",1996,"/_static/",["/_static/css/banner-styles.css?v=S1zqJCYt","/_static/css/iconochive.css?v=qtvMKcIJ"], false);
  __wm.rw(1);
//]]></script>
<!-- END WAYBACK TOOLBAR INSERT --><script>window._gtag=window._gtag||{};window._gtag.shouldGrayed = false;if ('cc30f7b633ac4c4b83c39decadc3ad79') window._gtag.traceId = 'cc30f7b633ac4c4b83c39decadc3ad79';if ({"illegality":true}) window.userInfo = {"illegality":true};</script><div class="topnavbox"><ul class="topnav"><li><a href="https://web.archive.org/web/20221025120000/https://www.sogou.com/web?query=">网页</a></li><li><a href="https://web.archive.org/web/20221025120000/https://weixin.sogou.com/weixin?p=75351201">微信</a></li><li><a href="https://web.archive.org/web/20221025120000/https://zhihu.sogou.com/zhihu?p=75351218">知乎</a></li><li><a href="https://web.archive.org/web/20221025120000/https://pic.sogou.com/pics?query=">图片</a></li><li><a href="https://web.archive.org/web/20221025120000/https://v.sogou.com/v?query=">视频</a></li><li><a href="https://web.archive.org/web/20221025120000/https://mingyi.sogou.com/">医疗</a></li><li class="cur"><strong>科学</strong></li><li><a href="https://web.archive.org/web/20221025120000/https://hanyu.sogou.com/">汉语</a></li><li><a href="https://web.archive.org/web/20221025120000/https://wenwen.sogou.com/">问问</a></li><li><a href="https://web.archive.org/web/20221025120000/https://www.sogou.com/docs/more.htm">更多<span class="topraquo">»</span></a></li></ul></div><div id="header"><div class="header-wrap"><a class="header-logo" href="https://web.archive.org/web/20221025120000/https://baike.sogou.com/kexue"></a><div class="header-search"><div class="querybox" id="suggBox"><form><input id="searchInput" class="query" type="text" placeholder="搜科学领域专业百科词条" name="query" autocomplete="off" value=""><a href="javascript:;" class="query-search"></a></form></div></div><div class="header-rgt"><span class="btn-header-rgt btn-edit" id="editLemma">创建</span><div class="header-user no-login"></div></div></div></div><div class="fixed-placeholder" style="visibility:none"></div><div id="container" class=""><div class="content lemma-level1"><div class="detail-title" id="abstract-title"><h1>前馈神经网络</h1><a href="https://web.archive.org/web/20221025120000/https://baike.sogou.com/kexue/d10730.htm#!" class="detail-edit">编辑</a></div><div class="section_content" data-id="54225861024473356"><div class="text_img ed_imgfloat_right"><a class="ed_image_link" data-src="https://img02.sogoucdn.com/app/a/200698/sogou_science_13715" data-bigsrc="https://img02.sogoucdn.com/app/a/200698/sogou_science_13715?width=231&amp;height=174&amp;titlename=%E5%9C%A8%E4%B8%80%E4%B8%AA%E5%89%8D%E9%A6%88%E7%BD%91%E7%BB%9C%E4%B8%AD%EF%BC%8C%E4%BF%A1%E6%81%AF%E6%80%BB%E6%98%AF%E6%9C%9D%E7%9D%80%E4%B8%80%E4%B8%AA%E6%96%B9%E5%90%91%E8%BF%90%E5%8A%A8%EF%BC%9B%E5%AE%83%E4%BB%8E%E4%B8%8D%E5%80%92%E9%80%80%E3%80%82&amp;w=380&amp;h=440" title="点击查看大图" data-w="380" data-h="440" style="background-image:url(https://web.archive.org/web/20221025120000im_/https://img02.sogoucdn.com/app/a/200698/sogou_science_13715)" href="https://web.archive.org/web/20221025120000/https://baike.sogou.com/kexue/d10730.htm#!"></a><div class="text_img_title">在一个前馈网络中，信息总是朝着一个方向运动；它从不倒退。</div></div><div><p>前馈神经网络是一种人工神经网络，其中节点之间的连接不形成循环。<sup><a href="https://web.archive.org/web/20221025120000/https://baike.sogou.com/kexue/d10730.htm#quote_1" class="kx_ref">[1]</a></sup>因此，它不同于递归神经网络。</p>
<p>前馈神经网络是第一种也是最简单的人工神经网络。<sup><a href="https://web.archive.org/web/20221025120000/https://baike.sogou.com/kexue/d10730.htm#quote_2" class="kx_ref">[2]</a></sup> 在这个网络中，信息只沿一个方向向前移动，从输入节点，通过隐藏节点（如果有的话）到达输出节点。网络中没有循环或环路。<sup><a href="https://web.archive.org/web/20221025120000/https://baike.sogou.com/kexue/d10730.htm#quote_1" class="kx_ref">[1]</a></sup> </p></div></div><div id="catalog"><h2 class="title2">目录<a href="javascript:" class="detail-edit">编辑</a></h2><div class="catalog_wrap" style=""><ul class="catalog_list col1"><li><span class="order">1</span><a href="javascript:" data-level="1" data-id="14995480727519759">单层感知器</a></li><li><span class="order">2</span><a href="javascript:" data-level="1" data-id="14995480744296972">多层感知器</a></li><li><span class="order">3</span><a href="javascript:" data-level="1" data-id="references">参考文献</a></li></ul></div></div><div id="paragraphs"><div><div id="par_14995480727519759"><h2 class="title">1 单层感知器<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>最简单的神经网络是单层感知器网络，它由单层输出节点组成；输入通过一系列权重直接馈入输出。在每个节点中计算权重和输入的乘积之和，如果该值高于某个阈值(通常为0)，则神经元触发并获取激活值(通常为1)；否则，它将采用停用的值(通常为-1)。具有这种激活功能的神经元也被称为人工神经元或线性阈值单元。在文献中，感知器一词通常指仅由包含上述三种所提单元其中一个单元组成的网络。沃伦·麦卡洛克和沃尔特·皮茨在20世纪40年代描述了一个类似的神经元。</p><p>感知器可以使用任何值来创建激活和去激活状态，只要阈值在两者之间。</p><p>感知器可以通过一种简单的学习算法来训练，这种算法通常被称为增量规则（<i>delta rule</i>）。它是计算输出数据和样本输出数据之间的误差，并使用该误差对权重进行调整，从而通过一种梯度下降形式来实现调整。</p><p>单层感知器只能学习线性可分离模式；1969年，在著名的专著《感知器》中，马文·明斯基（Marvin Minsky）和西摩·派普茨（Seymour Papert）指出单层感知器网络不可能学习异或函数(尽管如此，众所周知多层感知器能够产生任何可能的布尔函数)。</p><p>尽管单个阈值单元的计算能力非常有限，但已经表明，在区间[-1，1]中某个实数的紧凑区间，并行阈值单元网络可以近似任何连续函数。这个结果可以在彼得·奥尔、哈拉尔德·布尔施泰纳和沃尔夫冈·马斯的《"A learning rule for very simple universal approximators consisting of a single layer of perceptrons》中找到。<sup><a href="https://web.archive.org/web/20221025120000/https://baike.sogou.com/kexue/d10730.htm#quote_3" class="kx_ref">[3]</a></sup> </p><p>单层神经网络可以计算连续输出，而不是阶跃函数。一个常见的选择是所谓的逻辑函数:</p><p><span class="kx_formula" alt="{\displaystyle f(x)={\frac {1}{1+e^{-x}}}}"> 
 &nbsp;<svg xmlns:xlink="http://www.w3.org/1999/xlink" style="fill-opacity:1; color-rendering:auto; color-interpolation:auto; text-rendering:auto; stroke:black; stroke-linecap:square; stroke-miterlimit:10; shape-rendering:auto; stroke-opacity:1; fill:black; stroke-dasharray:none; font-weight:normal; stroke-width:1; font-family:&#39;Dialog&#39;; font-style:normal; stroke-linejoin:miter; font-size:12px; stroke-dashoffset:0; image-rendering:auto;" width="128" height="50" xmlns="http://www.w3.org/2000/svg" class="transfer_formula"><!--Generated by the Batik Graphics2D SVG Generator--><defs id="genericDefs"></defs><g><g transform="scale(20,20) translate(0,1.5031) scale(0.1,0.1)"><path d="M2.0625 -4.125 L2.0625 -1.1875 Q2.0625 -0.5625 2.2031 -0.3906 Q2.375 -0.1719 2.6875 -0.1719 L3.0938 -0.1719 L3.0938 0 L0.4219 0 L0.4219 -0.1719 L0.6094 -0.1719 Q0.8125 -0.1719 0.9766 -0.2734 Q1.1406 -0.375 1.1953 -0.5391 Q1.25 -0.7031 1.25 -1.1875 L1.25 -4.125 L0.3906 -4.125 L0.3906 -4.4688 L1.25 -4.4688 L1.25 -4.7656 Q1.25 -5.4375 1.4688 -5.8984 Q1.6875 -6.3594 2.125 -6.6484 Q2.5625 -6.9375 3.125 -6.9375 Q3.6406 -6.9375 4.0625 -6.6094 Q4.3438 -6.375 4.3438 -6.1094 Q4.3438 -5.9688 4.2188 -5.8359 Q4.0938 -5.7031 3.9531 -5.7031 Q3.8281 -5.7031 3.7031 -5.7812 Q3.5781 -5.8594 3.3984 -6.125 Q3.2188 -6.3906 3.0781 -6.4844 Q2.9219 -6.5781 2.7344 -6.5781 Q2.5156 -6.5781 2.3594 -6.4609 Q2.2031 -6.3438 2.1328 -6.0938 Q2.0625 -5.8438 2.0625 -4.7969 L2.0625 -4.4688 L3.2188 -4.4688 L3.2188 -4.125 L2.0625 -4.125 Z"></path><path d="M0.3281 0.2344 L0.3281 0.2344 Q0.3281 0.25 0.3281 0.25 Q0.3125 0.25 0.2656 0.2031 Q0.2031 0.1406 0.1719 0.0625 Q0.0938 -0.0781 0.0938 -0.25 Q0.0938 -0.4219 0.1562 -0.5625 Q0.2188 -0.6719 0.2969 -0.7344 Q0.3125 -0.75 0.3281 -0.75 Q0.3281 -0.75 0.3281 -0.7344 Q0.3281 -0.7344 0.3125 -0.7188 Q0.1562 -0.5625 0.1562 -0.25 Q0.1562 0.0625 0.3125 0.2188 Q0.3281 0.2344 0.3281 0.2344 Z" transform="scale(10,10) translate(0.4744,0)"></path></g><g transform="matrix(20,0,0,20,0,0) translate(0.8633,1.5031) scale(0.1,0.1)"><path d="M0.125 -4.4688 L2.2344 -4.4688 L2.2344 -4.2969 Q2.0312 -4.2969 1.9531 -4.2266 Q1.875 -4.1562 1.875 -4.0469 Q1.875 -3.9219 2.0469 -3.6875 Q2.0938 -3.6094 2.2031 -3.4375 L2.5312 -2.9375 L2.8906 -3.4375 Q3.25 -3.9219 3.25 -4.0469 Q3.25 -4.1562 3.1641 -4.2266 Q3.0781 -4.2969 2.8906 -4.2969 L2.8906 -4.4688 L4.4062 -4.4688 L4.4062 -4.2969 Q4.1719 -4.2812 3.9844 -4.1562 Q3.75 -4 3.3281 -3.4375 L2.7188 -2.625 L3.8438 -1.0156 Q4.25 -0.4375 4.4219 -0.3125 Q4.5938 -0.1875 4.875 -0.1719 L4.875 0 L2.7656 0 L2.7656 -0.1719 Q2.9844 -0.1719 3.1094 -0.2812 Q3.2031 -0.3438 3.2031 -0.4531 Q3.2031 -0.5625 2.8906 -1.0156 L2.2344 -1.9844 L1.5156 -1.0156 Q1.1875 -0.5781 1.1875 -0.5 Q1.1875 -0.375 1.2969 -0.2812 Q1.4062 -0.1875 1.625 -0.1719 L1.625 0 L0.1719 0 L0.1719 -0.1719 Q0.3438 -0.2031 0.4688 -0.2969 Q0.6562 -0.4375 1.0938 -1.0156 L2.0312 -2.2656 L1.1875 -3.5 Q0.8281 -4.0312 0.6328 -4.1641 Q0.4375 -4.2969 0.125 -4.2969 L0.125 -4.4688 Z"></path><path d="M0.2812 -0.25 L0.2812 -0.25 Q0.2812 -0.0781 0.2188 0.0625 Q0.1719 0.1719 0.0938 0.2344 Q0.0781 0.25 0.0625 0.25 Q0.0625 0.25 0.0625 0.2344 Q0.0625 0.2344 0.0625 0.2188 Q0.2344 0.0625 0.2344 -0.25 Q0.2344 -0.5625 0.0781 -0.7188 L0.0781 -0.7188 Q0.0625 -0.7344 0.0625 -0.7344 Q0.0625 -0.75 0.0625 -0.75 Q0.0781 -0.75 0.125 -0.7031 Q0.1875 -0.6406 0.2188 -0.5625 Q0.2812 -0.4219 0.2812 -0.25 Z" transform="scale(10,10) translate(0.5275,0)"></path></g><g transform="matrix(20,0,0,20,0,0) translate(2.0574,1.5031)"><path d="M0.6875 -0.3281 L0.0938 -0.3281 Q0.0625 -0.3281 0.0625 -0.3438 Q0.0625 -0.3594 0.0938 -0.3594 L0.6875 -0.3594 Q0.7188 -0.3594 0.7188 -0.3438 Q0.7188 -0.3281 0.6875 -0.3281 ZM0.6875 -0.1406 L0.0938 -0.1406 Q0.0625 -0.1406 0.0625 -0.1562 Q0.0625 -0.1719 0.0938 -0.1719 L0.6875 -0.1719 Q0.7188 -0.1719 0.7188 -0.1562 Q0.7188 -0.1406 0.6875 -0.1406 Z"></path></g><g transform="matrix(20,0,0,20,0,0) translate(4.5413,0.8266) scale(0.1,0.1)"><path d="M1.1719 -5.9688 L2.7812 -6.7656 L2.9375 -6.7656 L2.9375 -1.1719 Q2.9375 -0.6094 2.9844 -0.4766 Q3.0312 -0.3438 3.1797 -0.2656 Q3.3281 -0.1875 3.7812 -0.1875 L3.7812 0 L1.2969 0 L1.2969 -0.1875 Q1.7656 -0.1875 1.8984 -0.2578 Q2.0312 -0.3281 2.0859 -0.4531 Q2.1406 -0.5781 2.1406 -1.1719 L2.1406 -4.7344 Q2.1406 -5.4688 2.0938 -5.6719 Q2.0625 -5.8281 1.9688 -5.8984 Q1.875 -5.9688 1.75 -5.9688 Q1.5625 -5.9688 1.25 -5.8281 L1.1719 -5.9688 Z"></path><rect x="3.233" y="1.2331" transform="scale(10,10) translate(-4.5413,-0.8266)" width="3.0347" height="0.04"></rect><path d="M1.1719 -5.9688 L2.7812 -6.7656 L2.9375 -6.7656 L2.9375 -1.1719 Q2.9375 -0.6094 2.9844 -0.4766 Q3.0312 -0.3438 3.1797 -0.2656 Q3.3281 -0.1875 3.7812 -0.1875 L3.7812 0 L1.2969 0 L1.2969 -0.1875 Q1.7656 -0.1875 1.8984 -0.2578 Q2.0312 -0.3281 2.0859 -0.4531 Q2.1406 -0.5781 2.1406 -1.1719 L2.1406 -4.7344 Q2.1406 -5.4688 2.0938 -5.6719 Q2.0625 -5.8281 1.9688 -5.8984 Q1.875 -5.9688 1.75 -5.9688 Q1.5625 -5.9688 1.25 -5.8281 L1.1719 -5.9688 Z" transform="scale(10,10) translate(-1.3083,1.3625) scale(0.1,0.1)"></path><path d="M0.4062 -0.2344 L0.4062 0.0469 Q0.4062 0.0781 0.3906 0.0781 Q0.375 0.0781 0.375 0.0469 L0.375 -0.2344 L0.0938 -0.2344 Q0.0625 -0.2344 0.0625 -0.25 Q0.0625 -0.2656 0.0938 -0.2656 L0.375 -0.2656 L0.375 -0.5469 Q0.375 -0.5781 0.3906 -0.5781 Q0.4062 -0.5781 0.4062 -0.5469 L0.4062 -0.2656 L0.6875 -0.2656 Q0.7188 -0.2656 0.7188 -0.25 Q0.7188 -0.2344 0.6875 -0.2344 L0.4062 -0.2344 Z" transform="scale(10,10) translate(-0.6679,1.3625)"></path></g><g transform="matrix(20,0,0,20,0,0) translate(4.8733,2.189) scale(0.1,0.1)"><path d="M1.0625 -2.7812 Q1.0625 -1.7969 1.5469 -1.2188 Q2.0312 -0.6562 2.7031 -0.6562 Q3.1406 -0.6562 3.4609 -0.8984 Q3.7812 -1.1406 4 -1.7344 L4.1562 -1.625 Q4.0469 -0.9688 3.5547 -0.4141 Q3.0625 0.1406 2.3281 0.1406 Q1.5156 0.1406 0.9453 -0.4922 Q0.375 -1.125 0.375 -2.1719 Q0.375 -3.3281 0.9609 -3.9688 Q1.5469 -4.6094 2.4375 -4.6094 Q3.1875 -4.6094 3.6719 -4.1172 Q4.1562 -3.625 4.1562 -2.7812 L1.0625 -2.7812 ZM1.0625 -3.0781 L3.1406 -3.0781 Q3.1094 -3.5 3.0312 -3.6719 Q2.9062 -3.9531 2.6641 -4.1094 Q2.4219 -4.2656 2.1562 -4.2656 Q1.7656 -4.2656 1.4453 -3.9531 Q1.125 -3.6406 1.0625 -3.0781 Z"></path><path d="M0.6562 -0.2344 L0.1094 -0.2344 Q0.0781 -0.2344 0.0781 -0.25 Q0.0781 -0.2656 0.1094 -0.2656 L0.6562 -0.2656 Q0.6875 -0.2656 0.6875 -0.25 Q0.6875 -0.2344 0.6562 -0.2344 Z" transform="scale(10,10) translate(0.4556,-0.2889) scale(0.7,0.7)"></path></g><g transform="matrix(20,0,0,20,0,0) translate(5.8734,1.9001) scale(0.07,0.07)"><path d="M0.125 -4.4688 L2.2344 -4.4688 L2.2344 -4.2969 Q2.0312 -4.2969 1.9531 -4.2266 Q1.875 -4.1562 1.875 -4.0469 Q1.875 -3.9219 2.0469 -3.6875 Q2.0938 -3.6094 2.2031 -3.4375 L2.5312 -2.9375 L2.8906 -3.4375 Q3.25 -3.9219 3.25 -4.0469 Q3.25 -4.1562 3.1641 -4.2266 Q3.0781 -4.2969 2.8906 -4.2969 L2.8906 -4.4688 L4.4062 -4.4688 L4.4062 -4.2969 Q4.1719 -4.2812 3.9844 -4.1562 Q3.75 -4 3.3281 -3.4375 L2.7188 -2.625 L3.8438 -1.0156 Q4.25 -0.4375 4.4219 -0.3125 Q4.5938 -0.1875 4.875 -0.1719 L4.875 0 L2.7656 0 L2.7656 -0.1719 Q2.9844 -0.1719 3.1094 -0.2812 Q3.2031 -0.3438 3.2031 -0.4531 Q3.2031 -0.5625 2.8906 -1.0156 L2.2344 -1.9844 L1.5156 -1.0156 Q1.1875 -0.5781 1.1875 -0.5 Q1.1875 -0.375 1.2969 -0.2812 Q1.4062 -0.1875 1.625 -0.1719 L1.625 0 L0.1719 0 L0.1719 -0.1719 Q0.3438 -0.2031 0.4688 -0.2969 Q0.6562 -0.4375 1.0938 -1.0156 L2.0312 -2.2656 L1.1875 -3.5 Q0.8281 -4.0312 0.6328 -4.1641 Q0.4375 -4.2969 0.125 -4.2969 L0.125 -4.4688 Z"></path></g></g></svg>&nbsp;</span></p><p>有了这个选择，单层网络就等同于逻辑回归模型，广泛应用于统计建模。逻辑函数也被称为sigmoid函数。它导数具有连续性，因此它可以用于反向传播。该函数也是优选的，因为其导数易于计算:</p><p><span class="kx_formula" alt="{\displaystyle f&#39;(x)=f(x)(1-f(x))}"> 
 &nbsp;<svg xmlns:xlink="http://www.w3.org/1999/xlink" style="fill-opacity:1; color-rendering:auto; color-interpolation:auto; text-rendering:auto; stroke:black; stroke-linecap:square; stroke-miterlimit:10; shape-rendering:auto; stroke-opacity:1; fill:black; stroke-dasharray:none; font-weight:normal; stroke-width:1; font-family:&#39;Dialog&#39;; font-style:normal; stroke-linejoin:miter; font-size:12px; stroke-dashoffset:0; image-rendering:auto;" width="187" height="28" xmlns="http://www.w3.org/2000/svg" class="transfer_formula"><!--Generated by the Batik Graphics2D SVG Generator--><defs id="genericDefs"></defs><g><g transform="scale(20,20) translate(0,0.9624) scale(0.1,0.1)"><path d="M2.0625 -4.125 L2.0625 -1.1875 Q2.0625 -0.5625 2.2031 -0.3906 Q2.375 -0.1719 2.6875 -0.1719 L3.0938 -0.1719 L3.0938 0 L0.4219 0 L0.4219 -0.1719 L0.6094 -0.1719 Q0.8125 -0.1719 0.9766 -0.2734 Q1.1406 -0.375 1.1953 -0.5391 Q1.25 -0.7031 1.25 -1.1875 L1.25 -4.125 L0.3906 -4.125 L0.3906 -4.4688 L1.25 -4.4688 L1.25 -4.7656 Q1.25 -5.4375 1.4688 -5.8984 Q1.6875 -6.3594 2.125 -6.6484 Q2.5625 -6.9375 3.125 -6.9375 Q3.6406 -6.9375 4.0625 -6.6094 Q4.3438 -6.375 4.3438 -6.1094 Q4.3438 -5.9688 4.2188 -5.8359 Q4.0938 -5.7031 3.9531 -5.7031 Q3.8281 -5.7031 3.7031 -5.7812 Q3.5781 -5.8594 3.3984 -6.125 Q3.2188 -6.3906 3.0781 -6.4844 Q2.9219 -6.5781 2.7344 -6.5781 Q2.5156 -6.5781 2.3594 -6.4609 Q2.2031 -6.3438 2.1328 -6.0938 Q2.0625 -5.8438 2.0625 -4.7969 L2.0625 -4.4688 L3.2188 -4.4688 L3.2188 -4.125 L2.0625 -4.125 Z"></path><path d="M0.25 -0.4844 L0.0781 -0.0625 Q0.0625 -0.0469 0.0625 -0.0469 Q0.0469 -0.0469 0.0312 -0.0625 Q0.0312 -0.0625 0.0312 -0.0625 Q0.0312 -0.0625 0.0312 -0.0781 L0.1562 -0.5156 Q0.1719 -0.5469 0.2031 -0.5625 Q0.2031 -0.5625 0.2031 -0.5625 Q0.2344 -0.5625 0.25 -0.5312 Q0.2656 -0.5156 0.2656 -0.5 Q0.2656 -0.5 0.25 -0.4844 Z" transform="scale(10,10) translate(0.4744,-0.4235) scale(0.7,0.7)"></path></g><g transform="matrix(20,0,0,20,0,0) translate(0.6919,0.9624)"><path d="M0.3281 0.2344 L0.3281 0.2344 Q0.3281 0.25 0.3281 0.25 Q0.3125 0.25 0.2656 0.2031 Q0.2031 0.1406 0.1719 0.0625 Q0.0938 -0.0781 0.0938 -0.25 Q0.0938 -0.4219 0.1562 -0.5625 Q0.2188 -0.6719 0.2969 -0.7344 Q0.3125 -0.75 0.3281 -0.75 Q0.3281 -0.75 0.3281 -0.7344 Q0.3281 -0.7344 0.3125 -0.7188 Q0.1562 -0.5625 0.1562 -0.25 Q0.1562 0.0625 0.3125 0.2188 Q0.3281 0.2344 0.3281 0.2344 Z"></path></g><g transform="matrix(20,0,0,20,0,0) translate(1.0808,0.9624) scale(0.1,0.1)"><path d="M0.125 -4.4688 L2.2344 -4.4688 L2.2344 -4.2969 Q2.0312 -4.2969 1.9531 -4.2266 Q1.875 -4.1562 1.875 -4.0469 Q1.875 -3.9219 2.0469 -3.6875 Q2.0938 -3.6094 2.2031 -3.4375 L2.5312 -2.9375 L2.8906 -3.4375 Q3.25 -3.9219 3.25 -4.0469 Q3.25 -4.1562 3.1641 -4.2266 Q3.0781 -4.2969 2.8906 -4.2969 L2.8906 -4.4688 L4.4062 -4.4688 L4.4062 -4.2969 Q4.1719 -4.2812 3.9844 -4.1562 Q3.75 -4 3.3281 -3.4375 L2.7188 -2.625 L3.8438 -1.0156 Q4.25 -0.4375 4.4219 -0.3125 Q4.5938 -0.1875 4.875 -0.1719 L4.875 0 L2.7656 0 L2.7656 -0.1719 Q2.9844 -0.1719 3.1094 -0.2812 Q3.2031 -0.3438 3.2031 -0.4531 Q3.2031 -0.5625 2.8906 -1.0156 L2.2344 -1.9844 L1.5156 -1.0156 Q1.1875 -0.5781 1.1875 -0.5 Q1.1875 -0.375 1.2969 -0.2812 Q1.4062 -0.1875 1.625 -0.1719 L1.625 0 L0.1719 0 L0.1719 -0.1719 Q0.3438 -0.2031 0.4688 -0.2969 Q0.6562 -0.4375 1.0938 -1.0156 L2.0312 -2.2656 L1.1875 -3.5 Q0.8281 -4.0312 0.6328 -4.1641 Q0.4375 -4.2969 0.125 -4.2969 L0.125 -4.4688 Z"></path><path d="M0.2812 -0.25 L0.2812 -0.25 Q0.2812 -0.0781 0.2188 0.0625 Q0.1719 0.1719 0.0938 0.2344 Q0.0781 0.25 0.0625 0.25 Q0.0625 0.25 0.0625 0.2344 Q0.0625 0.2344 0.0625 0.2188 Q0.2344 0.0625 0.2344 -0.25 Q0.2344 -0.5625 0.0781 -0.7188 L0.0781 -0.7188 Q0.0625 -0.7344 0.0625 -0.7344 Q0.0625 -0.75 0.0625 -0.75 Q0.0781 -0.75 0.125 -0.7031 Q0.1875 -0.6406 0.2188 -0.5625 Q0.2812 -0.4219 0.2812 -0.25 Z" transform="scale(10,10) translate(0.5275,0)"></path></g><g transform="matrix(20,0,0,20,0,0) translate(2.2749,0.9624)"><path d="M0.6875 -0.3281 L0.0938 -0.3281 Q0.0625 -0.3281 0.0625 -0.3438 Q0.0625 -0.3594 0.0938 -0.3594 L0.6875 -0.3594 Q0.7188 -0.3594 0.7188 -0.3438 Q0.7188 -0.3281 0.6875 -0.3281 ZM0.6875 -0.1406 L0.0938 -0.1406 Q0.0625 -0.1406 0.0625 -0.1562 Q0.0625 -0.1719 0.0938 -0.1719 L0.6875 -0.1719 Q0.7188 -0.1719 0.7188 -0.1562 Q0.7188 -0.1406 0.6875 -0.1406 Z"></path></g><g transform="matrix(20,0,0,20,0,0) translate(3.3305,0.9624) scale(0.1,0.1)"><path d="M2.0625 -4.125 L2.0625 -1.1875 Q2.0625 -0.5625 2.2031 -0.3906 Q2.375 -0.1719 2.6875 -0.1719 L3.0938 -0.1719 L3.0938 0 L0.4219 0 L0.4219 -0.1719 L0.6094 -0.1719 Q0.8125 -0.1719 0.9766 -0.2734 Q1.1406 -0.375 1.1953 -0.5391 Q1.25 -0.7031 1.25 -1.1875 L1.25 -4.125 L0.3906 -4.125 L0.3906 -4.4688 L1.25 -4.4688 L1.25 -4.7656 Q1.25 -5.4375 1.4688 -5.8984 Q1.6875 -6.3594 2.125 -6.6484 Q2.5625 -6.9375 3.125 -6.9375 Q3.6406 -6.9375 4.0625 -6.6094 Q4.3438 -6.375 4.3438 -6.1094 Q4.3438 -5.9688 4.2188 -5.8359 Q4.0938 -5.7031 3.9531 -5.7031 Q3.8281 -5.7031 3.7031 -5.7812 Q3.5781 -5.8594 3.3984 -6.125 Q3.2188 -6.3906 3.0781 -6.4844 Q2.9219 -6.5781 2.7344 -6.5781 Q2.5156 -6.5781 2.3594 -6.4609 Q2.2031 -6.3438 2.1328 -6.0938 Q2.0625 -5.8438 2.0625 -4.7969 L2.0625 -4.4688 L3.2188 -4.4688 L3.2188 -4.125 L2.0625 -4.125 Z"></path><path d="M0.3281 0.2344 L0.3281 0.2344 Q0.3281 0.25 0.3281 0.25 Q0.3125 0.25 0.2656 0.2031 Q0.2031 0.1406 0.1719 0.0625 Q0.0938 -0.0781 0.0938 -0.25 Q0.0938 -0.4219 0.1562 -0.5625 Q0.2188 -0.6719 0.2969 -0.7344 Q0.3125 -0.75 0.3281 -0.75 Q0.3281 -0.75 0.3281 -0.7344 Q0.3281 -0.7344 0.3125 -0.7188 Q0.1562 -0.5625 0.1562 -0.25 Q0.1562 0.0625 0.3125 0.2188 Q0.3281 0.2344 0.3281 0.2344 Z" transform="scale(10,10) translate(0.4744,0)"></path></g><g transform="matrix(20,0,0,20,0,0) translate(4.1938,0.9624) scale(0.1,0.1)"><path d="M0.125 -4.4688 L2.2344 -4.4688 L2.2344 -4.2969 Q2.0312 -4.2969 1.9531 -4.2266 Q1.875 -4.1562 1.875 -4.0469 Q1.875 -3.9219 2.0469 -3.6875 Q2.0938 -3.6094 2.2031 -3.4375 L2.5312 -2.9375 L2.8906 -3.4375 Q3.25 -3.9219 3.25 -4.0469 Q3.25 -4.1562 3.1641 -4.2266 Q3.0781 -4.2969 2.8906 -4.2969 L2.8906 -4.4688 L4.4062 -4.4688 L4.4062 -4.2969 Q4.1719 -4.2812 3.9844 -4.1562 Q3.75 -4 3.3281 -3.4375 L2.7188 -2.625 L3.8438 -1.0156 Q4.25 -0.4375 4.4219 -0.3125 Q4.5938 -0.1875 4.875 -0.1719 L4.875 0 L2.7656 0 L2.7656 -0.1719 Q2.9844 -0.1719 3.1094 -0.2812 Q3.2031 -0.3438 3.2031 -0.4531 Q3.2031 -0.5625 2.8906 -1.0156 L2.2344 -1.9844 L1.5156 -1.0156 Q1.1875 -0.5781 1.1875 -0.5 Q1.1875 -0.375 1.2969 -0.2812 Q1.4062 -0.1875 1.625 -0.1719 L1.625 0 L0.1719 0 L0.1719 -0.1719 Q0.3438 -0.2031 0.4688 -0.2969 Q0.6562 -0.4375 1.0938 -1.0156 L2.0312 -2.2656 L1.1875 -3.5 Q0.8281 -4.0312 0.6328 -4.1641 Q0.4375 -4.2969 0.125 -4.2969 L0.125 -4.4688 Z"></path><path d="M0.2812 -0.25 L0.2812 -0.25 Q0.2812 -0.0781 0.2188 0.0625 Q0.1719 0.1719 0.0938 0.2344 Q0.0781 0.25 0.0625 0.25 Q0.0625 0.25 0.0625 0.2344 Q0.0625 0.2344 0.0625 0.2188 Q0.2344 0.0625 0.2344 -0.25 Q0.2344 -0.5625 0.0781 -0.7188 L0.0781 -0.7188 Q0.0625 -0.7344 0.0625 -0.7344 Q0.0625 -0.75 0.0625 -0.75 Q0.0781 -0.75 0.125 -0.7031 Q0.1875 -0.6406 0.2188 -0.5625 Q0.2812 -0.4219 0.2812 -0.25 Z" transform="scale(10,10) translate(0.5275,0)"></path></g><g transform="matrix(20,0,0,20,0,0) translate(5.1101,0.9624)"><path d="M0.3281 0.2344 L0.3281 0.2344 Q0.3281 0.25 0.3281 0.25 Q0.3125 0.25 0.2656 0.2031 Q0.2031 0.1406 0.1719 0.0625 Q0.0938 -0.0781 0.0938 -0.25 Q0.0938 -0.4219 0.1562 -0.5625 Q0.2188 -0.6719 0.2969 -0.7344 Q0.3125 -0.75 0.3281 -0.75 Q0.3281 -0.75 0.3281 -0.7344 Q0.3281 -0.7344 0.3125 -0.7188 Q0.1562 -0.5625 0.1562 -0.25 Q0.1562 0.0625 0.3125 0.2188 Q0.3281 0.2344 0.3281 0.2344 Z"></path></g><g transform="matrix(20,0,0,20,0,0) translate(5.499,0.9624) scale(0.1,0.1)"><path d="M1.1719 -5.9688 L2.7812 -6.7656 L2.9375 -6.7656 L2.9375 -1.1719 Q2.9375 -0.6094 2.9844 -0.4766 Q3.0312 -0.3438 3.1797 -0.2656 Q3.3281 -0.1875 3.7812 -0.1875 L3.7812 0 L1.2969 0 L1.2969 -0.1875 Q1.7656 -0.1875 1.8984 -0.2578 Q2.0312 -0.3281 2.0859 -0.4531 Q2.1406 -0.5781 2.1406 -1.1719 L2.1406 -4.7344 Q2.1406 -5.4688 2.0938 -5.6719 Q2.0625 -5.8281 1.9688 -5.8984 Q1.875 -5.9688 1.75 -5.9688 Q1.5625 -5.9688 1.25 -5.8281 L1.1719 -5.9688 Z"></path><path d="M0.6562 -0.2344 L0.1094 -0.2344 Q0.0781 -0.2344 0.0781 -0.25 Q0.0781 -0.2656 0.1094 -0.2656 L0.6562 -0.2656 Q0.6875 -0.2656 0.6875 -0.25 Q0.6875 -0.2344 0.6562 -0.2344 Z" transform="scale(10,10) translate(0.6403,0)"></path></g><g transform="matrix(20,0,0,20,0,0) translate(7.1394,0.9624) scale(0.1,0.1)"><path d="M2.0625 -4.125 L2.0625 -1.1875 Q2.0625 -0.5625 2.2031 -0.3906 Q2.375 -0.1719 2.6875 -0.1719 L3.0938 -0.1719 L3.0938 0 L0.4219 0 L0.4219 -0.1719 L0.6094 -0.1719 Q0.8125 -0.1719 0.9766 -0.2734 Q1.1406 -0.375 1.1953 -0.5391 Q1.25 -0.7031 1.25 -1.1875 L1.25 -4.125 L0.3906 -4.125 L0.3906 -4.4688 L1.25 -4.4688 L1.25 -4.7656 Q1.25 -5.4375 1.4688 -5.8984 Q1.6875 -6.3594 2.125 -6.6484 Q2.5625 -6.9375 3.125 -6.9375 Q3.6406 -6.9375 4.0625 -6.6094 Q4.3438 -6.375 4.3438 -6.1094 Q4.3438 -5.9688 4.2188 -5.8359 Q4.0938 -5.7031 3.9531 -5.7031 Q3.8281 -5.7031 3.7031 -5.7812 Q3.5781 -5.8594 3.3984 -6.125 Q3.2188 -6.3906 3.0781 -6.4844 Q2.9219 -6.5781 2.7344 -6.5781 Q2.5156 -6.5781 2.3594 -6.4609 Q2.2031 -6.3438 2.1328 -6.0938 Q2.0625 -5.8438 2.0625 -4.7969 L2.0625 -4.4688 L3.2188 -4.4688 L3.2188 -4.125 L2.0625 -4.125 Z"></path><path d="M0.3281 0.2344 L0.3281 0.2344 Q0.3281 0.25 0.3281 0.25 Q0.3125 0.25 0.2656 0.2031 Q0.2031 0.1406 0.1719 0.0625 Q0.0938 -0.0781 0.0938 -0.25 Q0.0938 -0.4219 0.1562 -0.5625 Q0.2188 -0.6719 0.2969 -0.7344 Q0.3125 -0.75 0.3281 -0.75 Q0.3281 -0.75 0.3281 -0.7344 Q0.3281 -0.7344 0.3125 -0.7188 Q0.1562 -0.5625 0.1562 -0.25 Q0.1562 0.0625 0.3125 0.2188 Q0.3281 0.2344 0.3281 0.2344 Z" transform="scale(10,10) translate(0.4744,0)"></path></g><g transform="matrix(20,0,0,20,0,0) translate(8.0027,0.9624) scale(0.1,0.1)"><path d="M0.125 -4.4688 L2.2344 -4.4688 L2.2344 -4.2969 Q2.0312 -4.2969 1.9531 -4.2266 Q1.875 -4.1562 1.875 -4.0469 Q1.875 -3.9219 2.0469 -3.6875 Q2.0938 -3.6094 2.2031 -3.4375 L2.5312 -2.9375 L2.8906 -3.4375 Q3.25 -3.9219 3.25 -4.0469 Q3.25 -4.1562 3.1641 -4.2266 Q3.0781 -4.2969 2.8906 -4.2969 L2.8906 -4.4688 L4.4062 -4.4688 L4.4062 -4.2969 Q4.1719 -4.2812 3.9844 -4.1562 Q3.75 -4 3.3281 -3.4375 L2.7188 -2.625 L3.8438 -1.0156 Q4.25 -0.4375 4.4219 -0.3125 Q4.5938 -0.1875 4.875 -0.1719 L4.875 0 L2.7656 0 L2.7656 -0.1719 Q2.9844 -0.1719 3.1094 -0.2812 Q3.2031 -0.3438 3.2031 -0.4531 Q3.2031 -0.5625 2.8906 -1.0156 L2.2344 -1.9844 L1.5156 -1.0156 Q1.1875 -0.5781 1.1875 -0.5 Q1.1875 -0.375 1.2969 -0.2812 Q1.4062 -0.1875 1.625 -0.1719 L1.625 0 L0.1719 0 L0.1719 -0.1719 Q0.3438 -0.2031 0.4688 -0.2969 Q0.6562 -0.4375 1.0938 -1.0156 L2.0312 -2.2656 L1.1875 -3.5 Q0.8281 -4.0312 0.6328 -4.1641 Q0.4375 -4.2969 0.125 -4.2969 L0.125 -4.4688 Z"></path><path d="M0.2812 -0.25 L0.2812 -0.25 Q0.2812 -0.0781 0.2188 0.0625 Q0.1719 0.1719 0.0938 0.2344 Q0.0781 0.25 0.0625 0.25 Q0.0625 0.25 0.0625 0.2344 Q0.0625 0.2344 0.0625 0.2188 Q0.2344 0.0625 0.2344 -0.25 Q0.2344 -0.5625 0.0781 -0.7188 L0.0781 -0.7188 Q0.0625 -0.7344 0.0625 -0.7344 Q0.0625 -0.75 0.0625 -0.75 Q0.0781 -0.75 0.125 -0.7031 Q0.1875 -0.6406 0.2188 -0.5625 Q0.2812 -0.4219 0.2812 -0.25 Z" transform="scale(10,10) translate(0.5275,0)"></path></g><g transform="matrix(20,0,0,20,0,0) translate(8.919,0.9624)"><path d="M0.2812 -0.25 L0.2812 -0.25 Q0.2812 -0.0781 0.2188 0.0625 Q0.1719 0.1719 0.0938 0.2344 Q0.0781 0.25 0.0625 0.25 Q0.0625 0.25 0.0625 0.2344 Q0.0625 0.2344 0.0625 0.2188 Q0.2344 0.0625 0.2344 -0.25 Q0.2344 -0.5625 0.0781 -0.7188 L0.0781 -0.7188 Q0.0625 -0.7344 0.0625 -0.7344 Q0.0625 -0.75 0.0625 -0.75 Q0.0781 -0.75 0.125 -0.7031 Q0.1875 -0.6406 0.2188 -0.5625 Q0.2812 -0.4219 0.2812 -0.25 Z"></path></g></g></svg>&nbsp;</span>。</p><p>(事实上，f满足上述微分方程，可以很容易地通过应用链式法则来证明。)</p></div></div><div id="par_14995480744296972"><h2 class="title">2 多层感知器<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p></p><div class="text_img ed_imgfloat_right">
            <a class="ed_image_link lazyLoad" data-src="https://img01.sogoucdn.com/app/a/200698/sogou_science_14112" data-bigsrc="" title="点击查看大图" href="javascript:" data-observer="true"></a>
            <div class="text_img_title">一种能够计算XOR的双层神经网络。神经元内的数字表示每个神经元的显式阈值（可以将其提出来，使所有神经元具有相同的阈值，通常为1）。标注箭头的数字表示输入的权重。这个网络假设如果没有达到阈值，则输出0（不是-1）。注意，输入的底层并不总被认作一个真正的神经网络层。</div>   
        </div> <p></p><p>这类网络由多层计算单元组成，通常以前馈方式相互连接。一层中的每个神经元都与下一层的神经元有直接的连接。在许多应用中，这些网络的单元将sigmoid函数用作激活函数。</p><p>神经网络的通用近似定理（Universal approximation theorem）指出，每个将实数区间映射到实数输出区间的连续函数，都可以由只有一个隐藏层的多层感知器任意逼近。这一结果适用于广泛的激活函数，例如sigmoid函数。</p><p>多层网络使用多种学习技术，最流行的是反向传播。这里，将输出值与正确答案进行比较，以计算某个预定义误差函数的值。通过各种技术，误差然后通过网络反馈。使用该信息，算法调整每个连接的权重，以便将误差函数值减少一些。在重复这个过程，并达到足够多的训练周期后，网络通常会收敛到计算误差很小的状态。在这种情况下，可以说网络已经学习了某个目标方程。为了适当地调整权重，我们应用了一种非线性优化的通用方法，称为梯度下降。为此，网络计算误差方程相对于网络权重的导数，并改变权重，使得误差减小(从而在误差方程的表面上下降)。因此，反向传播只能应用于具有可微分激活函数的网络。</p><p>一般来说，在测试样本上，如何来训练网络来取得良好的表现，也是一个非常微妙的问题，需要额外的技术。这对于只有非常有限数量的训练样本可用的情况尤其重要。<sup><a href="https://web.archive.org/web/20221025120000/https://baike.sogou.com/kexue/d10730.htm#quote_4" class="kx_ref">[4]</a></sup>一个危险在于网络对训练数据过度拟合，无法学习生成数据的真实统计过程。计算学习理论关注在有限的数据量上训练分类器。在神经网络的环境中，一种简单的启发式方法，称为早期停止（early stopping），通常可以确保网络很好地推广到不在训练集中的例子。</p><p>反向传播算法的其他典型问题是收敛速度和最终达到误差方程局部最小值的可能性。今天，有一些实用的方法使多层感知器中的反向传播成为许多机器学习任务的首选工具。</p><p>人们也可以使用一系列由某种媒介调节的独立神经网络，类似的行为也发生在大脑中。这些神经元可以独立地执行并处理一项大任务，最终可以将结果组合在一起。 <sup><a href="https://web.archive.org/web/20221025120000/https://baike.sogou.com/kexue/d10730.htm#quote_5" class="kx_ref">[5]</a></sup> </p></div></div></div></div><div id="references"><h2 class="title" id="par_references">参考文献</h2><ul class="references"><li id="quote_1"><span class="references-num">[1]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Zell, Andreas (1994). Simulation Neuronaler Netze [Simulation of Neural Networks] (in German) (1st ed.). Addison-Wesley. p. 73. ISBN 3-89319-554-8.CS1 maint: Unrecognized language (link).</span></p></li><li id="quote_2"><span class="references-num">[2]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Deep learning in neural networks: An overview". Neural Networks (in 英语). 61: 85–117. 2015-01-01. arXiv:1404.7828. doi:10.1016/j.neunet.2014.09.003. ISSN 0893-6080..</span></p></li><li id="quote_3"><span class="references-num">[3]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Auer, Peter; Harald Burgsteiner; Wolfgang Maass (2008). "A learning rule for very simple universal approximators consisting of a single layer of perceptrons" (PDF). Neural Networks. 21 (5): 786–795. doi:10.1016/j.neunet.2007.12.036. PMID 18249524..</span></p></li><li id="quote_4"><span class="references-num">[4]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Roman M. Balabin; Ravilya Z. Safieva; Ekaterina I. Lomakina (2007). "Comparison of linear and nonlinear calibration models based on near infrared (NIR) spectroscopy data for gasoline properties prediction". Chemometr Intell Lab. 88 (2): 183–188. doi:10.1016/j.chemolab.2007.04.006..</span></p></li><li id="quote_5"><span class="references-num">[5]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Tahmasebi, Pejman; Hezarkhani, Ardeshir (21 January 2011). "Application of a Modular Feedforward Neural Network for Grade Estimation". Natural Resources Research. 20 (1): 25–32. doi:10.1007/s11053-011-9135-3..</span></p></li></ul></div><div class="read-num">阅读 <!-- -->2038</div></div><div class="right-side" id="rightSide"><div class="side" id="lemma-side"><div class="side-title">版本记录</div><ul class="side-lst"><li><p class="side-lst-txt">暂无</p></li></ul><div class="user-card userCard"></div></div><div class="side"><div class="side-event"></div></div></div></div><div class="footer-box"><div id="footer"><div class="footer-logo-wrap"><div class="footer-logo"></div><div class="footer-logo-text">知识·传播·科普</div></div><div class="footer-info">本网站内容采用<a target="_blank" href="https://web.archive.org/web/20221025120000/https://creativecommons.org/licenses/by-sa/3.0/deed.zh?tdsourcetag=s_pctim_aiomsg">CC-BY-SA 3.0</a>授权</div><div class="footer-btn-wrap"><a target="_blank" href="https://web.archive.org/web/20221025120000/https://baike.sogou.com/help/#user_protocol">用户协议</a><a target="_blank" href="https://web.archive.org/web/20221025120000/http://www.sogou.com/docs/terms.htm?v=1">免责声明</a><a target="_blank" href="https://web.archive.org/web/20221025120000/http://corp.sogou.com/private.html">隐私政策</a><a target="_blank" href="https://web.archive.org/web/20221025120000/https://baike.sogou.com/kexue/intro.htm">关于我们</a></div></div></div><script>window.lemmaInfo ={"lemmaId":"10730","versionId":"54225861024473352","title":"前馈神经网络","subtitle":"","abstracts":{"paragraphId":"54225861024473356","title":"摘要","versionId":"54225861024473353","lemmaId":10730,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":82859321,"name":"━╋独特","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1599617131,"comment":null,"dependVersionId":0,"contentType":2,"content":"<p>前馈神经网络是一种人工神经网络，其中节点之间的连接不形成循环。<sup><a href=\"#quote_1\" class=\"kx_ref\">[1]</a></sup>因此，它不同于递归神经网络。</p>\n<p>前馈神经网络是第一种也是最简单的人工神经网络。<sup><a href=\"#quote_2\" class=\"kx_ref\">[2]</a></sup> 在这个网络中，信息只沿一个方向向前移动，从输入节点，通过隐藏节点（如果有的话）到达输出节点。网络中没有循环或环路。<sup><a href=\"#quote_1\" class=\"kx_ref\">[1]</a></sup> </p>","pics":[{"originalUrl":"https://web.archive.org/web/20221025120000/https://img02.sogoucdn.com/app/a/200698/sogou_science_13715?width=231&height=174&titlename=%E5%9C%A8%E4%B8%80%E4%B8%AA%E5%89%8D%E9%A6%88%E7%BD%91%E7%BB%9C%E4%B8%AD%EF%BC%8C%E4%BF%A1%E6%81%AF%E6%80%BB%E6%98%AF%E6%9C%9D%E7%9D%80%E4%B8%80%E4%B8%AA%E6%96%B9%E5%90%91%E8%BF%90%E5%8A%A8%EF%BC%9B%E5%AE%83%E4%BB%8E%E4%B8%8D%E5%80%92%E9%80%80%E3%80%82&w=380&h=440","url":"https://web.archive.org/web/20221025120000/https://img02.sogoucdn.com/app/a/200698/sogou_science_13715","rw":380,"rh":440,"title":"在一个前馈网络中，信息总是朝着一个方向运动；它从不倒退。","alt":null,"width":231,"height":174}],"card":null,"references":[],"versionCount":0},"card":{"paragraphId":"0","title":"","versionId":"0","lemmaId":0,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":0,"comment":null,"dependVersionId":0,"contentType":0,"content":"","pics":null,"card":null,"references":null,"versionCount":0},"categories":[{"id":1,"name":"计算机","parents":[]}],"creator":{"uid":10145103,"name":"柚子otto","pic":"https://web.archive.org/web/20221025120000/https://img02.sogoucdn.com/app/a/200698/1152_1152_1864088_20200427232849-1518843971.png","introduction":"","educations":[{"schoolName":"中国地质大学（北京）","major":"","degree":"本科","universityId":22,"universityLogo":"https://web.archive.org/web/20221025120000/https://img01.sogoucdn.com/app/a/200943/d3465c1c-6011-11e9-b353-fc4dd4f70029","majorLevel1":"理学","majorLevel2":"地理学","majorLevel3":"地图学与地理信息系统","majorLevel1Id":1,"majorLevel2Id":103,"majorLevel3Id":109,"state":"毕业","lab":"","researchField":""}],"jobs":[{"company":"搜狗","title":"产品经理"}],"works":null,"educationBrief":"中国地质大学（北京）","jobBrief":"产品经理","role":0,"roleName":null,"title":"中国地质大学（北京） · 地理学本科","professionalTitle":null,"phoneNo":null,"editable":true,"partnerId":139,"partnerIdCreateTime":1595844881,"partnerIdPoped":true},"createTime":1569227130,"editor":{"uid":10145103,"name":"柚子otto","pic":"https://web.archive.org/web/20221025120000/https://img02.sogoucdn.com/app/a/200698/1152_1152_1864088_20200427232849-1518843971.png","introduction":"","educations":[{"schoolName":"中国地质大学（北京）","major":"","degree":"本科","universityId":22,"universityLogo":"https://web.archive.org/web/20221025120000/https://img01.sogoucdn.com/app/a/200943/d3465c1c-6011-11e9-b353-fc4dd4f70029","majorLevel1":"理学","majorLevel2":"地理学","majorLevel3":"地图学与地理信息系统","majorLevel1Id":1,"majorLevel2Id":103,"majorLevel3Id":109,"state":"毕业","lab":"","researchField":""}],"jobs":[{"company":"搜狗","title":"产品经理"}],"works":null,"educationBrief":"中国地质大学（北京）","jobBrief":"产品经理","role":0,"roleName":null,"title":"中国地质大学（北京） · 地理学本科","professionalTitle":null,"phoneNo":null,"editable":true,"partnerId":139,"partnerIdCreateTime":1595844881,"partnerIdPoped":true},"editTime":1576234002,"state":1,"versionCount":1,"upNum":0,"downNum":0,"pics":[{"originalUrl":"https://web.archive.org/web/20221025120000/https://img02.sogoucdn.com/app/a/200698/sogou_science_13715?width=231&height=174&titlename=%E5%9C%A8%E4%B8%80%E4%B8%AA%E5%89%8D%E9%A6%88%E7%BD%91%E7%BB%9C%E4%B8%AD%EF%BC%8C%E4%BF%A1%E6%81%AF%E6%80%BB%E6%98%AF%E6%9C%9D%E7%9D%80%E4%B8%80%E4%B8%AA%E6%96%B9%E5%90%91%E8%BF%90%E5%8A%A8%EF%BC%9B%E5%AE%83%E4%BB%8E%E4%B8%8D%E5%80%92%E9%80%80%E3%80%82&w=380&h=440","url":"https://web.archive.org/web/20221025120000/https://img02.sogoucdn.com/app/a/200698/sogou_science_13715","rw":380,"rh":440,"title":"在一个前馈网络中，信息总是朝着一个方向运动；它从不倒退。","alt":null,"width":231,"height":174},{"originalUrl":"https://web.archive.org/web/20221025120000/https://img01.sogoucdn.com/app/a/200698/sogou_science_14112?w=250&h=248&titlename=%E4%B8%80%E7%A7%8D%E8%83%BD%E5%A4%9F%E8%AE%A1%E7%AE%97XOR%E7%9A%84%E5%8F%8C%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E3%80%82%E7%A5%9E%E7%BB%8F%E5%85%83%E5%86%85%E7%9A%84%E6%95%B0%E5%AD%97%E8%A1%A8%E7%A4%BA%E6%AF%8F%E4%B8%AA%E7%A5%9E%E7%BB%8F%E5%85%83%E7%9A%84%E6%98%BE%E5%BC%8F%E9%98%88%E5%80%BC%EF%BC%88%E5%8F%AF%E4%BB%A5%E5%B0%86%E5%85%B6%E6%8F%90%E5%87%BA%E6%9D%A5%EF%BC%8C%E4%BD%BF%E6%89%80%E6%9C%89%E7%A5%9E%E7%BB%8F%E5%85%83%E5%85%B7%E6%9C%89%E7%9B%B8%E5%90%8C%E7%9A%84%E9%98%88%E5%80%BC%EF%BC%8C%E9%80%9A%E5%B8%B8%E4%B8%BA1%EF%BC%89%E3%80%82%E6%A0%87%E6%B3%A8%E7%AE%AD%E5%A4%B4%E7%9A%84%E6%95%B0%E5%AD%97%E8%A1%A8%E7%A4%BA%E8%BE%93%E5%85%A5%E7%9A%84%E6%9D%83%E9%87%8D%E3%80%82%E8%BF%99%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%81%87%E8%AE%BE%E5%A6%82%E6%9E%9C%E6%B2%A1%E6%9C%89%E8%BE%BE%E5%88%B0%E9%98%88%E5%80%BC%EF%BC%8C%E5%88%99%E8%BE%93%E5%87%BA0%EF%BC%88%E4%B8%8D%E6%98%AF-1%EF%BC%89%E3%80%82%E6%B3%A8%E6%84%8F%EF%BC%8C%E8%BE%93%E5%85%A5%E7%9A%84%E5%BA%95%E5%B1%82%E5%B9%B6%E4%B8%8D%E6%80%BB%E8%A2%AB%E8%AE%A4%E4%BD%9C%E4%B8%80%E4%B8%AA%E7%9C%9F%E6%AD%A3%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%B1%82%E3%80%82","url":"https://web.archive.org/web/20221025120000/https://img01.sogoucdn.com/app/a/200698/sogou_science_14112","rw":250,"rh":248,"title":"一种能够计算XOR的双层神经网络。神经元内的数字表示每个神经元的显式阈值（可以将其提出来，使所有神经元具有相同的阈值，通常为1）。标注箭头的数字表示输入的权重。这个网络假设如果没有达到阈值，则输出0（不是-1）。注意，输入的底层并不总被认作一个真正的神经网络层。","alt":null,"width":0,"height":0}],"catalogs":[{"level":1,"title":"单层感知器","paragraphId":"14995480727519759","subCatalogs":null},{"level":1,"title":"多层感知器","paragraphId":"14995480744296972","subCatalogs":null},{"level":1,"title":"参考文献","paragraphId":"-1","subCatalogs":null}],"paragraphs":[{"paragraphId":"14995480727519759","title":"单层感知器","versionId":"54225861024473354","lemmaId":10730,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":82859321,"name":"━╋独特","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1599617131,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>最简单的神经网络是单层感知器网络，它由单层输出节点组成；输入通过一系列权重直接馈入输出。在每个节点中计算权重和输入的乘积之和，如果该值高于某个阈值(通常为0)，则神经元触发并获取激活值(通常为1)；否则，它将采用停用的值(通常为-1)。具有这种激活功能的神经元也被称为人工神经元或线性阈值单元。在文献中，感知器一词通常指仅由包含上述三种所提单元其中一个单元组成的网络。沃伦·麦卡洛克和沃尔特·皮茨在20世纪40年代描述了一个类似的神经元。</p><p>感知器可以使用任何值来创建激活和去激活状态，只要阈值在两者之间。</p><p>感知器可以通过一种简单的学习算法来训练，这种算法通常被称为增量规则（<i>delta rule</i>）。它是计算输出数据和样本输出数据之间的误差，并使用该误差对权重进行调整，从而通过一种梯度下降形式来实现调整。</p><p>单层感知器只能学习线性可分离模式；1969年，在著名的专著《感知器》中，马文·明斯基（Marvin Minsky）和西摩·派普茨（Seymour Papert）指出单层感知器网络不可能学习异或函数(尽管如此，众所周知多层感知器能够产生任何可能的布尔函数)。</p><p>尽管单个阈值单元的计算能力非常有限，但已经表明，在区间[-1，1]中某个实数的紧凑区间，并行阈值单元网络可以近似任何连续函数。这个结果可以在彼得·奥尔、哈拉尔德·布尔施泰纳和沃尔夫冈·马斯的《\"A learning rule for very simple universal approximators consisting of a single layer of perceptrons》中找到。<sup><a href=\"#quote_3\" class=\"kx_ref\">[3]</a></sup> </p><p>单层神经网络可以计算连续输出，而不是阶跃函数。一个常见的选择是所谓的逻辑函数:</p><p><span class=\"kx_formula\" alt=\"{\\displaystyle f(x)={\\frac {1}{1+e^{-x}}}}\"> \n &nbsp;<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" style=\"fill-opacity:1; color-rendering:auto; color-interpolation:auto; text-rendering:auto; stroke:black; stroke-linecap:square; stroke-miterlimit:10; shape-rendering:auto; stroke-opacity:1; fill:black; stroke-dasharray:none; font-weight:normal; stroke-width:1; font-family:'Dialog'; font-style:normal; stroke-linejoin:miter; font-size:12px; stroke-dashoffset:0; image-rendering:auto;\" width=\"128\" height=\"50\" xmlns=\"http://www.w3.org/2000/svg\" class=\"transfer_formula\"><!--Generated by the Batik Graphics2D SVG Generator--><defs id=\"genericDefs\"></defs><g><g transform=\"scale(20,20) translate(0,1.5031) scale(0.1,0.1)\"><path d=\"M2.0625 -4.125 L2.0625 -1.1875 Q2.0625 -0.5625 2.2031 -0.3906 Q2.375 -0.1719 2.6875 -0.1719 L3.0938 -0.1719 L3.0938 0 L0.4219 0 L0.4219 -0.1719 L0.6094 -0.1719 Q0.8125 -0.1719 0.9766 -0.2734 Q1.1406 -0.375 1.1953 -0.5391 Q1.25 -0.7031 1.25 -1.1875 L1.25 -4.125 L0.3906 -4.125 L0.3906 -4.4688 L1.25 -4.4688 L1.25 -4.7656 Q1.25 -5.4375 1.4688 -5.8984 Q1.6875 -6.3594 2.125 -6.6484 Q2.5625 -6.9375 3.125 -6.9375 Q3.6406 -6.9375 4.0625 -6.6094 Q4.3438 -6.375 4.3438 -6.1094 Q4.3438 -5.9688 4.2188 -5.8359 Q4.0938 -5.7031 3.9531 -5.7031 Q3.8281 -5.7031 3.7031 -5.7812 Q3.5781 -5.8594 3.3984 -6.125 Q3.2188 -6.3906 3.0781 -6.4844 Q2.9219 -6.5781 2.7344 -6.5781 Q2.5156 -6.5781 2.3594 -6.4609 Q2.2031 -6.3438 2.1328 -6.0938 Q2.0625 -5.8438 2.0625 -4.7969 L2.0625 -4.4688 L3.2188 -4.4688 L3.2188 -4.125 L2.0625 -4.125 Z\"></path><path d=\"M0.3281 0.2344 L0.3281 0.2344 Q0.3281 0.25 0.3281 0.25 Q0.3125 0.25 0.2656 0.2031 Q0.2031 0.1406 0.1719 0.0625 Q0.0938 -0.0781 0.0938 -0.25 Q0.0938 -0.4219 0.1562 -0.5625 Q0.2188 -0.6719 0.2969 -0.7344 Q0.3125 -0.75 0.3281 -0.75 Q0.3281 -0.75 0.3281 -0.7344 Q0.3281 -0.7344 0.3125 -0.7188 Q0.1562 -0.5625 0.1562 -0.25 Q0.1562 0.0625 0.3125 0.2188 Q0.3281 0.2344 0.3281 0.2344 Z\" transform=\"scale(10,10) translate(0.4744,0)\"></path></g><g transform=\"matrix(20,0,0,20,0,0) translate(0.8633,1.5031) scale(0.1,0.1)\"><path d=\"M0.125 -4.4688 L2.2344 -4.4688 L2.2344 -4.2969 Q2.0312 -4.2969 1.9531 -4.2266 Q1.875 -4.1562 1.875 -4.0469 Q1.875 -3.9219 2.0469 -3.6875 Q2.0938 -3.6094 2.2031 -3.4375 L2.5312 -2.9375 L2.8906 -3.4375 Q3.25 -3.9219 3.25 -4.0469 Q3.25 -4.1562 3.1641 -4.2266 Q3.0781 -4.2969 2.8906 -4.2969 L2.8906 -4.4688 L4.4062 -4.4688 L4.4062 -4.2969 Q4.1719 -4.2812 3.9844 -4.1562 Q3.75 -4 3.3281 -3.4375 L2.7188 -2.625 L3.8438 -1.0156 Q4.25 -0.4375 4.4219 -0.3125 Q4.5938 -0.1875 4.875 -0.1719 L4.875 0 L2.7656 0 L2.7656 -0.1719 Q2.9844 -0.1719 3.1094 -0.2812 Q3.2031 -0.3438 3.2031 -0.4531 Q3.2031 -0.5625 2.8906 -1.0156 L2.2344 -1.9844 L1.5156 -1.0156 Q1.1875 -0.5781 1.1875 -0.5 Q1.1875 -0.375 1.2969 -0.2812 Q1.4062 -0.1875 1.625 -0.1719 L1.625 0 L0.1719 0 L0.1719 -0.1719 Q0.3438 -0.2031 0.4688 -0.2969 Q0.6562 -0.4375 1.0938 -1.0156 L2.0312 -2.2656 L1.1875 -3.5 Q0.8281 -4.0312 0.6328 -4.1641 Q0.4375 -4.2969 0.125 -4.2969 L0.125 -4.4688 Z\"></path><path d=\"M0.2812 -0.25 L0.2812 -0.25 Q0.2812 -0.0781 0.2188 0.0625 Q0.1719 0.1719 0.0938 0.2344 Q0.0781 0.25 0.0625 0.25 Q0.0625 0.25 0.0625 0.2344 Q0.0625 0.2344 0.0625 0.2188 Q0.2344 0.0625 0.2344 -0.25 Q0.2344 -0.5625 0.0781 -0.7188 L0.0781 -0.7188 Q0.0625 -0.7344 0.0625 -0.7344 Q0.0625 -0.75 0.0625 -0.75 Q0.0781 -0.75 0.125 -0.7031 Q0.1875 -0.6406 0.2188 -0.5625 Q0.2812 -0.4219 0.2812 -0.25 Z\" transform=\"scale(10,10) translate(0.5275,0)\"></path></g><g transform=\"matrix(20,0,0,20,0,0) translate(2.0574,1.5031)\"><path d=\"M0.6875 -0.3281 L0.0938 -0.3281 Q0.0625 -0.3281 0.0625 -0.3438 Q0.0625 -0.3594 0.0938 -0.3594 L0.6875 -0.3594 Q0.7188 -0.3594 0.7188 -0.3438 Q0.7188 -0.3281 0.6875 -0.3281 ZM0.6875 -0.1406 L0.0938 -0.1406 Q0.0625 -0.1406 0.0625 -0.1562 Q0.0625 -0.1719 0.0938 -0.1719 L0.6875 -0.1719 Q0.7188 -0.1719 0.7188 -0.1562 Q0.7188 -0.1406 0.6875 -0.1406 Z\"></path></g><g transform=\"matrix(20,0,0,20,0,0) translate(4.5413,0.8266) scale(0.1,0.1)\"><path d=\"M1.1719 -5.9688 L2.7812 -6.7656 L2.9375 -6.7656 L2.9375 -1.1719 Q2.9375 -0.6094 2.9844 -0.4766 Q3.0312 -0.3438 3.1797 -0.2656 Q3.3281 -0.1875 3.7812 -0.1875 L3.7812 0 L1.2969 0 L1.2969 -0.1875 Q1.7656 -0.1875 1.8984 -0.2578 Q2.0312 -0.3281 2.0859 -0.4531 Q2.1406 -0.5781 2.1406 -1.1719 L2.1406 -4.7344 Q2.1406 -5.4688 2.0938 -5.6719 Q2.0625 -5.8281 1.9688 -5.8984 Q1.875 -5.9688 1.75 -5.9688 Q1.5625 -5.9688 1.25 -5.8281 L1.1719 -5.9688 Z\"></path><rect x=\"3.233\" y=\"1.2331\" transform=\"scale(10,10) translate(-4.5413,-0.8266)\" width=\"3.0347\" height=\"0.04\"></rect><path d=\"M1.1719 -5.9688 L2.7812 -6.7656 L2.9375 -6.7656 L2.9375 -1.1719 Q2.9375 -0.6094 2.9844 -0.4766 Q3.0312 -0.3438 3.1797 -0.2656 Q3.3281 -0.1875 3.7812 -0.1875 L3.7812 0 L1.2969 0 L1.2969 -0.1875 Q1.7656 -0.1875 1.8984 -0.2578 Q2.0312 -0.3281 2.0859 -0.4531 Q2.1406 -0.5781 2.1406 -1.1719 L2.1406 -4.7344 Q2.1406 -5.4688 2.0938 -5.6719 Q2.0625 -5.8281 1.9688 -5.8984 Q1.875 -5.9688 1.75 -5.9688 Q1.5625 -5.9688 1.25 -5.8281 L1.1719 -5.9688 Z\" transform=\"scale(10,10) translate(-1.3083,1.3625) scale(0.1,0.1)\"></path><path d=\"M0.4062 -0.2344 L0.4062 0.0469 Q0.4062 0.0781 0.3906 0.0781 Q0.375 0.0781 0.375 0.0469 L0.375 -0.2344 L0.0938 -0.2344 Q0.0625 -0.2344 0.0625 -0.25 Q0.0625 -0.2656 0.0938 -0.2656 L0.375 -0.2656 L0.375 -0.5469 Q0.375 -0.5781 0.3906 -0.5781 Q0.4062 -0.5781 0.4062 -0.5469 L0.4062 -0.2656 L0.6875 -0.2656 Q0.7188 -0.2656 0.7188 -0.25 Q0.7188 -0.2344 0.6875 -0.2344 L0.4062 -0.2344 Z\" transform=\"scale(10,10) translate(-0.6679,1.3625)\"></path></g><g transform=\"matrix(20,0,0,20,0,0) translate(4.8733,2.189) scale(0.1,0.1)\"><path d=\"M1.0625 -2.7812 Q1.0625 -1.7969 1.5469 -1.2188 Q2.0312 -0.6562 2.7031 -0.6562 Q3.1406 -0.6562 3.4609 -0.8984 Q3.7812 -1.1406 4 -1.7344 L4.1562 -1.625 Q4.0469 -0.9688 3.5547 -0.4141 Q3.0625 0.1406 2.3281 0.1406 Q1.5156 0.1406 0.9453 -0.4922 Q0.375 -1.125 0.375 -2.1719 Q0.375 -3.3281 0.9609 -3.9688 Q1.5469 -4.6094 2.4375 -4.6094 Q3.1875 -4.6094 3.6719 -4.1172 Q4.1562 -3.625 4.1562 -2.7812 L1.0625 -2.7812 ZM1.0625 -3.0781 L3.1406 -3.0781 Q3.1094 -3.5 3.0312 -3.6719 Q2.9062 -3.9531 2.6641 -4.1094 Q2.4219 -4.2656 2.1562 -4.2656 Q1.7656 -4.2656 1.4453 -3.9531 Q1.125 -3.6406 1.0625 -3.0781 Z\"></path><path d=\"M0.6562 -0.2344 L0.1094 -0.2344 Q0.0781 -0.2344 0.0781 -0.25 Q0.0781 -0.2656 0.1094 -0.2656 L0.6562 -0.2656 Q0.6875 -0.2656 0.6875 -0.25 Q0.6875 -0.2344 0.6562 -0.2344 Z\" transform=\"scale(10,10) translate(0.4556,-0.2889) scale(0.7,0.7)\"></path></g><g transform=\"matrix(20,0,0,20,0,0) translate(5.8734,1.9001) scale(0.07,0.07)\"><path d=\"M0.125 -4.4688 L2.2344 -4.4688 L2.2344 -4.2969 Q2.0312 -4.2969 1.9531 -4.2266 Q1.875 -4.1562 1.875 -4.0469 Q1.875 -3.9219 2.0469 -3.6875 Q2.0938 -3.6094 2.2031 -3.4375 L2.5312 -2.9375 L2.8906 -3.4375 Q3.25 -3.9219 3.25 -4.0469 Q3.25 -4.1562 3.1641 -4.2266 Q3.0781 -4.2969 2.8906 -4.2969 L2.8906 -4.4688 L4.4062 -4.4688 L4.4062 -4.2969 Q4.1719 -4.2812 3.9844 -4.1562 Q3.75 -4 3.3281 -3.4375 L2.7188 -2.625 L3.8438 -1.0156 Q4.25 -0.4375 4.4219 -0.3125 Q4.5938 -0.1875 4.875 -0.1719 L4.875 0 L2.7656 0 L2.7656 -0.1719 Q2.9844 -0.1719 3.1094 -0.2812 Q3.2031 -0.3438 3.2031 -0.4531 Q3.2031 -0.5625 2.8906 -1.0156 L2.2344 -1.9844 L1.5156 -1.0156 Q1.1875 -0.5781 1.1875 -0.5 Q1.1875 -0.375 1.2969 -0.2812 Q1.4062 -0.1875 1.625 -0.1719 L1.625 0 L0.1719 0 L0.1719 -0.1719 Q0.3438 -0.2031 0.4688 -0.2969 Q0.6562 -0.4375 1.0938 -1.0156 L2.0312 -2.2656 L1.1875 -3.5 Q0.8281 -4.0312 0.6328 -4.1641 Q0.4375 -4.2969 0.125 -4.2969 L0.125 -4.4688 Z\"></path></g></g></svg>&nbsp;</span></p><p>有了这个选择，单层网络就等同于逻辑回归模型，广泛应用于统计建模。逻辑函数也被称为sigmoid函数。它导数具有连续性，因此它可以用于反向传播。该函数也是优选的，因为其导数易于计算:</p><p><span class=\"kx_formula\" alt=\"{\\displaystyle f'(x)=f(x)(1-f(x))}\"> \n &nbsp;<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" style=\"fill-opacity:1; color-rendering:auto; color-interpolation:auto; text-rendering:auto; stroke:black; stroke-linecap:square; stroke-miterlimit:10; shape-rendering:auto; stroke-opacity:1; fill:black; stroke-dasharray:none; font-weight:normal; stroke-width:1; font-family:'Dialog'; font-style:normal; stroke-linejoin:miter; font-size:12px; stroke-dashoffset:0; image-rendering:auto;\" width=\"187\" height=\"28\" xmlns=\"http://www.w3.org/2000/svg\" class=\"transfer_formula\"><!--Generated by the Batik Graphics2D SVG Generator--><defs id=\"genericDefs\"></defs><g><g transform=\"scale(20,20) translate(0,0.9624) scale(0.1,0.1)\"><path d=\"M2.0625 -4.125 L2.0625 -1.1875 Q2.0625 -0.5625 2.2031 -0.3906 Q2.375 -0.1719 2.6875 -0.1719 L3.0938 -0.1719 L3.0938 0 L0.4219 0 L0.4219 -0.1719 L0.6094 -0.1719 Q0.8125 -0.1719 0.9766 -0.2734 Q1.1406 -0.375 1.1953 -0.5391 Q1.25 -0.7031 1.25 -1.1875 L1.25 -4.125 L0.3906 -4.125 L0.3906 -4.4688 L1.25 -4.4688 L1.25 -4.7656 Q1.25 -5.4375 1.4688 -5.8984 Q1.6875 -6.3594 2.125 -6.6484 Q2.5625 -6.9375 3.125 -6.9375 Q3.6406 -6.9375 4.0625 -6.6094 Q4.3438 -6.375 4.3438 -6.1094 Q4.3438 -5.9688 4.2188 -5.8359 Q4.0938 -5.7031 3.9531 -5.7031 Q3.8281 -5.7031 3.7031 -5.7812 Q3.5781 -5.8594 3.3984 -6.125 Q3.2188 -6.3906 3.0781 -6.4844 Q2.9219 -6.5781 2.7344 -6.5781 Q2.5156 -6.5781 2.3594 -6.4609 Q2.2031 -6.3438 2.1328 -6.0938 Q2.0625 -5.8438 2.0625 -4.7969 L2.0625 -4.4688 L3.2188 -4.4688 L3.2188 -4.125 L2.0625 -4.125 Z\"></path><path d=\"M0.25 -0.4844 L0.0781 -0.0625 Q0.0625 -0.0469 0.0625 -0.0469 Q0.0469 -0.0469 0.0312 -0.0625 Q0.0312 -0.0625 0.0312 -0.0625 Q0.0312 -0.0625 0.0312 -0.0781 L0.1562 -0.5156 Q0.1719 -0.5469 0.2031 -0.5625 Q0.2031 -0.5625 0.2031 -0.5625 Q0.2344 -0.5625 0.25 -0.5312 Q0.2656 -0.5156 0.2656 -0.5 Q0.2656 -0.5 0.25 -0.4844 Z\" transform=\"scale(10,10) translate(0.4744,-0.4235) scale(0.7,0.7)\"></path></g><g transform=\"matrix(20,0,0,20,0,0) translate(0.6919,0.9624)\"><path d=\"M0.3281 0.2344 L0.3281 0.2344 Q0.3281 0.25 0.3281 0.25 Q0.3125 0.25 0.2656 0.2031 Q0.2031 0.1406 0.1719 0.0625 Q0.0938 -0.0781 0.0938 -0.25 Q0.0938 -0.4219 0.1562 -0.5625 Q0.2188 -0.6719 0.2969 -0.7344 Q0.3125 -0.75 0.3281 -0.75 Q0.3281 -0.75 0.3281 -0.7344 Q0.3281 -0.7344 0.3125 -0.7188 Q0.1562 -0.5625 0.1562 -0.25 Q0.1562 0.0625 0.3125 0.2188 Q0.3281 0.2344 0.3281 0.2344 Z\"></path></g><g transform=\"matrix(20,0,0,20,0,0) translate(1.0808,0.9624) scale(0.1,0.1)\"><path d=\"M0.125 -4.4688 L2.2344 -4.4688 L2.2344 -4.2969 Q2.0312 -4.2969 1.9531 -4.2266 Q1.875 -4.1562 1.875 -4.0469 Q1.875 -3.9219 2.0469 -3.6875 Q2.0938 -3.6094 2.2031 -3.4375 L2.5312 -2.9375 L2.8906 -3.4375 Q3.25 -3.9219 3.25 -4.0469 Q3.25 -4.1562 3.1641 -4.2266 Q3.0781 -4.2969 2.8906 -4.2969 L2.8906 -4.4688 L4.4062 -4.4688 L4.4062 -4.2969 Q4.1719 -4.2812 3.9844 -4.1562 Q3.75 -4 3.3281 -3.4375 L2.7188 -2.625 L3.8438 -1.0156 Q4.25 -0.4375 4.4219 -0.3125 Q4.5938 -0.1875 4.875 -0.1719 L4.875 0 L2.7656 0 L2.7656 -0.1719 Q2.9844 -0.1719 3.1094 -0.2812 Q3.2031 -0.3438 3.2031 -0.4531 Q3.2031 -0.5625 2.8906 -1.0156 L2.2344 -1.9844 L1.5156 -1.0156 Q1.1875 -0.5781 1.1875 -0.5 Q1.1875 -0.375 1.2969 -0.2812 Q1.4062 -0.1875 1.625 -0.1719 L1.625 0 L0.1719 0 L0.1719 -0.1719 Q0.3438 -0.2031 0.4688 -0.2969 Q0.6562 -0.4375 1.0938 -1.0156 L2.0312 -2.2656 L1.1875 -3.5 Q0.8281 -4.0312 0.6328 -4.1641 Q0.4375 -4.2969 0.125 -4.2969 L0.125 -4.4688 Z\"></path><path d=\"M0.2812 -0.25 L0.2812 -0.25 Q0.2812 -0.0781 0.2188 0.0625 Q0.1719 0.1719 0.0938 0.2344 Q0.0781 0.25 0.0625 0.25 Q0.0625 0.25 0.0625 0.2344 Q0.0625 0.2344 0.0625 0.2188 Q0.2344 0.0625 0.2344 -0.25 Q0.2344 -0.5625 0.0781 -0.7188 L0.0781 -0.7188 Q0.0625 -0.7344 0.0625 -0.7344 Q0.0625 -0.75 0.0625 -0.75 Q0.0781 -0.75 0.125 -0.7031 Q0.1875 -0.6406 0.2188 -0.5625 Q0.2812 -0.4219 0.2812 -0.25 Z\" transform=\"scale(10,10) translate(0.5275,0)\"></path></g><g transform=\"matrix(20,0,0,20,0,0) translate(2.2749,0.9624)\"><path d=\"M0.6875 -0.3281 L0.0938 -0.3281 Q0.0625 -0.3281 0.0625 -0.3438 Q0.0625 -0.3594 0.0938 -0.3594 L0.6875 -0.3594 Q0.7188 -0.3594 0.7188 -0.3438 Q0.7188 -0.3281 0.6875 -0.3281 ZM0.6875 -0.1406 L0.0938 -0.1406 Q0.0625 -0.1406 0.0625 -0.1562 Q0.0625 -0.1719 0.0938 -0.1719 L0.6875 -0.1719 Q0.7188 -0.1719 0.7188 -0.1562 Q0.7188 -0.1406 0.6875 -0.1406 Z\"></path></g><g transform=\"matrix(20,0,0,20,0,0) translate(3.3305,0.9624) scale(0.1,0.1)\"><path d=\"M2.0625 -4.125 L2.0625 -1.1875 Q2.0625 -0.5625 2.2031 -0.3906 Q2.375 -0.1719 2.6875 -0.1719 L3.0938 -0.1719 L3.0938 0 L0.4219 0 L0.4219 -0.1719 L0.6094 -0.1719 Q0.8125 -0.1719 0.9766 -0.2734 Q1.1406 -0.375 1.1953 -0.5391 Q1.25 -0.7031 1.25 -1.1875 L1.25 -4.125 L0.3906 -4.125 L0.3906 -4.4688 L1.25 -4.4688 L1.25 -4.7656 Q1.25 -5.4375 1.4688 -5.8984 Q1.6875 -6.3594 2.125 -6.6484 Q2.5625 -6.9375 3.125 -6.9375 Q3.6406 -6.9375 4.0625 -6.6094 Q4.3438 -6.375 4.3438 -6.1094 Q4.3438 -5.9688 4.2188 -5.8359 Q4.0938 -5.7031 3.9531 -5.7031 Q3.8281 -5.7031 3.7031 -5.7812 Q3.5781 -5.8594 3.3984 -6.125 Q3.2188 -6.3906 3.0781 -6.4844 Q2.9219 -6.5781 2.7344 -6.5781 Q2.5156 -6.5781 2.3594 -6.4609 Q2.2031 -6.3438 2.1328 -6.0938 Q2.0625 -5.8438 2.0625 -4.7969 L2.0625 -4.4688 L3.2188 -4.4688 L3.2188 -4.125 L2.0625 -4.125 Z\"></path><path d=\"M0.3281 0.2344 L0.3281 0.2344 Q0.3281 0.25 0.3281 0.25 Q0.3125 0.25 0.2656 0.2031 Q0.2031 0.1406 0.1719 0.0625 Q0.0938 -0.0781 0.0938 -0.25 Q0.0938 -0.4219 0.1562 -0.5625 Q0.2188 -0.6719 0.2969 -0.7344 Q0.3125 -0.75 0.3281 -0.75 Q0.3281 -0.75 0.3281 -0.7344 Q0.3281 -0.7344 0.3125 -0.7188 Q0.1562 -0.5625 0.1562 -0.25 Q0.1562 0.0625 0.3125 0.2188 Q0.3281 0.2344 0.3281 0.2344 Z\" transform=\"scale(10,10) translate(0.4744,0)\"></path></g><g transform=\"matrix(20,0,0,20,0,0) translate(4.1938,0.9624) scale(0.1,0.1)\"><path d=\"M0.125 -4.4688 L2.2344 -4.4688 L2.2344 -4.2969 Q2.0312 -4.2969 1.9531 -4.2266 Q1.875 -4.1562 1.875 -4.0469 Q1.875 -3.9219 2.0469 -3.6875 Q2.0938 -3.6094 2.2031 -3.4375 L2.5312 -2.9375 L2.8906 -3.4375 Q3.25 -3.9219 3.25 -4.0469 Q3.25 -4.1562 3.1641 -4.2266 Q3.0781 -4.2969 2.8906 -4.2969 L2.8906 -4.4688 L4.4062 -4.4688 L4.4062 -4.2969 Q4.1719 -4.2812 3.9844 -4.1562 Q3.75 -4 3.3281 -3.4375 L2.7188 -2.625 L3.8438 -1.0156 Q4.25 -0.4375 4.4219 -0.3125 Q4.5938 -0.1875 4.875 -0.1719 L4.875 0 L2.7656 0 L2.7656 -0.1719 Q2.9844 -0.1719 3.1094 -0.2812 Q3.2031 -0.3438 3.2031 -0.4531 Q3.2031 -0.5625 2.8906 -1.0156 L2.2344 -1.9844 L1.5156 -1.0156 Q1.1875 -0.5781 1.1875 -0.5 Q1.1875 -0.375 1.2969 -0.2812 Q1.4062 -0.1875 1.625 -0.1719 L1.625 0 L0.1719 0 L0.1719 -0.1719 Q0.3438 -0.2031 0.4688 -0.2969 Q0.6562 -0.4375 1.0938 -1.0156 L2.0312 -2.2656 L1.1875 -3.5 Q0.8281 -4.0312 0.6328 -4.1641 Q0.4375 -4.2969 0.125 -4.2969 L0.125 -4.4688 Z\"></path><path d=\"M0.2812 -0.25 L0.2812 -0.25 Q0.2812 -0.0781 0.2188 0.0625 Q0.1719 0.1719 0.0938 0.2344 Q0.0781 0.25 0.0625 0.25 Q0.0625 0.25 0.0625 0.2344 Q0.0625 0.2344 0.0625 0.2188 Q0.2344 0.0625 0.2344 -0.25 Q0.2344 -0.5625 0.0781 -0.7188 L0.0781 -0.7188 Q0.0625 -0.7344 0.0625 -0.7344 Q0.0625 -0.75 0.0625 -0.75 Q0.0781 -0.75 0.125 -0.7031 Q0.1875 -0.6406 0.2188 -0.5625 Q0.2812 -0.4219 0.2812 -0.25 Z\" transform=\"scale(10,10) translate(0.5275,0)\"></path></g><g transform=\"matrix(20,0,0,20,0,0) translate(5.1101,0.9624)\"><path d=\"M0.3281 0.2344 L0.3281 0.2344 Q0.3281 0.25 0.3281 0.25 Q0.3125 0.25 0.2656 0.2031 Q0.2031 0.1406 0.1719 0.0625 Q0.0938 -0.0781 0.0938 -0.25 Q0.0938 -0.4219 0.1562 -0.5625 Q0.2188 -0.6719 0.2969 -0.7344 Q0.3125 -0.75 0.3281 -0.75 Q0.3281 -0.75 0.3281 -0.7344 Q0.3281 -0.7344 0.3125 -0.7188 Q0.1562 -0.5625 0.1562 -0.25 Q0.1562 0.0625 0.3125 0.2188 Q0.3281 0.2344 0.3281 0.2344 Z\"></path></g><g transform=\"matrix(20,0,0,20,0,0) translate(5.499,0.9624) scale(0.1,0.1)\"><path d=\"M1.1719 -5.9688 L2.7812 -6.7656 L2.9375 -6.7656 L2.9375 -1.1719 Q2.9375 -0.6094 2.9844 -0.4766 Q3.0312 -0.3438 3.1797 -0.2656 Q3.3281 -0.1875 3.7812 -0.1875 L3.7812 0 L1.2969 0 L1.2969 -0.1875 Q1.7656 -0.1875 1.8984 -0.2578 Q2.0312 -0.3281 2.0859 -0.4531 Q2.1406 -0.5781 2.1406 -1.1719 L2.1406 -4.7344 Q2.1406 -5.4688 2.0938 -5.6719 Q2.0625 -5.8281 1.9688 -5.8984 Q1.875 -5.9688 1.75 -5.9688 Q1.5625 -5.9688 1.25 -5.8281 L1.1719 -5.9688 Z\"></path><path d=\"M0.6562 -0.2344 L0.1094 -0.2344 Q0.0781 -0.2344 0.0781 -0.25 Q0.0781 -0.2656 0.1094 -0.2656 L0.6562 -0.2656 Q0.6875 -0.2656 0.6875 -0.25 Q0.6875 -0.2344 0.6562 -0.2344 Z\" transform=\"scale(10,10) translate(0.6403,0)\"></path></g><g transform=\"matrix(20,0,0,20,0,0) translate(7.1394,0.9624) scale(0.1,0.1)\"><path d=\"M2.0625 -4.125 L2.0625 -1.1875 Q2.0625 -0.5625 2.2031 -0.3906 Q2.375 -0.1719 2.6875 -0.1719 L3.0938 -0.1719 L3.0938 0 L0.4219 0 L0.4219 -0.1719 L0.6094 -0.1719 Q0.8125 -0.1719 0.9766 -0.2734 Q1.1406 -0.375 1.1953 -0.5391 Q1.25 -0.7031 1.25 -1.1875 L1.25 -4.125 L0.3906 -4.125 L0.3906 -4.4688 L1.25 -4.4688 L1.25 -4.7656 Q1.25 -5.4375 1.4688 -5.8984 Q1.6875 -6.3594 2.125 -6.6484 Q2.5625 -6.9375 3.125 -6.9375 Q3.6406 -6.9375 4.0625 -6.6094 Q4.3438 -6.375 4.3438 -6.1094 Q4.3438 -5.9688 4.2188 -5.8359 Q4.0938 -5.7031 3.9531 -5.7031 Q3.8281 -5.7031 3.7031 -5.7812 Q3.5781 -5.8594 3.3984 -6.125 Q3.2188 -6.3906 3.0781 -6.4844 Q2.9219 -6.5781 2.7344 -6.5781 Q2.5156 -6.5781 2.3594 -6.4609 Q2.2031 -6.3438 2.1328 -6.0938 Q2.0625 -5.8438 2.0625 -4.7969 L2.0625 -4.4688 L3.2188 -4.4688 L3.2188 -4.125 L2.0625 -4.125 Z\"></path><path d=\"M0.3281 0.2344 L0.3281 0.2344 Q0.3281 0.25 0.3281 0.25 Q0.3125 0.25 0.2656 0.2031 Q0.2031 0.1406 0.1719 0.0625 Q0.0938 -0.0781 0.0938 -0.25 Q0.0938 -0.4219 0.1562 -0.5625 Q0.2188 -0.6719 0.2969 -0.7344 Q0.3125 -0.75 0.3281 -0.75 Q0.3281 -0.75 0.3281 -0.7344 Q0.3281 -0.7344 0.3125 -0.7188 Q0.1562 -0.5625 0.1562 -0.25 Q0.1562 0.0625 0.3125 0.2188 Q0.3281 0.2344 0.3281 0.2344 Z\" transform=\"scale(10,10) translate(0.4744,0)\"></path></g><g transform=\"matrix(20,0,0,20,0,0) translate(8.0027,0.9624) scale(0.1,0.1)\"><path d=\"M0.125 -4.4688 L2.2344 -4.4688 L2.2344 -4.2969 Q2.0312 -4.2969 1.9531 -4.2266 Q1.875 -4.1562 1.875 -4.0469 Q1.875 -3.9219 2.0469 -3.6875 Q2.0938 -3.6094 2.2031 -3.4375 L2.5312 -2.9375 L2.8906 -3.4375 Q3.25 -3.9219 3.25 -4.0469 Q3.25 -4.1562 3.1641 -4.2266 Q3.0781 -4.2969 2.8906 -4.2969 L2.8906 -4.4688 L4.4062 -4.4688 L4.4062 -4.2969 Q4.1719 -4.2812 3.9844 -4.1562 Q3.75 -4 3.3281 -3.4375 L2.7188 -2.625 L3.8438 -1.0156 Q4.25 -0.4375 4.4219 -0.3125 Q4.5938 -0.1875 4.875 -0.1719 L4.875 0 L2.7656 0 L2.7656 -0.1719 Q2.9844 -0.1719 3.1094 -0.2812 Q3.2031 -0.3438 3.2031 -0.4531 Q3.2031 -0.5625 2.8906 -1.0156 L2.2344 -1.9844 L1.5156 -1.0156 Q1.1875 -0.5781 1.1875 -0.5 Q1.1875 -0.375 1.2969 -0.2812 Q1.4062 -0.1875 1.625 -0.1719 L1.625 0 L0.1719 0 L0.1719 -0.1719 Q0.3438 -0.2031 0.4688 -0.2969 Q0.6562 -0.4375 1.0938 -1.0156 L2.0312 -2.2656 L1.1875 -3.5 Q0.8281 -4.0312 0.6328 -4.1641 Q0.4375 -4.2969 0.125 -4.2969 L0.125 -4.4688 Z\"></path><path d=\"M0.2812 -0.25 L0.2812 -0.25 Q0.2812 -0.0781 0.2188 0.0625 Q0.1719 0.1719 0.0938 0.2344 Q0.0781 0.25 0.0625 0.25 Q0.0625 0.25 0.0625 0.2344 Q0.0625 0.2344 0.0625 0.2188 Q0.2344 0.0625 0.2344 -0.25 Q0.2344 -0.5625 0.0781 -0.7188 L0.0781 -0.7188 Q0.0625 -0.7344 0.0625 -0.7344 Q0.0625 -0.75 0.0625 -0.75 Q0.0781 -0.75 0.125 -0.7031 Q0.1875 -0.6406 0.2188 -0.5625 Q0.2812 -0.4219 0.2812 -0.25 Z\" transform=\"scale(10,10) translate(0.5275,0)\"></path></g><g transform=\"matrix(20,0,0,20,0,0) translate(8.919,0.9624)\"><path d=\"M0.2812 -0.25 L0.2812 -0.25 Q0.2812 -0.0781 0.2188 0.0625 Q0.1719 0.1719 0.0938 0.2344 Q0.0781 0.25 0.0625 0.25 Q0.0625 0.25 0.0625 0.2344 Q0.0625 0.2344 0.0625 0.2188 Q0.2344 0.0625 0.2344 -0.25 Q0.2344 -0.5625 0.0781 -0.7188 L0.0781 -0.7188 Q0.0625 -0.7344 0.0625 -0.7344 Q0.0625 -0.75 0.0625 -0.75 Q0.0781 -0.75 0.125 -0.7031 Q0.1875 -0.6406 0.2188 -0.5625 Q0.2812 -0.4219 0.2812 -0.25 Z\"></path></g></g></svg>&nbsp;</span>。</p><p>(事实上，f满足上述微分方程，可以很容易地通过应用链式法则来证明。)</p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995480744296972","title":"多层感知器","versionId":"54225861024473355","lemmaId":10730,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":82859321,"name":"━╋独特","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1599617131,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p><img alt=\"\" class=\"fileimage kx_img ed_imgfloat_right\" img_height=\"248\" img_width=\"250\" titlename=\"一种能够计算XOR的双层神经网络。神经元内的数字表示每个神经元的显式阈值（可以将其提出来，使所有神经元具有相同的阈值，通常为1）。标注箭头的数字表示输入的权重。这个网络假设如果没有达到阈值，则输出0（不是-1）。注意，输入的底层并不总被认作一个真正的神经网络层。\" data-src=\"https://img01.sogoucdn.com/app/a/200698/sogou_science_14112\"> </p><p>这类网络由多层计算单元组成，通常以前馈方式相互连接。一层中的每个神经元都与下一层的神经元有直接的连接。在许多应用中，这些网络的单元将sigmoid函数用作激活函数。</p><p>神经网络的通用近似定理（Universal approximation theorem）指出，每个将实数区间映射到实数输出区间的连续函数，都可以由只有一个隐藏层的多层感知器任意逼近。这一结果适用于广泛的激活函数，例如sigmoid函数。</p><p>多层网络使用多种学习技术，最流行的是反向传播。这里，将输出值与正确答案进行比较，以计算某个预定义误差函数的值。通过各种技术，误差然后通过网络反馈。使用该信息，算法调整每个连接的权重，以便将误差函数值减少一些。在重复这个过程，并达到足够多的训练周期后，网络通常会收敛到计算误差很小的状态。在这种情况下，可以说网络已经学习了某个目标方程。为了适当地调整权重，我们应用了一种非线性优化的通用方法，称为梯度下降。为此，网络计算误差方程相对于网络权重的导数，并改变权重，使得误差减小(从而在误差方程的表面上下降)。因此，反向传播只能应用于具有可微分激活函数的网络。</p><p>一般来说，在测试样本上，如何来训练网络来取得良好的表现，也是一个非常微妙的问题，需要额外的技术。这对于只有非常有限数量的训练样本可用的情况尤其重要。<sup><a href=\"#quote_4\" class=\"kx_ref\">[4]</a></sup>一个危险在于网络对训练数据过度拟合，无法学习生成数据的真实统计过程。计算学习理论关注在有限的数据量上训练分类器。在神经网络的环境中，一种简单的启发式方法，称为早期停止（early stopping），通常可以确保网络很好地推广到不在训练集中的例子。</p><p>反向传播算法的其他典型问题是收敛速度和最终达到误差方程局部最小值的可能性。今天，有一些实用的方法使多层感知器中的反向传播成为许多机器学习任务的首选工具。</p><p>人们也可以使用一系列由某种媒介调节的独立神经网络，类似的行为也发生在大脑中。这些神经元可以独立地执行并处理一项大任务，最终可以将结果组合在一起。 <sup><a href=\"#quote_5\" class=\"kx_ref\">[5]</a></sup> </p>","pics":[{"originalUrl":"https://web.archive.org/web/20221025120000/https://img01.sogoucdn.com/app/a/200698/sogou_science_14112?w=250&h=248&titlename=%E4%B8%80%E7%A7%8D%E8%83%BD%E5%A4%9F%E8%AE%A1%E7%AE%97XOR%E7%9A%84%E5%8F%8C%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E3%80%82%E7%A5%9E%E7%BB%8F%E5%85%83%E5%86%85%E7%9A%84%E6%95%B0%E5%AD%97%E8%A1%A8%E7%A4%BA%E6%AF%8F%E4%B8%AA%E7%A5%9E%E7%BB%8F%E5%85%83%E7%9A%84%E6%98%BE%E5%BC%8F%E9%98%88%E5%80%BC%EF%BC%88%E5%8F%AF%E4%BB%A5%E5%B0%86%E5%85%B6%E6%8F%90%E5%87%BA%E6%9D%A5%EF%BC%8C%E4%BD%BF%E6%89%80%E6%9C%89%E7%A5%9E%E7%BB%8F%E5%85%83%E5%85%B7%E6%9C%89%E7%9B%B8%E5%90%8C%E7%9A%84%E9%98%88%E5%80%BC%EF%BC%8C%E9%80%9A%E5%B8%B8%E4%B8%BA1%EF%BC%89%E3%80%82%E6%A0%87%E6%B3%A8%E7%AE%AD%E5%A4%B4%E7%9A%84%E6%95%B0%E5%AD%97%E8%A1%A8%E7%A4%BA%E8%BE%93%E5%85%A5%E7%9A%84%E6%9D%83%E9%87%8D%E3%80%82%E8%BF%99%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%81%87%E8%AE%BE%E5%A6%82%E6%9E%9C%E6%B2%A1%E6%9C%89%E8%BE%BE%E5%88%B0%E9%98%88%E5%80%BC%EF%BC%8C%E5%88%99%E8%BE%93%E5%87%BA0%EF%BC%88%E4%B8%8D%E6%98%AF-1%EF%BC%89%E3%80%82%E6%B3%A8%E6%84%8F%EF%BC%8C%E8%BE%93%E5%85%A5%E7%9A%84%E5%BA%95%E5%B1%82%E5%B9%B6%E4%B8%8D%E6%80%BB%E8%A2%AB%E8%AE%A4%E4%BD%9C%E4%B8%80%E4%B8%AA%E7%9C%9F%E6%AD%A3%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%B1%82%E3%80%82","url":"https://web.archive.org/web/20221025120000/https://img01.sogoucdn.com/app/a/200698/sogou_science_14112","rw":250,"rh":248,"title":"一种能够计算XOR的双层神经网络。神经元内的数字表示每个神经元的显式阈值（可以将其提出来，使所有神经元具有相同的阈值，通常为1）。标注箭头的数字表示输入的权重。这个网络假设如果没有达到阈值，则输出0（不是-1）。注意，输入的底层并不总被认作一个真正的神经网络层。","alt":null,"width":0,"height":0}],"card":null,"references":[],"versionCount":0}],"references":[{"id":1,"type":"book","title":"Zell, Andreas (1994). Simulation Neuronaler Netze [Simulation of Neural Networks] (in German) (1st ed.). Addison-Wesley. p. 73. ISBN 3-89319-554-8.CS1 maint: Unrecognized language (link)","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":2,"type":"book","title":"\"Deep learning in neural networks: An overview\". Neural Networks (in 英语). 61: 85–117. 2015-01-01. arXiv:1404.7828. doi:10.1016/j.neunet.2014.09.003. ISSN 0893-6080.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":3,"type":"book","title":"Auer, Peter; Harald Burgsteiner; Wolfgang Maass (2008). \"A learning rule for very simple universal approximators consisting of a single layer of perceptrons\" (PDF). Neural Networks. 21 (5): 786–795. doi:10.1016/j.neunet.2007.12.036. PMID 18249524.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":4,"type":"book","title":"Roman M. Balabin; Ravilya Z. Safieva; Ekaterina I. Lomakina (2007). \"Comparison of linear and nonlinear calibration models based on near infrared (NIR) spectroscopy data for gasoline properties prediction\". Chemometr Intell Lab. 88 (2): 183–188. doi:10.1016/j.chemolab.2007.04.006.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":5,"type":"book","title":"Tahmasebi, Pejman; Hezarkhani, Ardeshir (21 January 2011). \"Application of a Modular Feedforward Neural Network for Grade Estimation\". Natural Resources Research. 20 (1): 25–32. doi:10.1007/s11053-011-9135-3.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false}],"recommendReferences":null,"auditState":2,"lemmaLevel":1,"origin":0,"originEnTitle":null,"originZhTitle":null,"pv":2038,"auditType":0,"synonyms":null,"showEditTime":"2019.12.13 18:46","auditors":[{"uid":0,"name":"Ki.κe","pic":"https://web.archive.org/web/20221025120000/https://wx.qlogo.cn/mmopen/vi_32/y67kfr32Doib4wg71Jiau7jVWvharic3nRKgdRRQSl6koeQJCo0GQs2Krw0vwdFRsOWnHIQOwAZsSg5lIkIrFCOcQ/132","introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":"","jobBrief":"","role":0,"roleName":null,"title":"","professionalTitle":null,"phoneNo":null,"editable":true,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false}],"hasZhishiNav":false,"auditInfos":{},"isHistory":false};</script><script crossorigin="anonymous" src="./730.前馈神经网络 - 搜狗科学百科_files/aegis.min.js.download"></script><script crossorigin="anonymous" src="./730.前馈神经网络 - 搜狗科学百科_files/main_2020092401.js.download"></script><script crossorigin="anonymous" src="./730.前馈神经网络 - 搜狗科学百科_files/react.production.min.js.download"></script><script crossorigin="anonymous" src="./730.前馈神经网络 - 搜狗科学百科_files/react-dom.production.min.js.download"></script><script crossorigin="anonymous" src="./730.前馈神经网络 - 搜狗科学百科_files/jquery-1.11.1.min.js.download"></script><script crossorigin="anonymous" src="./730.前馈神经网络 - 搜狗科学百科_files/main_2022062701.js.download"></script><script crossorigin="anonymous" src="./730.前馈神经网络 - 搜狗科学百科_files/main_66bbe21.js.download"></script><script crossorigin="anonymous" src="./730.前馈神经网络 - 搜狗科学百科_files/react.production.min.js.download"></script><script crossorigin="anonymous" src="./730.前馈神经网络 - 搜狗科学百科_files/react-dom.production.min.js.download"></script><script crossorigin="anonymous" src="./730.前馈神经网络 - 搜狗科学百科_files/main_edf0f08.js.download"></script>
</body></html>