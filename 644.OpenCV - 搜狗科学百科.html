<!DOCTYPE html>
<!-- saved from url=(0083)https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm -->
<html class="" data-reactroot=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script src="./644.OpenCV - 搜狗科学百科_files/analytics.js.download" type="text/javascript"></script>
<script type="text/javascript">window.addEventListener('DOMContentLoaded',function(){var v=archive_analytics.values;v.service='wb';v.server_name='wwwb-app228.us.archive.org';v.server_ms=384;archive_analytics.send_pageview({});});</script>
<script type="text/javascript" src="./644.OpenCV - 搜狗科学百科_files/bundle-playback.js.download" charset="utf-8"></script>
<script type="text/javascript" src="./644.OpenCV - 搜狗科学百科_files/wombat.js.download" charset="utf-8"></script>
<script type="text/javascript">
  __wm.init("https://web.archive.org/web");
  __wm.wombat("https://baike.sogou.com/kexue/d10644.htm","20221025090252","https://web.archive.org/","web","/_static/",
	      "1666688572");
</script>
<link rel="stylesheet" type="text/css" href="./644.OpenCV - 搜狗科学百科_files/banner-styles.css">
<link rel="stylesheet" type="text/css" href="./644.OpenCV - 搜狗科学百科_files/iconochive.css">
<!-- End Wayback Rewrite JS Include -->
<meta name="save" content="history"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="baidu-site-verification" content="VWGb6TyYx8"><meta content="OpenCV - 搜狗科学百科" name="keywords"><meta content="搜狗科学百科是一部有着平等、协作、分享、自由理念的网络科学全书，为每一个互联网用户创造一个涵盖所有领域知识、服务的中文知识性平台。" name="description"><meta http-equiv="x-dns-prefetch-control" content="on"><meta name="server" baike="235" ip="210" env="online"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025090252/https://cache.soso.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025090252/https://hhy.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025090252/https://pic.baike.soso.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025090252/https://ugc.qpic.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025090252/https://xui.ptlogin2.qq.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025090252/https://q1.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025090252/https://q2.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025090252/https://q3.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025090252/https://q4.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025090252/https://q.qlogo.cn/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025090252/https://img01.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025090252/https://img02.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025090252/https://img03.sogoucdn.com/"><link rel="dns-prefetch" href="https://web.archive.org/web/20221025090252/https://img04.sogoucdn.com/"><link rel="Shortcut Icon" href="https://web.archive.org/web/20221025090252im_/https://www.sogou.com/images/logo/new/favicon.ico?v=4"><link rel="Bookmark" href="https://www.sogou.com/images/logo/new/favicon.ico?v=4"><link href="./644.OpenCV - 搜狗科学百科_files/base_b849887.css" rel="stylesheet"><link href="./644.OpenCV - 搜狗科学百科_files/detail_378aed5.css" rel="stylesheet"><link href="./644.OpenCV - 搜狗科学百科_files/inviteAudit_7894507.css" rel="stylesheet"><link rel="stylesheet" href="./644.OpenCV - 搜狗科学百科_files/highlight.min.css"><title>OpenCV - 搜狗科学百科</title><style>.onekey-close {
	position: absolute;
	top: 16px;
	right: 16px;
	width: 24px;
	height: 24px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	text-indent: -999em;
	background-size: 84px;
	background-position: -63px 0;
}

.onekey-login {
	position: absolute;
	top: 16.4%;
	left: 0;
	right: 0;
	width: 100%;
}

/* .onekey-login-img {
    width: 75px;
    height: 75px;
    background: url("https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/images/sprite_wap_baike.png") no-repeat;
    background-size: 100px 91px;
    background-position: 0 0;
    background-repeat: no-repeat;
    margin: 0 auto;
} */

.onekey-login-title {
	text-align: center;
	padding-bottom: 3px;
	font-size: 21px;
	font-weight: bold;
	line-height: 30px;
	color: #000;
}

.onekey-login-txt {
	text-align: center;
	font-family: PingFangSC;
	font-size: 14px;
	line-height: 20px;
	color: #8f8f8f;
}

.onekey-login-qq,
.onekey-login-wx,
.onekey-login-phone {
	display: block;
	width: 245px;
	height: 54px;
	border-radius: 45px;
	text-align: center;

	margin: 0 auto;
	font-size: 17px;
	line-height: 24px;
	color: #000;
	/* padding: 16px 77px; */
	border-radius: 12px;
	border: solid 1px #e0e0e0;
}
.onekey-qq-content,
.onekey-vx-content,
.onekey-phone-content {
	display: inline-block;
	margin-top: 16px;
}
.onekey-qq-content {
	padding: 0 5px;
}

.onekey-login-qq {
	margin-top: 48px;
	margin-bottom: 24px;
}

.onekey-login-qq:before {
	display: inline-block;
	content: "";
	width: 20px;
	height: 20px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 80px;
	background-position: -20px 0;
	vertical-align: top;
	margin: 17px 8px 0 0;
}

.onekey-login-wx {
	margin-bottom: 24px;
}

.onekey-login-wx:before {
	display: inline-block;
	content: "";
	width: 21px;
	height: 21px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 84px;
	background-position: 0 0;
	vertical-align: top;
	margin: 17px 10px 0 0;
}

.onekey-login-phone {
}

.onekey-login-phone:before {
	display: inline-block;
	content: "";
	width: 21px;
	height: 21px;
	background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/sprite_wap_baike_37443f3.png) no-repeat;
	background-size: 84px;
	background-position: -42px 0;
	vertical-align: top;
	margin: 17px 10px 0 0;
}

.onekey-fixed {
	z-index: 100;
	position: fixed;
	top: 0;
	bottom: 0;
	left: 0;
	right: 0;
	background: #fff;
	width: 100%;
	height: 100%;
}

.onekey-fixed.forbid {
	z-index: 100;
	position: fixed;
	top: auto;
	bottom: 68px;
	left: 9%;
	right: 0;
	background: rgba(0, 0, 0, 0.7);
	width: 82%;
	height: 43px;
	border-radius: 25px;
	color: #ffffff;
}
.onekey-login-title.forbid {
	text-align: center;
	padding-bottom: 3px;
	font-size: 14px;
	font-weight: normal;
	line-height: 30px;
	color: white;
}
</style><style>#login_mask {
  background: #000;
  opacity: 0.5;
  filter: alpha(opacity=50);
  position: fixed;
  /*fixed好像在哪个IE上有BUG，先用用*/
  left: 0;
  top: 0;
  z-index: 999;
  height: 100%;
}

#login_iframe_container {
  position: fixed;
  width: 550px;
  height: 360px;
  z-index: 1020;
  background-color: #ffffff;
}

@media screen and (max-width: 828px) {
  #login_iframe_container {
    top: 50% !important;
    left: 50% !important;
    transform: translate(-50%, -50%);
  }
}

#login_iframe_container.new-login {
  width: 550px;
  height: 360px;
  background-image: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/background_2a4a8a6.png);
}

#login_iframe_container.new-login.no-bg {
  background: #fff;
}

#login_iframe_container.new-login .login-title {
  width: 100%;
  height: 42px;
  line-height: 42px;
  text-align: center;
  font-size: 30px;
  letter-spacing: 0.19px;
  color: #ffffff;
  margin-top: 62px;
}
#login_iframe_container.new-login .forbid-title {
  width: 100%;
  height: 42px;
  line-height: 42px;
  text-align: center;
  font-size: 24px;
  letter-spacing: 0.19px;
  color: #333333;
  margin-top: 150px;
}

#login_iframe_container.new-login.no-bg .login-title {
  color: #333333;
}

#login_iframe_container.new-login .login-subtitle {
  width: 100%;
  height: 18px;
  line-height: 18px;
  font-size: 13px;
  letter-spacing: 0.08px;
  color: #ffffff;
  text-align: center;
  margin-top: 9px;
  margin-bottom: 43px;
}

#login_iframe_container.new-login.no-bg .login-subtitle {
  color: #999999;
}

#login_iframe_container.new-login .login-subtitle::before {
  content: '';
  display: inline-block;
  width: 10px;
  height: 1px;
  background-color: #ffffff;
  position: relative;
  top: -4px;
  left: -5px;
}

#login_iframe_container.new-login .login-subtitle::after {
  content: '';
  display: inline-block;
  width: 10px;
  height: 1px;
  background-color: #ffffff;
  position: relative;
  top: -4px;
  left: 5px;
}

#login_iframe_container.new-login.no-bg .login-subtitle::before {
  background-color: #999999;
}

#login_iframe_container.new-login.no-bg .login-subtitle::after {
  background-color: #999999;
}

#login_iframe_container.new-login .close-btn {
  position: absolute;
  top: 20px;
  right: 20px;
  width: 12px;
  height: 12px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -59px -10px;
  background-size: 81px 91px;
  cursor: pointer;
}

#login_iframe_container.new-login .login-btn {
  width: 220px;
  height: 47px;
  border-radius: 24px;
  border: solid 1px #dddddd;
  background-color: #ffffff;
  margin: 0 auto;
  margin-top: 28px;
  position: relative;
  display: block;
}

#login_iframe_container.new-login .login-btn .login-icon {
  position: absolute;
}

#login_iframe_container.new-login .login-btn .login-text {
  width: 61px;
  height: 47px;
  line-height: 47px;
  vertical-align: middle;
  font-size: 15px;
  letter-spacing: 0.1px;
  color: #666666;
  position: absolute;
  right: 62px;
}

#login_iframe_container.new-login .login-btn.qq-btn .login-icon {
  width: 22px;
  height: 27px;
  top: 10px;
  left: 67px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -10px -54px;
  background-size: 81px 91px;
}

#login_iframe_container.new-login .login-btn.qq-btn .login-text {
  right: 59px;
}

#login_iframe_container.new-login .login-btn.wechat-btn .login-icon {
  width: 29px;
  height: 24px;
  top: 12px;
  left: 62px;
  background: url(//web.archive.org/web/20221025113757/https://hhy.sogoucdn.com/js/common/hhy/login-sprites_e3853e5.png) -10px -10px;
  background-size: 81px 91px;
}</style><style>/* -- container -- */
.rodal,
.rodal-mask {
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: 100;
}

.rodal {
    position: fixed;
}

/* -- mask -- */
.rodal-mask {
    position: fixed;
    background: rgba(0, 0, 0, .5);
}

/* -- dialog -- */
.rodal-dialog {
    position: absolute;
    z-index: 101;
    background: #fff;
    border-radius: 3px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, .2);
}

.rodal-center {
    top: 50%;
    transform: translateY(-50%);
    left: 0;
    right: 0;
    margin: 0 auto;
}

.rodal-bottom {
    left: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

.rodal-top {
    left: 0;
    right: 0;
    top: 0;
    margin: auto;
}

.rodal-left {
    top: 0;
    left: 0;
    bottom: 0;
    margin: auto;
}

.rodal-right {
    top: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

/* -- close button -- */
.rodal-close {
    position: absolute;
    cursor: pointer;
    top: 16px;
    right: 16px;
    width: 16px;
    height: 16px;
}

.rodal-close:before,
.rodal-close:after {
    position: absolute;
    content: '';
    height: 2px;
    width: 100%;
    top: 50%;
    left: 0;
    margin-top: -1px;
    background: #999;
    border-radius: 100%;
    -webkit-transition: background .2s;
    transition: background .2s;
}

.rodal-close:before {
    -webkit-transform: rotate(45deg);
    transform: rotate(45deg);
}

.rodal-close:after {
    -webkit-transform: rotate(-45deg);
    transform: rotate(-45deg);
}

.rodal-close:hover:before,
.rodal-close:hover:after {
    background: #333;
}

/* -- fade -- */
/* @-webkit-keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

@keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

.rodal-fade-enter {
    -webkit-animation: rodal-fade-enter both ease-in;
    animation: rodal-fade-enter both ease-in;
} */

@-webkit-keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

@keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

.rodal-fade-leave {
    -webkit-animation: rodal-fade-leave both ease-out;
    animation: rodal-fade-leave both ease-out;
}

/* -- zoom -- */
@-webkit-keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-enter {
    -webkit-animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-leave {
    -webkit-animation: rodal-zoom-leave both;
    animation: rodal-zoom-leave both;
}

/* -- slideDown -- */
@-webkit-keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-enter {
    -webkit-animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-leave {
    -webkit-animation: rodal-slideDown-leave both;
    animation: rodal-slideDown-leave both;
}

/* -- slideLeft -- */
@-webkit-keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-enter {
    -webkit-animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-leave {
    -webkit-animation: rodal-slideLeft-leave both;
    animation: rodal-slideLeft-leave both;
}

/* -- slideRight -- */
@-webkit-keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-enter {
    -webkit-animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-leave {
    -webkit-animation: rodal-slideRight-leave both;
    animation: rodal-slideRight-leave both;
}

/* -- slideUp -- */
@-webkit-keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-enter {
    -webkit-animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
    animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
}

@-webkit-keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-leave {
    -webkit-animation: rodal-slideUp-leave both;
    animation: rodal-slideUp-leave both;
}

/* -- flip -- */
@-webkit-keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

@keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

.rodal-flip-enter {
    -webkit-animation: rodal-flip-enter both ease-in;
    animation: rodal-flip-enter both ease-in;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

@-webkit-keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

@keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

.rodal-flip-leave {
    -webkit-animation: rodal-flip-leave both;
    animation: rodal-flip-leave both;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

/* -- rotate -- */
@-webkit-keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-enter {
    -webkit-animation: rodal-rotate-enter both;
    animation: rodal-rotate-enter both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

@-webkit-keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-leave {
    -webkit-animation: rodal-rotate-leave both;
    animation: rodal-rotate-leave both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

/* -- door -- */
@-webkit-keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

@keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

.rodal-door-enter {
    -webkit-animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

@keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

.rodal-door-leave {
    -webkit-animation: rodal-door-leave both;
    animation: rodal-door-leave both;
}</style><style>/* -- container -- */
.rodal,
.rodal-mask {
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: 100;
}

.rodal {
    position: fixed;
}

/* -- mask -- */
.rodal-mask {
    position: fixed;
    background: rgba(0, 0, 0, .5);
}

/* -- dialog -- */
.rodal-dialog {
    position: absolute;
    z-index: 101;
    background: #fff;
    border-radius: 3px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, .2);
}

.rodal-center {
    top: 50%;
    transform: translateY(-50%);
    left: 0;
    right: 0;
    margin: 0 auto;
}

.rodal-bottom {
    left: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

.rodal-top {
    left: 0;
    right: 0;
    top: 0;
    margin: auto;
}

.rodal-left {
    top: 0;
    left: 0;
    bottom: 0;
    margin: auto;
}

.rodal-right {
    top: 0;
    right: 0;
    bottom: 0;
    margin: auto;
}

/* -- close button -- */
.rodal-close {
    position: absolute;
    cursor: pointer;
    top: 16px;
    right: 16px;
    width: 16px;
    height: 16px;
}

.rodal-close:before,
.rodal-close:after {
    position: absolute;
    content: '';
    height: 2px;
    width: 100%;
    top: 50%;
    left: 0;
    margin-top: -1px;
    background: #999;
    border-radius: 100%;
    -webkit-transition: background .2s;
    transition: background .2s;
}

.rodal-close:before {
    -webkit-transform: rotate(45deg);
    transform: rotate(45deg);
}

.rodal-close:after {
    -webkit-transform: rotate(-45deg);
    transform: rotate(-45deg);
}

.rodal-close:hover:before,
.rodal-close:hover:after {
    background: #333;
}

/* -- fade -- */
/* @-webkit-keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

@keyframes rodal-fade-enter {
    from {
        opacity: 0;
    }
}

.rodal-fade-enter {
    -webkit-animation: rodal-fade-enter both ease-in;
    animation: rodal-fade-enter both ease-in;
} */

@-webkit-keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

@keyframes rodal-fade-leave {
    to {
        opacity: 0
    }
}

.rodal-fade-leave {
    -webkit-animation: rodal-fade-leave both ease-out;
    animation: rodal-fade-leave both ease-out;
}

/* -- zoom -- */
@-webkit-keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-enter {
    from {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-enter {
    -webkit-animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-zoom-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

@keyframes rodal-zoom-leave {
    to {
        -webkit-transform: scale3d(.3, .3, .3);
        transform: scale3d(.3, .3, .3);
    }
}

.rodal-zoom-leave {
    -webkit-animation: rodal-zoom-leave both;
    animation: rodal-zoom-leave both;
}

/* -- slideDown -- */
@-webkit-keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-enter {
    from {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-enter {
    -webkit-animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideDown-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

@keyframes rodal-slideDown-leave {
    to {
        -webkit-transform: translate3d(0, -100px, 0);
        transform: translate3d(0, -100px, 0);
    }
}

.rodal-slideDown-leave {
    -webkit-animation: rodal-slideDown-leave both;
    animation: rodal-slideDown-leave both;
}

/* -- slideLeft -- */
@-webkit-keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-enter {
    from {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-enter {
    -webkit-animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideLeft-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

@keyframes rodal-slideLeft-leave {
    to {
        -webkit-transform: translate3d(-150px, 0, 0);
        transform: translate3d(-150px, 0, 0);
    }
}

.rodal-slideLeft-leave {
    -webkit-animation: rodal-slideLeft-leave both;
    animation: rodal-slideLeft-leave both;
}

/* -- slideRight -- */
@-webkit-keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-enter {
    from {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-enter {
    -webkit-animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-slideRight-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

@keyframes rodal-slideRight-leave {
    to {
        -webkit-transform: translate3d(150px, 0, 0);
        transform: translate3d(150px, 0, 0);
    }
}

.rodal-slideRight-leave {
    -webkit-animation: rodal-slideRight-leave both;
    animation: rodal-slideRight-leave both;
}

/* -- slideUp -- */
@-webkit-keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-enter {
    from {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-enter {
    -webkit-animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
    animation: rodal-slideUp-enter both cubic-bezier(0.23, 1, 0.32, 1);
}

@-webkit-keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

@keyframes rodal-slideUp-leave {
    to {
        -webkit-transform: translate3d(0, 100px, 0);
        transform: translate3d(0, 100px, 0);
    }
}

.rodal-slideUp-leave {
    -webkit-animation: rodal-slideUp-leave both;
    animation: rodal-slideUp-leave both;
}

/* -- flip -- */
@-webkit-keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

@keyframes rodal-flip-enter {
    from {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 60deg);
    }

    70% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }
}

.rodal-flip-enter {
    -webkit-animation: rodal-flip-enter both ease-in;
    animation: rodal-flip-enter both ease-in;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

@-webkit-keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

@keyframes rodal-flip-leave {
    from {
        -webkit-transform: perspective(400px);
        transform: perspective(400px);
    }

    30% {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
        transform: perspective(400px) rotate3d(1, 0, 0, -15deg);
    }

    to {
        -webkit-transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
        transform: perspective(400px) rotate3d(1, 0, 0, 45deg);
    }
}

.rodal-flip-leave {
    -webkit-animation: rodal-flip-leave both;
    animation: rodal-flip-leave both;
    -webkit-backface-visibility: visible !important;
    backface-visibility: visible !important;
}

/* -- rotate -- */
@-webkit-keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-enter {
    from {
        -webkit-transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, -180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-enter {
    -webkit-animation: rodal-rotate-enter both;
    animation: rodal-rotate-enter both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

@-webkit-keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

@keyframes rodal-rotate-leave {
    to {
        -webkit-transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
        transform: rotate3d(0, 0, 1, 180deg) scale3d(.3, .3, .3);
    }
}

.rodal-rotate-leave {
    -webkit-animation: rodal-rotate-leave both;
    animation: rodal-rotate-leave both;
    -webkit-transform-origin: center;
    transform-origin: center;
}

/* -- door -- */
@-webkit-keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

@keyframes rodal-door-enter {
    from {
        -webkit-transform: scale3d(0, 1, 1);
        transform: scale3d(0, 1, 1);
    }
}

.rodal-door-enter {
    -webkit-animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
    animation: rodal-door-enter both cubic-bezier(0.4, 0, 0, 1.5);
}

@-webkit-keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

@keyframes rodal-door-leave {
    60% {
        -webkit-transform: scale3d(.01, 1, 1);
        transform: scale3d(.01, 1, 1);
    }

    to {
        -webkit-transform: scale3d(0, 1, .1);
        transform: scale3d(0, 1, .1);
    }
}

.rodal-door-leave {
    -webkit-animation: rodal-door-leave both;
    animation: rodal-door-leave both;
}</style></head><body class=""><!-- BEGIN WAYBACK TOOLBAR INSERT -->
<style type="text/css">
body {
  margin-top:0 !important;
  padding-top:0 !important;
  /*min-width:800px !important;*/
}
</style>
<script>__wm.rw(0);</script>
<div id="wm-ipp-base" lang="en" style="display: block; direction: ltr;">
</div><div id="wm-ipp-print">The Wayback Machine - https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm</div>
<script type="text/javascript">//<![CDATA[
__wm.bt(675,27,25,2,"web","https://baike.sogou.com/kexue/d10644.htm","20221025090252",1996,"/_static/",["/_static/css/banner-styles.css?v=S1zqJCYt","/_static/css/iconochive.css?v=qtvMKcIJ"], false);
  __wm.rw(1);
//]]></script>
<!-- END WAYBACK TOOLBAR INSERT --><script>window._gtag=window._gtag||{};window._gtag.shouldGrayed = false;if ('0afe6b6df10847d380234e180a00b134') window._gtag.traceId = '0afe6b6df10847d380234e180a00b134';if ({"illegality":true}) window.userInfo = {"illegality":true};</script><div class="topnavbox"><ul class="topnav"><li><a href="https://web.archive.org/web/20221025090252/https://www.sogou.com/web?query=">网页</a></li><li><a href="https://web.archive.org/web/20221025090252/https://weixin.sogou.com/weixin?p=75351201">微信</a></li><li><a href="https://web.archive.org/web/20221025090252/https://zhihu.sogou.com/zhihu?p=75351218">知乎</a></li><li><a href="https://web.archive.org/web/20221025090252/https://pic.sogou.com/pics?query=">图片</a></li><li><a href="https://web.archive.org/web/20221025090252/https://v.sogou.com/v?query=">视频</a></li><li><a href="https://web.archive.org/web/20221025090252/https://mingyi.sogou.com/">医疗</a></li><li class="cur"><strong>科学</strong></li><li><a href="https://web.archive.org/web/20221025090252/https://hanyu.sogou.com/">汉语</a></li><li><a href="https://web.archive.org/web/20221025090252/https://wenwen.sogou.com/">问问</a></li><li><a href="https://web.archive.org/web/20221025090252/https://www.sogou.com/docs/more.htm">更多<span class="topraquo">»</span></a></li></ul></div><div id="header"><div class="header-wrap"><a class="header-logo" href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue"></a><div class="header-search"><div class="querybox" id="suggBox"><form><input id="searchInput" class="query" type="text" placeholder="搜科学领域专业百科词条" name="query" autocomplete="off" value=""><a href="javascript:;" class="query-search"></a></form></div></div><div class="header-rgt"><span class="btn-header-rgt btn-edit" id="editLemma">创建</span><div class="header-user no-login"></div></div></div></div><div class="fixed-placeholder" style="visibility:none"></div><div id="container" class=""><div class="content lemma-level1"><div class="detail-title" id="abstract-title"><h1>OpenCV</h1><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#!" class="detail-edit">编辑</a></div><div class="section_content" data-id="14995442559353357"><div><p>开源计算机视觉(OpenCV)是一个主要针对实时计算机视觉的编程函数库<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_1" class="kx_ref">[1]</a></sup>。 最初由英特尔开发，后来由柳树车库（Willow Garage）支持，后来由伊塞兹（Itseez）支持(后来被英特尔收购<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_2" class="kx_ref">[2]</a></sup>)。该库是跨平台的，根据开源BSD许可证免费使用。 </p>
<p>OpenCV支持深度学习框架TensorFlow、Torch/PyTorch和Caffe<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_3" class="kx_ref">[3]</a></sup>。 </p></div></div><div id="catalog"><h2 class="title2">目录<a href="javascript:" class="detail-edit">编辑</a></h2><div class="catalog_wrap" style=""><ul class="catalog_list col2"><li><span class="order">1</span><a href="javascript:" data-level="1" data-id="14995442576130563">历史</a></li><li><span class="order">2</span><a href="javascript:" data-level="1" data-id="14995442576130564">应用</a></li><li><span class="order">3</span><a href="javascript:" data-level="1" data-id="14995442576130565">程序设计语言</a></li><li><span class="order">4</span><a href="javascript:" data-level="1" data-id="14995442592907779">硬件加速</a></li></ul><ul class="catalog_list col2"><li><span class="order">5</span><a href="javascript:" data-level="1" data-id="14995442592907780">操作系统支持</a></li><li><span class="order">6</span><a href="javascript:" data-level="1" data-id="references">参考文献</a></li></ul></div></div><div id="paragraphs"><div><div id="par_14995442576130563"><h2 class="title">1 历史<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>OpenCV项目于1999年正式启动，最初是英特尔的一项研究计划，旨在推进中央处理器密集型应用，是包括实时光线跟踪和3D显示墙在内的一系列项目的一部分<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_4" class="kx_ref">[4]</a></sup>。该项目的主要贡献者包括英特尔俄罗斯公司的许多优化专家，以及英特尔的性能库团队。在OpenCV的早期，项目的目标被描述为:<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_5" class="kx_ref">[5]</a></sup> </p> 
<ul>
 <li>通过为基本视觉基础设施提供开放且优化的代码来推进视觉研究。不再重新发明轮子。</li> 
 <li>通过提供开发人员可以构建的公共基础设施来传播视觉知识，以便代码更容易阅读和转移。</li> 
 <li>通过免费提供可移植的、性能优化的代码来推进基于视觉的商业应用程序——许可证不要求代码本身是开放的或自由的。</li>
</ul> 
<p>OpenCV的第一个alpha版本在2000年的IEEE计算机视觉和模式识别会议上向公众发布，2001年至2005年间发布了五个beta版本。第一个1.0版本于2006年发布。1.1版“预览版”于2008年10月发布。 </p>
<p>OpenCV的第二次主要发布是在2009年10月。OpenCV 2包括对C++接口的主要更改，旨在更容易、更类型安全的模式、新功能以及现有功能在性能方面的更好实现(尤其是在多核系统上)。现在每六个月发布一次<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_6" class="kx_ref">[6]</a></sup> 官方版本，开发工作现在由商业公司支持的独立俄罗斯团队完成。 </p>
<p>2012年8月，对OpenCV的支持被一个非营利基金会OpenCV.org接管<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_7" class="kx_ref">[7]</a></sup>， 该基金会拥有一个开发者和用户网站<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_8" class="kx_ref">[8]</a></sup>。 </p>
<p>2016年5月，英特尔签署了一项协议<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_9" class="kx_ref">[9]</a></sup>， 收购OpenCV的主要开发商伊塞兹<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_10" class="kx_ref">[10]</a></sup>。 </p></div></div><div id="par_14995442576130564"><h2 class="title">2 应用<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p></p><p></p><div class="text_img ed_imgfloat_right">
            <a class="ed_image_link lazyLoad" data-src="https://img02.sogoucdn.com/app/a/200698/sogou_science_13496" data-bigsrc="" title="点击查看大图" href="javascript:" data-observer="true"></a>
            <div class="text_img_title">运行OpenCV插件示例的openFrameworks</div>   
        </div> <p></p><p></p> 
<p>OpenCV的应用领域包括: </p> 
<ul>
 <li>2D和3D功能工具包</li> 
 <li>运动估计</li> 
 <li>面部识别系统</li> 
 <li>手势识别</li> 
 <li>人机交互</li> 
 <li>移动机器人</li> 
 <li>动作理解</li> 
 <li>物体识别</li> 
 <li>分割和识别</li> 
 <li>实体影像立体视觉:来自两个摄像机的深度感知</li> 
 <li>运动中的结构(SFM)</li> 
 <li>运动跟踪</li> 
 <li>增强现实</li>
</ul> 
<p>为了支持上述一些领域，OpenCV包括一个统计机器学习库，其中包含: </p> 
<ul>
 <li>提升(Boosting)</li> 
 <li>决策树学习</li> 
 <li>梯度提升树</li> 
 <li>期望最大化算法</li> 
 <li>k最近邻算法</li> 
 <li>朴素贝叶斯分类器</li> 
 <li>人工神经网络</li> 
 <li>随机森林</li> 
 <li>支持向量机(SVM)</li> 
 <li>深层神经网络(DNN)<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_11" class="kx_ref">[11]</a></sup></li>
</ul></div></div><div id="par_14995442576130565"><h2 class="title">3 程序设计语言<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>OpenCV是用C++编写的，它的主要接口是用C++编写的，但是它仍然保留了一个很广泛但不太全面的旧C接口。Python、Java和MATLAB/OCTAVE都有OpenCV 的API。这些接口的应用编程接口（API）可以在在线文档中找到<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_12" class="kx_ref">[12]</a></sup>。 现在OpenCV还提供诸如C#、Perl<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_13" class="kx_ref">[13]</a></sup>、 Ch <sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_14" class="kx_ref">[14]</a></sup>、 Haskell<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_15" class="kx_ref">[15]</a></sup> 和Ruby的接口，以鼓励更广泛的用户进行使用。 </p>
<p>从3.4版开始，OpenCV.js是一个针对网络平台的OpenCV函数的选定子集的JavaScript对应API<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_16" class="kx_ref">[16]</a></sup>。 </p>
<p>OpenCV中的所有新开发和算法现在都是在C++接口中开发的。 </p></div></div><div id="par_14995442592907779"><h2 class="title">4 硬件加速<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>如果库在系统上找到英特尔的集成性能原语，它将使用这些专有的优化例程来加速自身。 </p>
<p>自2010年9月以来，一个基于CUDA的图形处理器接口一直在支持中<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_17" class="kx_ref">[17]</a></sup>。 </p>
<p>基于OpenCL的图形处理器接口自2012年10月以来一直在开发中<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_18" class="kx_ref">[18]</a></sup>，2.4.13.3版本的文档可在docs.opencv.org 上找到<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_19" class="kx_ref">[19]</a></sup>。 </p></div></div><div id="par_14995442592907780"><h2 class="title">5 操作系统支持<a href="javascript:" class="detail-edit">编辑</a></h2><div class="section_content"><p>OpenCV运行在以下桌面操作系统上:Windows、Linux、macOS、FreeBSD、NetBSD、OpenBSD。OpenCV运行在以下移动操作系统上:安卓、iOS、梅莫<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_20" class="kx_ref">[20]</a></sup>、黑莓10<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_21" class="kx_ref">[21]</a></sup>。 用户可以从SourceForge获得官方发布版本，也可以从GitHub获得最新的源代码<sup><a href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/d10644.htm#quote_22" class="kx_ref">[22]</a></sup>。 OpenCV使用CMake。 </p></div></div></div></div><div id="references"><h2 class="title" id="par_references">参考文献</h2><ul class="references"><li id="quote_1"><span class="references-num">[1]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Pulli, Kari; Baksheev, Anatoly; Kornyakov, Kirill; Eruhimov, Victor (1 April 2012). "Realtime Computer Vision with OpenCV". Queue. pp. 40:40–40:56. doi:10.1145/2181796.2206309..</span></p></li><li id="quote_2"><span class="references-num">[2]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Intel acquires Itseez: https://opencv.org/intel-acquires-itseez.html.</span></p></li><li id="quote_3"><span class="references-num">[3]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">https://web.archive.org/web/20221025090252/https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV.</span></p></li><li id="quote_4"><span class="references-num">[4]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Adrian Kaehler; Gary Bradski (14 December 2016). Learning OpenCV 3: Computer Vision in C++ with the OpenCV Library. O'Reilly Media. pp. 26ff. ISBN 978-1-4919-3800-3..</span></p></li><li id="quote_5"><span class="references-num">[5]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Bradski, Gary; Kaehler, Adrian (2008). Learning OpenCV: Computer vision with the OpenCV library. O'Reilly Media, Inc. p. 6..</span></p></li><li id="quote_6"><span class="references-num">[6]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">OpenCV change logs: http://code.opencv.org/projects/opencv/wiki/ChangeLog.</span></p></li><li id="quote_7"><span class="references-num">[7]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">OpenCV Developer Site: http://code.opencv.org.</span></p></li><li id="quote_8"><span class="references-num">[8]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">OpenCV User Site: http://opencv.org/.</span></p></li><li id="quote_9"><span class="references-num">[9]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Intel Acquires Computer Vision for IOT, Automotive | Intel Newsroom". Intel Newsroom (in 英语). Retrieved 2018-11-26..</span></p></li><li id="quote_10"><span class="references-num">[10]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">"Intel acquires Russian computer vision company Itseez". East-West Digital News (in 英语). 2016-05-31. Retrieved 2018-11-26..</span></p></li><li id="quote_11"><span class="references-num">[11]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">OpenCV: http://opencv.org/opencv-3-3.html.</span></p></li><li id="quote_12"><span class="references-num">[12]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">OpenCV C interface: http://docs.opencv.org.</span></p></li><li id="quote_13"><span class="references-num">[13]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">CPAN: http://search.cpan.org/~yuta/Cv-0.29/.</span></p></li><li id="quote_14"><span class="references-num">[14]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Ch OpenCV: http://www.softintegration.com/products/thirdparty/opencv/.</span></p></li><li id="quote_15"><span class="references-num">[15]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">The haskell-opencv project on Github: https://github.com/LumiGuide/haskell-opencv.</span></p></li><li id="quote_16"><span class="references-num">[16]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Introduction to OpenCV.js and Tutorials.</span></p></li><li id="quote_17"><span class="references-num">[17]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Cuda GPU port: http://opencv.org/platforms/cuda.html.</span></p></li><li id="quote_18"><span class="references-num">[18]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">OpenCL Announcement: http://opencv.org/opencv-v2-4-3rc-is-under-way.html.</span></p></li><li id="quote_19"><span class="references-num">[19]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">OpenCL-accelerated Computer Vision API Reference: http://docs.opencv.org/modules/ocl/doc/ocl.html.</span></p></li><li id="quote_20"><span class="references-num">[20]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">Maemo port: https://garage.maemo.org/projects/opencv.</span></p></li><li id="quote_21"><span class="references-num">[21]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">BlackBerry 10 (partial port): https://github.com/blackberry/OpenCV.</span></p></li><li id="quote_22"><span class="references-num">[22]</span><p><a class="ref-back-btn">^</a><span data-url="" class="">https://web.archive.org/web/20221025090252/https://github.com/Itseez/opencv.</span></p></li></ul></div><div class="read-num">阅读 <!-- -->1.7<!-- -->w</div></div><div class="right-side" id="rightSide"><div class="side" id="lemma-side"><div class="side-title">版本记录</div><ul class="side-lst"><li><p class="side-lst-txt">暂无</p></li></ul><div class="user-card userCard"></div></div><div class="side"><div class="side-event"></div></div></div></div><div class="footer-box"><div id="footer"><div class="footer-logo-wrap"><div class="footer-logo"></div><div class="footer-logo-text">知识·传播·科普</div></div><div class="footer-info">本网站内容采用<a target="_blank" href="https://web.archive.org/web/20221025090252/https://creativecommons.org/licenses/by-sa/3.0/deed.zh?tdsourcetag=s_pctim_aiomsg">CC-BY-SA 3.0</a>授权</div><div class="footer-btn-wrap"><a target="_blank" href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/help/#user_protocol">用户协议</a><a target="_blank" href="https://web.archive.org/web/20221025090252/http://www.sogou.com/docs/terms.htm?v=1">免责声明</a><a target="_blank" href="https://web.archive.org/web/20221025090252/http://corp.sogou.com/private.html">隐私政策</a><a target="_blank" href="https://web.archive.org/web/20221025090252/https://baike.sogou.com/kexue/intro.htm">关于我们</a></div></div></div><script>window.lemmaInfo ={"lemmaId":"10644","versionId":"14995442559353349","title":"OpenCV","subtitle":"","abstracts":{"paragraphId":"14995442559353357","title":"简介","versionId":"14995442559353350","lemmaId":10644,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233979,"comment":null,"dependVersionId":0,"contentType":2,"content":"<p>开源计算机视觉(OpenCV)是一个主要针对实时计算机视觉的编程函数库<sup><a href=\"#quote_1\" class=\"kx_ref\">[1]</a></sup>。 最初由英特尔开发，后来由柳树车库（Willow Garage）支持，后来由伊塞兹（Itseez）支持(后来被英特尔收购<sup><a href=\"#quote_2\" class=\"kx_ref\">[2]</a></sup>)。该库是跨平台的，根据开源BSD许可证免费使用。 </p>\n<p>OpenCV支持深度学习框架TensorFlow、Torch/PyTorch和Caffe<sup><a href=\"#quote_3\" class=\"kx_ref\">[3]</a></sup>。 </p>","pics":null,"card":null,"references":[],"versionCount":0},"card":{"paragraphId":"14995442576130562","title":"基本信息","versionId":"14995442559353351","lemmaId":0,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233979,"comment":null,"dependVersionId":0,"contentType":3,"content":"","pics":null,"card":{"cardItems":[{"key":"原作者","value":"Intel Corporation, Willow Garage, Itseez"},{"key":"初始版本","value":"2000年6月，​19 years ago"},{"key":"稳定版本","value":"4.0.1 （2018年12月22日，​11 months ago ）"},{"key":"源代码库","value":"<ul>\n <li>github.com/opencv/opencv</li>\n</ul>"},{"key":"编程语言","value":"C/C++"},{"key":"操作系统","value":"Cross-platform"},{"key":"文件大小","value":"~200 MB"},{"key":"类型","value":"Library"},{"key":"许可协议","value":"BSD license"},{"key":"网站","value":"opencv.org"}]},"references":[],"versionCount":0},"categories":[{"id":14,"name":"电子与通信技术","parents":[]}],"creator":{"uid":10145103,"name":"柚子otto","pic":"https://web.archive.org/web/20221025090252/https://img02.sogoucdn.com/app/a/200698/1152_1152_1864088_20200427232849-1518843971.png","introduction":"","educations":[{"schoolName":"中国地质大学（北京）","major":"","degree":"本科","universityId":22,"universityLogo":"https://web.archive.org/web/20221025090252/https://img01.sogoucdn.com/app/a/200943/d3465c1c-6011-11e9-b353-fc4dd4f70029","majorLevel1":"理学","majorLevel2":"地理学","majorLevel3":"地图学与地理信息系统","majorLevel1Id":1,"majorLevel2Id":103,"majorLevel3Id":109,"state":"毕业","lab":"","researchField":""}],"jobs":[{"company":"搜狗","title":"产品经理"}],"works":null,"educationBrief":"中国地质大学（北京）","jobBrief":"产品经理","role":0,"roleName":null,"title":"中国地质大学（北京） · 地理学本科","professionalTitle":null,"phoneNo":null,"editable":true,"partnerId":139,"partnerIdCreateTime":1595844881,"partnerIdPoped":true},"createTime":1568626690,"editor":{"uid":10145103,"name":"柚子otto","pic":"https://web.archive.org/web/20221025090252/https://img02.sogoucdn.com/app/a/200698/1152_1152_1864088_20200427232849-1518843971.png","introduction":"","educations":[{"schoolName":"中国地质大学（北京）","major":"","degree":"本科","universityId":22,"universityLogo":"https://web.archive.org/web/20221025090252/https://img01.sogoucdn.com/app/a/200943/d3465c1c-6011-11e9-b353-fc4dd4f70029","majorLevel1":"理学","majorLevel2":"地理学","majorLevel3":"地图学与地理信息系统","majorLevel1Id":1,"majorLevel2Id":103,"majorLevel3Id":109,"state":"毕业","lab":"","researchField":""}],"jobs":[{"company":"搜狗","title":"产品经理"}],"works":null,"educationBrief":"中国地质大学（北京）","jobBrief":"产品经理","role":0,"roleName":null,"title":"中国地质大学（北京） · 地理学本科","professionalTitle":null,"phoneNo":null,"editable":true,"partnerId":139,"partnerIdCreateTime":1595844881,"partnerIdPoped":true},"editTime":1576233979,"state":1,"versionCount":1,"upNum":3,"downNum":0,"pics":[{"originalUrl":"https://web.archive.org/web/20221025090252/https://img02.sogoucdn.com/app/a/200698/sogou_science_13496?w=300&h=336&titlename=%E8%BF%90%E8%A1%8COpenCV%E6%8F%92%E4%BB%B6%E7%A4%BA%E4%BE%8B%E7%9A%84openFrameworks","url":"https://web.archive.org/web/20221025090252/https://img02.sogoucdn.com/app/a/200698/sogou_science_13496","rw":300,"rh":336,"title":"运行OpenCV插件示例的openFrameworks","alt":null,"width":0,"height":0}],"catalogs":[{"level":1,"title":"历史","paragraphId":"14995442576130563","subCatalogs":null},{"level":1,"title":"应用","paragraphId":"14995442576130564","subCatalogs":null},{"level":1,"title":"程序设计语言","paragraphId":"14995442576130565","subCatalogs":null},{"level":1,"title":"硬件加速","paragraphId":"14995442592907779","subCatalogs":null},{"level":1,"title":"操作系统支持","paragraphId":"14995442592907780","subCatalogs":null},{"level":1,"title":"参考文献","paragraphId":"-1","subCatalogs":null}],"paragraphs":[{"paragraphId":"14995442576130563","title":"历史","versionId":"14995442559353352","lemmaId":10644,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233979,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>OpenCV项目于1999年正式启动，最初是英特尔的一项研究计划，旨在推进中央处理器密集型应用，是包括实时光线跟踪和3D显示墙在内的一系列项目的一部分<sup><a href=\"#quote_4\" class=\"kx_ref\">[4]</a></sup>。该项目的主要贡献者包括英特尔俄罗斯公司的许多优化专家，以及英特尔的性能库团队。在OpenCV的早期，项目的目标被描述为:<sup><a href=\"#quote_5\" class=\"kx_ref\">[5]</a></sup> </p> \n<ul>\n <li>通过为基本视觉基础设施提供开放且优化的代码来推进视觉研究。不再重新发明轮子。</li> \n <li>通过提供开发人员可以构建的公共基础设施来传播视觉知识，以便代码更容易阅读和转移。</li> \n <li>通过免费提供可移植的、性能优化的代码来推进基于视觉的商业应用程序——许可证不要求代码本身是开放的或自由的。</li>\n</ul> \n<p>OpenCV的第一个alpha版本在2000年的IEEE计算机视觉和模式识别会议上向公众发布，2001年至2005年间发布了五个beta版本。第一个1.0版本于2006年发布。1.1版“预览版”于2008年10月发布。 </p>\n<p>OpenCV的第二次主要发布是在2009年10月。OpenCV 2包括对C++接口的主要更改，旨在更容易、更类型安全的模式、新功能以及现有功能在性能方面的更好实现(尤其是在多核系统上)。现在每六个月发布一次<sup><a href=\"#quote_6\" class=\"kx_ref\">[6]</a></sup> 官方版本，开发工作现在由商业公司支持的独立俄罗斯团队完成。 </p>\n<p>2012年8月，对OpenCV的支持被一个非营利基金会OpenCV.org接管<sup><a href=\"#quote_7\" class=\"kx_ref\">[7]</a></sup>， 该基金会拥有一个开发者和用户网站<sup><a href=\"#quote_8\" class=\"kx_ref\">[8]</a></sup>。 </p>\n<p>2016年5月，英特尔签署了一项协议<sup><a href=\"#quote_9\" class=\"kx_ref\">[9]</a></sup>， 收购OpenCV的主要开发商伊塞兹<sup><a href=\"#quote_10\" class=\"kx_ref\">[10]</a></sup>。 </p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995442576130564","title":"应用","versionId":"14995442559353353","lemmaId":10644,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233979,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p></p><p><img alt=\"\" class=\"fileimage kx_img ed_imgfloat_right\" img_height=\"336\" img_width=\"300\" titlename=\"运行OpenCV插件示例的openFrameworks\" data-src=\"https://img02.sogoucdn.com/app/a/200698/sogou_science_13496\"> </p><p></p> \n<p>OpenCV的应用领域包括: </p> \n<ul>\n <li>2D和3D功能工具包</li> \n <li>运动估计</li> \n <li>面部识别系统</li> \n <li>手势识别</li> \n <li>人机交互</li> \n <li>移动机器人</li> \n <li>动作理解</li> \n <li>物体识别</li> \n <li>分割和识别</li> \n <li>实体影像立体视觉:来自两个摄像机的深度感知</li> \n <li>运动中的结构(SFM)</li> \n <li>运动跟踪</li> \n <li>增强现实</li>\n</ul> \n<p>为了支持上述一些领域，OpenCV包括一个统计机器学习库，其中包含: </p> \n<ul>\n <li>提升(Boosting)</li> \n <li>决策树学习</li> \n <li>梯度提升树</li> \n <li>期望最大化算法</li> \n <li>k最近邻算法</li> \n <li>朴素贝叶斯分类器</li> \n <li>人工神经网络</li> \n <li>随机森林</li> \n <li>支持向量机(SVM)</li> \n <li>深层神经网络(DNN)<sup><a href=\"#quote_11\" class=\"kx_ref\">[11]</a></sup></li>\n</ul>","pics":[{"originalUrl":"https://web.archive.org/web/20221025090252/https://img02.sogoucdn.com/app/a/200698/sogou_science_13496?w=300&h=336&titlename=%E8%BF%90%E8%A1%8COpenCV%E6%8F%92%E4%BB%B6%E7%A4%BA%E4%BE%8B%E7%9A%84openFrameworks","url":"https://web.archive.org/web/20221025090252/https://img02.sogoucdn.com/app/a/200698/sogou_science_13496","rw":300,"rh":336,"title":"运行OpenCV插件示例的openFrameworks","alt":null,"width":0,"height":0}],"card":null,"references":[],"versionCount":0},{"paragraphId":"14995442576130565","title":"程序设计语言","versionId":"14995442559353354","lemmaId":10644,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233979,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>OpenCV是用C++编写的，它的主要接口是用C++编写的，但是它仍然保留了一个很广泛但不太全面的旧C接口。Python、Java和MATLAB/OCTAVE都有OpenCV 的API。这些接口的应用编程接口（API）可以在在线文档中找到<sup><a href=\"#quote_12\" class=\"kx_ref\">[12]</a></sup>。 现在OpenCV还提供诸如C#、Perl<sup><a href=\"#quote_13\" class=\"kx_ref\">[13]</a></sup>、 Ch <sup><a href=\"#quote_14\" class=\"kx_ref\">[14]</a></sup>、 Haskell<sup><a href=\"#quote_15\" class=\"kx_ref\">[15]</a></sup> 和Ruby的接口，以鼓励更广泛的用户进行使用。 </p>\n<p>从3.4版开始，OpenCV.js是一个针对网络平台的OpenCV函数的选定子集的JavaScript对应API<sup><a href=\"#quote_16\" class=\"kx_ref\">[16]</a></sup>。 </p>\n<p>OpenCV中的所有新开发和算法现在都是在C++接口中开发的。 </p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995442592907779","title":"硬件加速","versionId":"14995442559353355","lemmaId":10644,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233979,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>如果库在系统上找到英特尔的集成性能原语，它将使用这些专有的优化例程来加速自身。 </p>\n<p>自2010年9月以来，一个基于CUDA的图形处理器接口一直在支持中<sup><a href=\"#quote_17\" class=\"kx_ref\">[17]</a></sup>。 </p>\n<p>基于OpenCL的图形处理器接口自2012年10月以来一直在开发中<sup><a href=\"#quote_18\" class=\"kx_ref\">[18]</a></sup>，2.4.13.3版本的文档可在docs.opencv.org 上找到<sup><a href=\"#quote_19\" class=\"kx_ref\">[19]</a></sup>。 </p>","pics":null,"card":null,"references":[],"versionCount":0},{"paragraphId":"14995442592907780","title":"操作系统支持","versionId":"14995442559353356","lemmaId":10644,"createType":0,"creator":{"uid":0,"name":null,"pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"createTime":0,"versionEditor":{"uid":10145103,"name":"科学百科编辑组","pic":null,"introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":null,"jobBrief":null,"role":0,"roleName":null,"title":null,"professionalTitle":null,"phoneNo":null,"editable":false,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false},"editTime":1576233979,"comment":null,"dependVersionId":0,"contentType":1,"content":"<p>OpenCV运行在以下桌面操作系统上:Windows、Linux、macOS、FreeBSD、NetBSD、OpenBSD。OpenCV运行在以下移动操作系统上:安卓、iOS、梅莫<sup><a href=\"#quote_20\" class=\"kx_ref\">[20]</a></sup>、黑莓10<sup><a href=\"#quote_21\" class=\"kx_ref\">[21]</a></sup>。 用户可以从SourceForge获得官方发布版本，也可以从GitHub获得最新的源代码<sup><a href=\"#quote_22\" class=\"kx_ref\">[22]</a></sup>。 OpenCV使用CMake。 </p>","pics":null,"card":null,"references":[],"versionCount":0}],"references":[{"id":1,"type":"book","title":"Pulli, Kari; Baksheev, Anatoly; Kornyakov, Kirill; Eruhimov, Victor (1 April 2012). \"Realtime Computer Vision with OpenCV\". Queue. pp. 40:40–40:56. doi:10.1145/2181796.2206309.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":2,"type":"book","title":"Intel acquires Itseez: https://opencv.org/intel-acquires-itseez.html","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":3,"type":"book","title":"https://web.archive.org/web/20221025090252/https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":4,"type":"book","title":"Adrian Kaehler; Gary Bradski (14 December 2016). Learning OpenCV 3: Computer Vision in C++ with the OpenCV Library. O'Reilly Media. pp. 26ff. ISBN 978-1-4919-3800-3.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":5,"type":"book","title":"Bradski, Gary; Kaehler, Adrian (2008). Learning OpenCV: Computer vision with the OpenCV library. O'Reilly Media, Inc. p. 6.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":6,"type":"book","title":"OpenCV change logs: http://code.opencv.org/projects/opencv/wiki/ChangeLog","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":7,"type":"book","title":"OpenCV Developer Site: http://code.opencv.org","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":8,"type":"book","title":"OpenCV User Site: http://opencv.org/","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":9,"type":"book","title":"\"Intel Acquires Computer Vision for IOT, Automotive | Intel Newsroom\". Intel Newsroom (in 英语). Retrieved 2018-11-26.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":10,"type":"book","title":"\"Intel acquires Russian computer vision company Itseez\". East-West Digital News (in 英语). 2016-05-31. Retrieved 2018-11-26.","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":11,"type":"book","title":"OpenCV: http://opencv.org/opencv-3-3.html","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":12,"type":"book","title":"OpenCV C interface: http://docs.opencv.org","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":13,"type":"book","title":"CPAN: http://search.cpan.org/~yuta/Cv-0.29/","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":14,"type":"book","title":"Ch OpenCV: http://www.softintegration.com/products/thirdparty/opencv/","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":15,"type":"book","title":"The haskell-opencv project on Github: https://github.com/LumiGuide/haskell-opencv","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":16,"type":"book","title":"Introduction to OpenCV.js and Tutorials","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":17,"type":"book","title":"Cuda GPU port: http://opencv.org/platforms/cuda.html","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":18,"type":"book","title":"OpenCL Announcement: http://opencv.org/opencv-v2-4-3rc-is-under-way.html","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":19,"type":"book","title":"OpenCL-accelerated Computer Vision API Reference: http://docs.opencv.org/modules/ocl/doc/ocl.html","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":20,"type":"book","title":"Maemo port: https://garage.maemo.org/projects/opencv","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":21,"type":"book","title":"BlackBerry 10 (partial port): https://github.com/blackberry/OpenCV","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false},{"id":22,"type":"book","title":"https://web.archive.org/web/20221025090252/https://github.com/Itseez/opencv","site":"","url":"","journalName":null,"author":"","press":"","publishYear":"","publishTime":null,"publishPlace":"","page":"","volume":"","quoteTime":null,"quoted":false}],"recommendReferences":null,"auditState":2,"lemmaLevel":1,"origin":0,"originEnTitle":null,"originZhTitle":null,"pv":16710,"auditType":0,"synonyms":["opecv"],"showEditTime":"2019.12.13 18:46","auditors":[{"uid":0,"name":"Ki.κe","pic":"https://web.archive.org/web/20221025090252/https://wx.qlogo.cn/mmopen/vi_32/y67kfr32Doib4wg71Jiau7jVWvharic3nRKgdRRQSl6koeQJCo0GQs2Krw0vwdFRsOWnHIQOwAZsSg5lIkIrFCOcQ/132","introduction":null,"educations":null,"jobs":null,"works":null,"educationBrief":"","jobBrief":"","role":0,"roleName":null,"title":"","professionalTitle":null,"phoneNo":null,"editable":true,"partnerId":0,"partnerIdCreateTime":0,"partnerIdPoped":false}],"hasZhishiNav":false,"auditInfos":{},"isHistory":false};</script><script crossorigin="anonymous" src="./644.OpenCV - 搜狗科学百科_files/aegis.min.js.download"></script><script crossorigin="anonymous" src="./644.OpenCV - 搜狗科学百科_files/main_2020092401.js.download"></script><script crossorigin="anonymous" src="./644.OpenCV - 搜狗科学百科_files/react.production.min.js.download"></script><script crossorigin="anonymous" src="./644.OpenCV - 搜狗科学百科_files/react-dom.production.min.js.download"></script><script crossorigin="anonymous" src="./644.OpenCV - 搜狗科学百科_files/jquery-1.11.1.min.js.download"></script><script crossorigin="anonymous" src="./644.OpenCV - 搜狗科学百科_files/main_2022062701.js.download"></script><script crossorigin="anonymous" src="./644.OpenCV - 搜狗科学百科_files/main_66bbe21.js.download"></script><script crossorigin="anonymous" src="./644.OpenCV - 搜狗科学百科_files/react.production.min.js.download"></script><script crossorigin="anonymous" src="./644.OpenCV - 搜狗科学百科_files/react-dom.production.min.js.download"></script><script crossorigin="anonymous" src="./644.OpenCV - 搜狗科学百科_files/main_edf0f08.js.download"></script>
</body></html>